{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:49:40 - INFO - root -   {'run_text': 'multilabel toxic comments with freezable layers', 'train_size': -1, 'val_size': -1, 'log_path': PosixPath('/scratch/da2734/twitter/sana/log'), 'full_data_dir': PosixPath('/scratch/da2734/twitter/sana/data'), 'data_dir': PosixPath('/scratch/da2734/twitter/sana/data'), 'task_name': 'intent', 'no_cuda': False, 'output_dir': PosixPath('/scratch/da2734/twitter/sana/output_100'), 'max_seq_length': 512, 'do_train': True, 'do_eval': True, 'do_lower_case': True, 'train_batch_size': 8, 'eval_batch_size': 16, 'learning_rate': 5e-05, 'num_train_epochs': 100, 'warmup_proportion': 0.0, 'local_rank': -1, 'seed': 42, 'gradient_accumulation_steps': 1, 'optimize_on_cpu': False, 'fp16': False, 'fp16_opt_level': 'O1', 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'max_steps': -1, 'warmup_steps': 500, 'logging_steps': 50, 'eval_all_checkpoints': True, 'overwrite_output_dir': True, 'overwrite_cache': False, 'loss_scale': 128, 'model_name': 'bert-base-uncased', 'model_type': 'bert'}\n",
      "03/06/2020 12:49:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/da2734/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da2734/miniconda3/envs/worldbank/lib/python3.7/site-packages/ipykernel_launcher.py:26: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:49:41 - INFO - root -   Writing example 0 of 1303\n",
      "03/06/2020 12:49:41 - INFO - root -   Saving features into cached file /scratch/da2734/twitter/sana/data/cache/cached_bert_train_multi_label_512_train.csv\n",
      "03/06/2020 12:49:42 - INFO - root -   Writing example 0 of 559\n",
      "03/06/2020 12:49:43 - INFO - root -   Saving features into cached file /scratch/da2734/twitter/sana/data/cache/cached_bert_dev_multi_label_512_dev.csv\n",
      "num_labels 5\n"
     ]
    }
   ],
   "source": [
    "#gets all this setup\n",
    "from transformers import BertTokenizer\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from box import Box\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "# import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.metrics import *\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "LOG_PATH=Path('/scratch/da2734/twitter/sana/log/')\n",
    "DATA_PATH=Path('/scratch/da2734/twitter/sana/data')\n",
    "LABEL_PATH=Path('/scratch/da2734/twitter/sana/data/')\n",
    "OUTPUT_PATH=Path('/scratch/da2734/twitter/sana/output_100')\n",
    "FINETUNED_PATH = None\n",
    "\n",
    "args = Box({\n",
    "    \"run_text\": \"multilabel toxic comments with freezable layers\",\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"log_path\": LOG_PATH,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"task_name\": \"labor_market_classification\",\n",
    "    \"no_cuda\": False,\n",
    "#     \"bert_model\": BERT_PRETRAINED_PATH,\n",
    "    \"output_dir\": OUTPUT_PATH,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_train_epochs\": 100,\n",
    "    \"warmup_proportion\": 0.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"max_steps\": -1,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"logging_steps\": 50,\n",
    "    \"eval_all_checkpoints\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"overwrite_cache\": False,\n",
    "    \"seed\": 42,\n",
    "    \"loss_scale\": 128,\n",
    "    \"task_name\": 'intent',\n",
    "    \"model_name\": 'bert-base-uncased',\n",
    "    \"model_type\": 'bert'\n",
    "})\n",
    "\n",
    "import logging\n",
    "\n",
    "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.info(args)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    args.multi_gpu = True\n",
    "else:\n",
    "    args.multi_gpu = False\n",
    "\n",
    "label_cols = [\"job_loss\",\"is_unemployed\",\"job_search\",\"is_hired\",\"job_offer\"]\n",
    "\n",
    "databunch = BertDataBunch(\n",
    "                        args['data_dir'], \n",
    "                        LABEL_PATH, \n",
    "                        args.model_name, \n",
    "                        train_file='train.csv', \n",
    "                        val_file='dev.csv',\n",
    "                        # test_data='test.csv',\n",
    "                        text_col=\"text\", #this is the name of the column in the train file that containts the tweet text\n",
    "                        label_col=label_cols,\n",
    "                        batch_size_per_gpu=args['train_batch_size'], \n",
    "                        max_seq_length=args['max_seq_length'], \n",
    "                        multi_gpu=args.multi_gpu, \n",
    "                        multi_label=True, \n",
    "                        model_type=args.model_type)\n",
    "\n",
    "num_labels = len(databunch.labels)\n",
    "print('num_labels', num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databunch.train_dl.dataset[2][3] # this train_dlgives us the training dataset for example 2's labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics defined: https://github.com/kaushaltrivedi/fast-bert/blob/d89e2aa01d948d6d3cdea7ad106bf5792fea7dfa/fast_bert/metrics.py\n",
    "metrics = []\n",
    "metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
    "metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
    "metrics.append({'name': 'fbeta', 'function': fbeta})\n",
    "metrics.append({'name': 'accuracy', 'function': accuracy})\n",
    "metrics.append({'name': 'accuracy_multilabel', 'function': accuracy_multilabel})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:49:50 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/da2734/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "03/06/2020 12:49:50 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 5,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "bert-base-uncased\n",
      "<class 'str'>\n",
      "03/06/2020 12:49:50 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/da2734/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "03/06/2020 12:49:53 - INFO - transformers.modeling_utils -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "03/06/2020 12:49:53 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "learner = BertLearner.from_pretrained_model(\n",
    "                                            databunch, \n",
    "                                            pretrained_path=args.model_name, \n",
    "                                            metrics=metrics, \n",
    "                                            device=device, \n",
    "                                            logger=logger, \n",
    "                                            output_dir=args.output_dir, \n",
    "                                            finetuned_wgts_path=FINETUNED_PATH, \n",
    "                                            warmup_steps=args.warmup_steps,\n",
    "                                            multi_gpu=args.multi_gpu, \n",
    "                                            is_fp16=args.fp16, \n",
    "                                            multi_label=True, \n",
    "                                            logging_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:50:12 - INFO - root -   ***** Running training *****\n",
      "03/06/2020 12:50:12 - INFO - root -     Num examples = 1303\n",
      "03/06/2020 12:50:12 - INFO - root -     Num Epochs = 100\n",
      "03/06/2020 12:50:12 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "03/06/2020 12:50:12 - INFO - root -     Gradient Accumulation steps = 1\n",
      "03/06/2020 12:50:12 - INFO - root -     Total optimization steps = 16300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.00% [5/100 23:49<7:32:35]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='163', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.52% [9/163 00:13<03:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:54:22 - INFO - root -   Running evaluation\n",
      "03/06/2020 12:54:22 - INFO - root -     Num examples = 559\n",
      "03/06/2020 12:54:22 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='35' class='' max='35', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [35/35 00:35<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:54:57 - INFO - root -   eval_loss after epoch 1: 0.6702173931258065: \n",
      "03/06/2020 12:54:57 - INFO - root -   eval_accuracy_thresh after epoch 1: 0.5588550567626953: \n",
      "03/06/2020 12:54:57 - INFO - root -   eval_roc_auc after epoch 1: 0.4849224147136861: \n",
      "03/06/2020 12:54:57 - INFO - root -   eval_fbeta after epoch 1: 0.32639095187187195: \n",
      "03/06/2020 12:54:57 - INFO - root -   eval_accuracy after epoch 1: 0.0: \n",
      "03/06/2020 12:54:57 - INFO - root -   eval_accuracy_multilabel after epoch 1: 0.5366726296958855: \n",
      "03/06/2020 12:54:57 - INFO - root -   lr after epoch 1: 1.63e-05\n",
      "03/06/2020 12:54:57 - INFO - root -   train_loss after epoch 1: 0.7085930869623196\n",
      "03/06/2020 12:54:57 - INFO - root -   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da2734/miniconda3/envs/worldbank/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:59:08 - INFO - root -   Running evaluation\n",
      "03/06/2020 12:59:08 - INFO - root -     Num examples = 559\n",
      "03/06/2020 12:59:08 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='35' class='' max='35', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [35/35 00:35<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 12:59:43 - INFO - root -   eval_loss after epoch 2: 0.5479243057114738: \n",
      "03/06/2020 12:59:43 - INFO - root -   eval_accuracy_thresh after epoch 2: 0.8522360920906067: \n",
      "03/06/2020 12:59:43 - INFO - root -   eval_roc_auc after epoch 2: 0.6037328421104512: \n",
      "03/06/2020 12:59:43 - INFO - root -   eval_fbeta after epoch 2: 0.32633334398269653: \n",
      "03/06/2020 12:59:43 - INFO - root -   eval_accuracy after epoch 2: 0.0: \n",
      "03/06/2020 12:59:43 - INFO - root -   eval_accuracy_multilabel after epoch 2: 0.3595706618962433: \n",
      "03/06/2020 12:59:43 - INFO - root -   lr after epoch 2: 3.26e-05\n",
      "03/06/2020 12:59:43 - INFO - root -   train_loss after epoch 2: 0.61217272318214\n",
      "03/06/2020 12:59:43 - INFO - root -   \n",
      "\n",
      "03/06/2020 13:03:54 - INFO - root -   Running evaluation\n",
      "03/06/2020 13:03:54 - INFO - root -     Num examples = 559\n",
      "03/06/2020 13:03:54 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='35' class='' max='35', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [35/35 00:35<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 13:04:29 - INFO - root -   eval_loss after epoch 3: 0.46058563590049745: \n",
      "03/06/2020 13:04:29 - INFO - root -   eval_accuracy_thresh after epoch 3: 0.8540250062942505: \n",
      "03/06/2020 13:04:29 - INFO - root -   eval_roc_auc after epoch 3: 0.7122059234250886: \n",
      "03/06/2020 13:04:29 - INFO - root -   eval_fbeta after epoch 3: 0.3068256378173828: \n",
      "03/06/2020 13:04:29 - INFO - root -   eval_accuracy after epoch 3: 0.0: \n",
      "03/06/2020 13:04:29 - INFO - root -   eval_accuracy_multilabel after epoch 3: 0.24329159212880144: \n",
      "03/06/2020 13:04:29 - INFO - root -   lr after epoch 3: 4.89e-05\n",
      "03/06/2020 13:04:29 - INFO - root -   train_loss after epoch 3: 0.5040030786596192\n",
      "03/06/2020 13:04:29 - INFO - root -   \n",
      "\n",
      "03/06/2020 13:08:40 - INFO - root -   Running evaluation\n",
      "03/06/2020 13:08:40 - INFO - root -     Num examples = 559\n",
      "03/06/2020 13:08:40 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='35' class='' max='35', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [35/35 00:35<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 13:09:16 - INFO - root -   eval_loss after epoch 4: 0.40564790197781153: \n",
      "03/06/2020 13:09:16 - INFO - root -   eval_accuracy_thresh after epoch 4: 0.8540250062942505: \n",
      "03/06/2020 13:09:16 - INFO - root -   eval_roc_auc after epoch 4: 0.7435157347396436: \n",
      "03/06/2020 13:09:16 - INFO - root -   eval_fbeta after epoch 4: 0.17866261303424835: \n",
      "03/06/2020 13:09:16 - INFO - root -   eval_accuracy after epoch 4: 0.0: \n",
      "03/06/2020 13:09:16 - INFO - root -   eval_accuracy_multilabel after epoch 4: 0.2003577817531306: \n",
      "03/06/2020 13:09:16 - INFO - root -   lr after epoch 4: 4.998858306043398e-05\n",
      "03/06/2020 13:09:16 - INFO - root -   train_loss after epoch 4: 0.43177414415804155\n",
      "03/06/2020 13:09:16 - INFO - root -   \n",
      "\n",
      "03/06/2020 13:13:26 - INFO - root -   Running evaluation\n",
      "03/06/2020 13:13:26 - INFO - root -     Num examples = 559\n",
      "03/06/2020 13:13:26 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='35' class='' max='35', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [35/35 00:35<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06/2020 13:14:01 - INFO - root -   eval_loss after epoch 5: 0.37689241554055897: \n",
      "03/06/2020 13:14:01 - INFO - root -   eval_accuracy_thresh after epoch 5: 0.8540250062942505: \n",
      "03/06/2020 13:14:01 - INFO - root -   eval_roc_auc after epoch 5: 0.782469586074899: \n",
      "03/06/2020 13:14:01 - INFO - root -   eval_fbeta after epoch 5: 0.13316011428833008: \n",
      "03/06/2020 13:14:01 - INFO - root -   eval_accuracy after epoch 5: 0.0: \n",
      "03/06/2020 13:14:01 - INFO - root -   eval_accuracy_multilabel after epoch 5: 0.2003577817531306: \n",
      "03/06/2020 13:14:01 - INFO - root -   lr after epoch 5: 4.99509798412774e-05\n",
      "03/06/2020 13:14:01 - INFO - root -   train_loss after epoch 5: 0.39070983706442125\n",
      "03/06/2020 13:14:01 - INFO - root -   \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-50cc94614e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this trains the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/fast_bert/learner_cls.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, validate, schedule_type, optimizer_type)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     )\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     torch.nn.utils.clip_grad_norm_(\n\u001b[1;32m    388\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(args.num_train_epochs, args.learning_rate, validate=True) #this trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2020 18:29:52 - INFO - root -   Running evaluation\n",
      "02/22/2020 18:29:52 - INFO - root -     Num examples = 559\n",
      "02/22/2020 18:29:52 - INFO - root -     Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='35' class='' max='35', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [35/35 00:10<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.38508441490786416,\n",
       " 'accuracy_thresh': 0.8540250062942505,\n",
       " 'roc_auc': 0.7829953095607745,\n",
       " 'fbeta': 0.12640202045440674}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2020 18:30:24 - INFO - transformers.configuration_utils -   Configuration saved in /scratch/da2734/twitter/sana/output/model_out/config.json\n",
      "02/22/2020 18:30:24 - INFO - transformers.modeling_utils -   Model weights saved in /scratch/da2734/twitter/sana/output/model_out/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "learner.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2020 18:33:33 - INFO - root -   Writing example 0 of 1\n",
      "[('job_loss', 0.29054415225982666), ('is_unemployed', 0.2861913740634918), ('is_hired', 0.2792271375656128), ('job_search', 0.17347979545593262), ('job_offer', 0.11866018921136856)]\n"
     ]
    }
   ],
   "source": [
    "texts = ['I just received a job offer']\n",
    "predictions = learner.predict_batch(texts)\n",
    "print(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
