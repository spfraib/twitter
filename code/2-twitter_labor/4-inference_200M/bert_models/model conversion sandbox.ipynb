{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnxruntime as ort\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import onnx\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "\n",
    "sys.path.append('/scratch/da2734/twitter/jobs/inference_200M/utils_for_inference')\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "from transformers import BertConfig, BertTokenizer, BertTokenizerFast, BertForSequenceClassification\n",
    "from onnxruntime_tools import optimizer\n",
    "from quantize import quantize, QuantizationMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lost_job_1mo\n",
      ">> converting..\n",
      "ONNX opset version set to: 11\n",
      "Loading pipeline (model: /scratch/mt4493/twitter_labor/trained_models/iter0/jul23_iter0/DeepPavlov_bert-base-cased-conversational_jul23_iter0_preprocessed_11232989/lost_job_1mo/models/best_model, tokenizer: DeepPavlov/bert-base-cased-conversational)\n",
      "Creating folder /scratch/mt4493/twitter_labor/trained_models/iter0/jul23_iter0/DeepPavlov_bert-base-cased-conversational_jul23_iter0_preprocessed_11232989/lost_job_1mo/models/best_model/onnx\n",
      "PyTorch: 1.5.0+cu101\n",
      ">> optimizing..\n",
      "Optimized model saved at : /scratch/mt4493/twitter_labor/trained_models/iter0/jul23_iter0/DeepPavlov_bert-base-cased-conversational_jul23_iter0_preprocessed_11232989/lost_job_1mo/models/best_model/onnx/bert_optimized.onnx\n",
      ">> quantizing..\n",
      "Quantized&optimized model saved at : /scratch/mt4493/twitter_labor/trained_models/iter0/jul23_iter0/DeepPavlov_bert-base-cased-conversational_jul23_iter0_preprocessed_11232989/lost_job_1mo/models/best_model/onnx/bert_optimized_quantized.onnx\n"
     ]
    }
   ],
   "source": [
    "# model_path = '/scratch/da2734/twitter/jobs/onnx/results_simpletransformers_jun3_10Klabels_0_all_labels/lost_job_1mo/'\n",
    "# onnx_path = '/scratch/da2734/twitter/jobs/onnx/results_simpletransformers_jun3_10Klabels_0_all_labels/lost_job_1mo/onnx/'\n",
    "\n",
    "for label in [\"lost_job_1mo\",\"is_unemployed\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "\n",
    "    print(label)\n",
    "    model_path = '/scratch/mt4493/twitter_labor/trained_models/iter0/jul23_iter0/DeepPavlov_bert-base-cased-conversational_jul23_iter0_preprocessed_11232989/{}/models/best_model'.format(label)\n",
    "    onnx_path = model_path+'/onnx/'.format(label)\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(onnx_path) # deleting onxx folder and contents, if exists, conversion excepts\n",
    "    except:\n",
    "        print('no existing folder, creating one')\n",
    "        os.makedirs(onnx_path)\n",
    "    \n",
    "    print('>> converting..')\n",
    "    convert(framework=\"pt\", \n",
    "        model=model_path, \n",
    "        tokenizer=\"DeepPavlov/bert-base-cased-conversational\",\n",
    "        output=onnx_path+'converted.onnx', \n",
    "        opset=11)\n",
    "\n",
    "    print('>> optimizing..')\n",
    "    # ONNX optimization\n",
    "    optimized_model = optimizer.optimize_model(onnx_path+'/converted.onnx',\n",
    "                                               model_type='bert', \n",
    "                                               num_heads=12, \n",
    "                                               hidden_size=768)\n",
    "\n",
    "    optimized_onnx_model_path = os.path.join(onnx_path, 'bert_optimized.onnx')\n",
    "    optimized_model.save_model_to_file(optimized_onnx_model_path)\n",
    "    print('Optimized model saved at :', optimized_onnx_model_path)\n",
    "\n",
    "    print('>> quantizing..')    \n",
    "    model = onnx.load(onnx_path+'/converted.onnx')\n",
    "    quantized_model = quantize(model, quantization_mode=QuantizationMode.IntegerOps, static=False)\n",
    "    optimized_quantized_onnx_model_path = os.path.join(os.path.dirname(optimized_onnx_model_path), 'bert_optimized_quantized.onnx')\n",
    "    onnx.save(quantized_model, optimized_quantized_onnx_model_path)\n",
    "    print('Quantized&optimized model saved at :', optimized_quantized_onnx_model_path)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
