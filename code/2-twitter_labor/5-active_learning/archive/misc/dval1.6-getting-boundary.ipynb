{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure you have all libraries installed. \n",
    "use conda environment: /scratch/da2734/twitter/worldbank_twitter_environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cpus: 16\n",
      "memory available (GB): 251.8069610595703\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "workers = os.cpu_count()\n",
    "if 'sched_getaffinity' in dir(os):\n",
    "    workers = len(os.sched_getaffinity(0))\n",
    "print('number of cpus:', workers)\n",
    "\n",
    "import re\n",
    "with open('/proc/meminfo') as f:\n",
    "    meminfo = f.read()\n",
    "matched = re.search(r'^MemTotal:\\s+(\\d+)', meminfo)\n",
    "if matched: \n",
    "    mem_total_kB = int(matched.groups()[0])\n",
    "# meminfo \n",
    "    \n",
    "print('memory available (GB):', mem_total_kB/1024/1024)\n",
    "\n",
    "# import os\n",
    "# mem=str(os.popen('free -t -m').readlines())\n",
    "# mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#gets all this setup\n",
    "import time\n",
    "start_time = time.time()\n",
    "from transformers import BertTokenizer\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from box import Box\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "# import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
    "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "# from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc, accuracy\n",
    "from fast_bert.metrics import *\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# LOG_PATH=Path('/scratch/da2734/twitter/sana/log/')\n",
    "# DATA_PATH=Path('/scratch/da2734/twitter/sana/data')\n",
    "# LABEL_PATH=Path('/scratch/da2734/twitter/sana/data/')\n",
    "# OUTPUT_PATH=Path('/scratch/da2734/twitter/sana/output/')\n",
    "LOG_PATH=Path('/scratch/da2734/twitter/mturk_mar6/log/')\n",
    "DATA_PATH=Path('/scratch/da2734/twitter/mturk_mar6/data')\n",
    "LABEL_PATH=Path('/scratch/da2734/twitter/mturk_mar6/data/')\n",
    "OUTPUT_PATH=Path('/scratch/da2734/twitter/mturk_mar6/output_100')\n",
    "FINETUNED_PATH = None\n",
    "\n",
    "args = Box({\n",
    "    \"run_text\": \"multilabel toxic comments with freezable layers\",\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"log_path\": LOG_PATH,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": DATA_PATH,\n",
    "    \"task_name\": \"labor_market_classification\",\n",
    "    \"no_cuda\": False,\n",
    "#     \"bert_model\": BERT_PRETRAINED_PATH,\n",
    "    \"output_dir\": OUTPUT_PATH,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 200,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_train_epochs\": 6,\n",
    "    \"warmup_proportion\": 0.0,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    \"fp16_opt_level\": \"O1\",\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"max_steps\": -1,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"logging_steps\": 50,\n",
    "    \"eval_all_checkpoints\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"overwrite_cache\": False,\n",
    "    \"seed\": 42,\n",
    "    \"loss_scale\": 128,\n",
    "    \"task_name\": 'intent',\n",
    "    \"model_name\": 'bert-base-uncased',\n",
    "    \"model_type\": 'bert'\n",
    "})\n",
    "\n",
    "import logging\n",
    "\n",
    "logfile = str(LOG_PATH/'log-{}-{}.txt'.format(run_start_time, args[\"run_text\"]))\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logfile),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# logger.info(args)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    args.multi_gpu = True\n",
    "else:\n",
    "    args.multi_gpu = False\n",
    "\n",
    "label_cols = [\"job_loss\",\"is_unemployed\",\"job_search\",\"is_hired\",\"job_offer\"]\n",
    "\n",
    "# databunch defined here https://github.com/kaushaltrivedi/fast-bert/blob/master/fast_bert/data_cls.py\n",
    "databunch = BertDataBunch(\n",
    "                        args['data_dir'], \n",
    "                        LABEL_PATH, \n",
    "                        args.model_name, \n",
    "                        train_file='train.csv', \n",
    "                        val_file='val.csv',\n",
    "                        # test_data='test.csv',\n",
    "                        text_col=\"text\", #this is the name of the column in the train file that containts the tweet text\n",
    "                        label_col=label_cols,\n",
    "                        batch_size_per_gpu=args['train_batch_size'], \n",
    "                        max_seq_length=args['max_seq_length'], \n",
    "                        multi_gpu=args.multi_gpu, \n",
    "                        multi_label=True, \n",
    "                        model_type=args.model_type)\n",
    "\n",
    "num_labels = len(databunch.labels)\n",
    "print('num_labels', num_labels)\n",
    "\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "# print ('Current cuda device ', torch.cuda.current_device)\n",
    "\n",
    "# metrics defined: https://github.com/kaushaltrivedi/fast-bert/blob/d89e2aa01d948d6d3cdea7ad106bf5792fea7dfa/fast_bert/metrics.py\n",
    "metrics = []\n",
    "metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
    "metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
    "metrics.append({'name': 'roc_auc_save_to_plot', 'function': roc_auc_save_to_plot})\n",
    "metrics.append({'name': 'fbeta', 'function': fbeta})\n",
    "metrics.append({'name': 'accuracy', 'function': accuracy})\n",
    "metrics.append({'name': 'accuracy_multilabel', 'function': accuracy_multilabel})\n",
    "\n",
    "\n",
    "learner = BertLearner.from_pretrained_model(\n",
    "                                            databunch, \n",
    "                                            pretrained_path='/scratch/da2734/twitter/mturk_mar6/output_100/model_out/', \n",
    "                                            metrics=metrics, \n",
    "                                            device=device, \n",
    "                                            logger=logger, \n",
    "                                            output_dir=args.output_dir, \n",
    "                                            finetuned_wgts_path=FINETUNED_PATH, \n",
    "                                            warmup_steps=args.warmup_steps,\n",
    "                                            multi_gpu=args.multi_gpu, \n",
    "                                            is_fp16=args.fp16, \n",
    "                                            multi_label=True, \n",
    "                                            logging_steps=0)\n",
    "\n",
    "print('time taken to load all this stuff:', str(time.time() - start_time), 'seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading random and filtered samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to load keyword filtered sample: 329.5322268009186 seconds\n",
      "(92121093, 11)\n"
     ]
    }
   ],
   "source": [
    "# filtered contains 8G of data!!\n",
    "import time\n",
    "start_time = time.time()\n",
    "import pyarrow.parquet as pq\n",
    "from glob import glob\n",
    "import os\n",
    "country_code = 'US'\n",
    "month = '2012-1'\n",
    "path_to_data = '/scratch/spf248/twitter/data/classification/US/filtered/'\n",
    "tweets_filtered=pq.ParquetDataset(glob(os.path.join(path_to_data,                                           \n",
    "#                                            country_code,\n",
    "#                                            month,\n",
    "                                           '*.parquet'))).read().to_pandas()\n",
    "print('time taken to load keyword filtered sample:', str(time.time() - start_time), 'seconds')\n",
    "print(tweets_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to load random sample: 320.91191005706787 seconds\n",
      "(92114009, 11)\n"
     ]
    }
   ],
   "source": [
    "# random contains 7.3G of data!!\n",
    "import time\n",
    "start_time = time.time()\n",
    "import pyarrow.parquet as pq\n",
    "from glob import glob\n",
    "import os\n",
    "country_code = 'US'\n",
    "month = '2012-1'\n",
    "path_to_data = '/scratch/spf248/twitter/data/classification/US/random'\n",
    "tweets_random=pq.ParquetDataset(glob(os.path.join(path_to_data,                                           \n",
    "#                                            country_code,\n",
    "#                                            month,\n",
    "                                           '*.parquet'))).read().to_pandas()\n",
    "print('time taken to load random sample:', str(time.time() - start_time), 'seconds')\n",
    "print(tweets_random.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read csv output from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to load filtered sample: 71.29864716529846 seconds\n",
      "time taken to load random sample: 69.16849756240845 seconds\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "start_time = time.time()\n",
    "model_output_path = '/scratch/spf248/twitter/data/classification/US/BERT/twitter_sam/mturk_mar6/pred/'\n",
    "model_output_filtered = pd.concat([pd.read_csv(f) for f in glob.glob(model_output_path+'filtered*.csv')], ignore_index = True)\n",
    "print('time taken to load filtered sample:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "start_time = time.time()\n",
    "model_output_path = '/scratch/spf248/twitter/data/classification/US/BERT/twitter_sam/mturk_mar6/pred/'\n",
    "model_output_random = pd.concat([pd.read_csv(f) for f in glob.glob(model_output_path+'random*.csv')], ignore_index = True)\n",
    "print('time taken to load random sample:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "model_output_random.columns = ['tweet_id', 'offer_model', 'search_model', 'unemployed_model', 'hired_model', 'loss_model']\n",
    "model_output_filtered.columns = ['tweet_id', 'search_model', 'unemployed_model', 'offer_model', 'hired_model', 'loss_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>search_model</th>\n",
       "      <th>unemployed_model</th>\n",
       "      <th>offer_model</th>\n",
       "      <th>hired_model</th>\n",
       "      <th>loss_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367703789572079616</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.029396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367703936251490304</td>\n",
       "      <td>0.056376</td>\n",
       "      <td>0.046692</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>0.034980</td>\n",
       "      <td>0.032195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367704099858300929</td>\n",
       "      <td>0.069512</td>\n",
       "      <td>0.049335</td>\n",
       "      <td>0.056562</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.029765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367704339076243457</td>\n",
       "      <td>0.064265</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367704640948682752</td>\n",
       "      <td>0.080633</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>0.051603</td>\n",
       "      <td>0.030082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  search_model  unemployed_model  offer_model  \\\n",
       "0  367703789572079616      0.069985          0.058530     0.048582   \n",
       "1  367703936251490304      0.056376          0.046692     0.075235   \n",
       "2  367704099858300929      0.069512          0.049335     0.056562   \n",
       "3  367704339076243457      0.064265          0.044906     0.063739   \n",
       "4  367704640948682752      0.080633          0.048776     0.059704   \n",
       "\n",
       "   hired_model  loss_model  \n",
       "0     0.036250    0.029396  \n",
       "1     0.034980    0.032195  \n",
       "2     0.043067    0.029765  \n",
       "3     0.041979    0.036900  \n",
       "4     0.051603    0.030082  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_random.columns = ['tweet_id', 'offer_model', 'search_model', 'unemployed_model', 'hired_model', 'loss_model']\n",
    "model_output_filtered.columns = ['tweet_id', 'search_model', 'unemployed_model', 'offer_model', 'hired_model', 'loss_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>fired</th>\n",
       "      <th>hired</th>\n",
       "      <th>job</th>\n",
       "      <th>laid_off</th>\n",
       "      <th>position</th>\n",
       "      <th>quit</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>work</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367881326273105920</td>\n",
       "      <td>@shoebydoo32 I only left to go back home for t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367881326281519105</td>\n",
       "      <td>oh my god bina id idnt read that u played GTA ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367882185916702722</td>\n",
       "      <td>I Have To Make What I Think Is The Best Decisi...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367883553121394690</td>\n",
       "      <td>@elizrod_ that's from hard work ðŸ˜‰</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367883867719348224</td>\n",
       "      <td>RT @MileenaSucks: Can I just lay out in the gr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  367881326273105920  @shoebydoo32 I only left to go back home for t...   \n",
       "1  367881326281519105  oh my god bina id idnt read that u played GTA ...   \n",
       "2  367882185916702722  I Have To Make What I Think Is The Best Decisi...   \n",
       "3  367883553121394690                  @elizrod_ that's from hard work ðŸ˜‰   \n",
       "4  367883867719348224  RT @MileenaSucks: Can I just lay out in the gr...   \n",
       "\n",
       "   fired  hired    job  laid_off  position   quit  unemployed   work  keyword  \n",
       "0  False  False  False     False     False  False       False  False    False  \n",
       "1  False  False  False     False     False  False       False  False    False  \n",
       "2  False  False  False     False     False  False       False  False    False  \n",
       "3  False  False  False     False     False  False       False   True     True  \n",
       "4  False  False  False     False     False  False       False  False    False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_random.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working with smaller samples for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "(10000, 11)\n",
      "(10000, 6)\n",
      "(10000, 6)\n"
     ]
    }
   ],
   "source": [
    "tweets_random_sample = tweets_random.head(10000)\n",
    "print(tweets_random_sample.shape)\n",
    "tweets_filtered_sample = tweets_filtered.head(10000)\n",
    "print(tweets_filtered_sample.shape)\n",
    "\n",
    "model_output_filtered_sample = model_output_filtered.head(10000)\n",
    "print(model_output_filtered_sample.shape)\n",
    "model_output_random_sample = model_output_random.head(10000)\n",
    "print(model_output_random_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>fired</th>\n",
       "      <th>hired</th>\n",
       "      <th>job</th>\n",
       "      <th>laid_off</th>\n",
       "      <th>position</th>\n",
       "      <th>quit</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>work</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276933934124765184</td>\n",
       "      <td>Damn i have to much homework</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>277143632232992768</td>\n",
       "      <td>Does a bedazzler work on leather? Serious ques...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277150490276540416</td>\n",
       "      <td>RT @porcelain10: Washington Post D Milbank bas...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>277151157208637440</td>\n",
       "      <td>Finally off work</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277175194454462465</td>\n",
       "      <td>Irrational: No BioShock PS Vita until Sony and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  276933934124765184                       Damn i have to much homework   \n",
       "1  277143632232992768  Does a bedazzler work on leather? Serious ques...   \n",
       "2  277150490276540416  RT @porcelain10: Washington Post D Milbank bas...   \n",
       "3  277151157208637440                                   Finally off work   \n",
       "4  277175194454462465  Irrational: No BioShock PS Vita until Sony and...   \n",
       "\n",
       "   fired  hired    job  laid_off  position   quit  unemployed  work  keyword  \n",
       "0  False  False  False     False     False  False       False  True     True  \n",
       "1  False  False  False     False     False  False       False  True     True  \n",
       "2  False  False  False     False     False  False       False  True     True  \n",
       "3  False  False  False     False     False  False       False  True     True  \n",
       "4  False  False  False     False     False  False       False  True     True  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_filtered_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>search_model</th>\n",
       "      <th>unemployed_model</th>\n",
       "      <th>offer_model</th>\n",
       "      <th>hired_model</th>\n",
       "      <th>loss_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367703789572079616</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.029396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367703936251490304</td>\n",
       "      <td>0.056376</td>\n",
       "      <td>0.046692</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>0.034980</td>\n",
       "      <td>0.032195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367704099858300929</td>\n",
       "      <td>0.069512</td>\n",
       "      <td>0.049335</td>\n",
       "      <td>0.056562</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.029765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367704339076243457</td>\n",
       "      <td>0.064265</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.063739</td>\n",
       "      <td>0.041979</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367704640948682752</td>\n",
       "      <td>0.080633</td>\n",
       "      <td>0.048776</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>0.051603</td>\n",
       "      <td>0.030082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  search_model  unemployed_model  offer_model  \\\n",
       "0  367703789572079616      0.069985          0.058530     0.048582   \n",
       "1  367703936251490304      0.056376          0.046692     0.075235   \n",
       "2  367704099858300929      0.069512          0.049335     0.056562   \n",
       "3  367704339076243457      0.064265          0.044906     0.063739   \n",
       "4  367704640948682752      0.080633          0.048776     0.059704   \n",
       "\n",
       "   hired_model  loss_model  \n",
       "0     0.036250    0.029396  \n",
       "1     0.034980    0.032195  \n",
       "2     0.043067    0.029765  \n",
       "3     0.041979    0.036900  \n",
       "4     0.051603    0.030082  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_filtered_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named tweet_id for object type <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-da8479d44e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# merged_filtered_sample = tweets_filtered_sample.merge(model_output_filtered_sample, on='tweet_id')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmerged_filtered_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets_filtered_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output_filtered_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tweet_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmerged_filtered_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Need to flip BlockManager axis in the DataFrame special case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No axis named {axis} for object type {cls}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No axis named tweet_id for object type <class 'pandas.core.frame.DataFrame'>"
     ]
    }
   ],
   "source": [
    "# tweets_filtered_sample.dtypes\n",
    "# tweets_filtered_sample['tweet_id'] = tweets_filtered_sample['tweet_id'].apply(pd.to_numeric)\n",
    "# tweets_filtered_sample.dtypes\n",
    "# merged_filtered_sample = tweets_filtered_sample.merge(model_output_filtered_sample, on='tweet_id')\n",
    "\n",
    "merged_filtered_sample = pd.concat([tweets_filtered_sample, model_output_filtered_sample], join=\"inner\", axis = 'tweet_id')\n",
    "\n",
    "merged_filtered_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting original tweets column type to int from object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3da9f08d35e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time taken:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/worldbank/lib/python3.7/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             values = lib.maybe_convert_numeric(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tweets_filtered['tweet_id'] = tweets_filtered['tweet_id'].apply(pd.to_numeric)\n",
    "print('time taken for filtered conversion:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tweets_random['tweet_id'] = tweets_random['tweet_id'].apply(pd.to_numeric)\n",
    "print('time taken for random conversion:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging original tweets with model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "merged_filtered = tweets_filtered.merge(model_output_filtered, on='tweet_id')\n",
    "print(merged_filtered.shape)\n",
    "print('time taken for merge filtered:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "merged_random = tweets_random.merge(model_output_random, on='tweet_id')\n",
    "print(merged_random.shape)\n",
    "print('time taken for merge random:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# then we can pick tweets close to any threshold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offer_model filtered time taken: 0.00632476806640625 seconds\n",
      "search_model filtered time taken: 0.005393505096435547 seconds\n",
      "unemployed_model filtered time taken: 0.004188060760498047 seconds\n",
      "hired_model filtered time taken: 0.015344381332397461 seconds\n",
      "loss_model filtered time taken: 0.0038330554962158203 seconds\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "boundary_width = 0.05\n",
    "columns = ['offer_model','search_model','unemployed_model','hired_model','loss_model']\n",
    "\n",
    "for column in columns:\n",
    "    start_time = time.time()\n",
    "    all_filtered_boundary = merged_filtered.loc[(merged_filtered[column] >= threshold - boundary_width) & \n",
    "                                                (merged_filtered[column] <= threshold + boundary_width)]\n",
    "    all_filtered_boundary.to_csv('../mturk_mar6/boundary/filtered_{}.csv'.format(column))\n",
    "    # print(all_filtered_boundary['text'])\n",
    "    print(column, 'filtered time taken:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offer_model random time taken: 0.004136085510253906 seconds\n",
      "search_model random time taken: 0.002611875534057617 seconds\n",
      "unemployed_model random time taken: 0.0023164749145507812 seconds\n",
      "hired_model random time taken: 0.0022461414337158203 seconds\n",
      "loss_model random time taken: 0.0023136138916015625 seconds\n"
     ]
    }
   ],
   "source": [
    "# merged_random = merged_filtered_sample\n",
    "\n",
    "for column in columns:\n",
    "    start_time = time.time()\n",
    "    all_filtered_boundary = merged_random.loc[(merged_random[column] >= threshold - boundary_width) & \n",
    "                                                (merged_random[column] <= threshold + boundary_width)]\n",
    "    all_filtered_boundary.to_csv('../mturk_mar6/boundary/random_{}.csv'.format(column))\n",
    "    # print(all_filtered_boundary['text'])\n",
    "    print(column, 'random time taken:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
