{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure you have all libraries installed. \n",
    "use conda environment: /scratch/da2734/twitter/worldbank_twitter_environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to load random sample: 440.7797255516052 seconds\n",
      "(92114009, 11)\n"
     ]
    }
   ],
   "source": [
    "# random contains 0.8G of data!!\n",
    "import time\n",
    "start_time = time.time()\n",
    "import pyarrow.parquet as pq\n",
    "from glob import glob\n",
    "import os\n",
    "country_code = 'US'\n",
    "month = '2012-1'\n",
    "path_to_data = '/scratch/spf248/twitter/data/classification/US/random/'\n",
    "tweets_random=pq.ParquetDataset(glob(os.path.join(path_to_data,                                           \n",
    "#                                            country_code,\n",
    "#                                            month,\n",
    "                                           '*.parquet'))).read().to_pandas()\n",
    "tweets_random['tweet_id'] = tweets_random['tweet_id'].astype(int)\n",
    "print('time taken to load random sample:', str(time.time() - start_time), 'seconds')\n",
    "print(tweets_random.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop columns: 5.32327938079834 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tweets_random = tweets_random[['tweet_id', 'text']]\n",
    "print('drop columns:', str(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367881326273105920</td>\n",
       "      <td>@shoebydoo32 I only left to go back home for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367881326281519105</td>\n",
       "      <td>oh my god bina id idnt read that u played GTA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367882185916702722</td>\n",
       "      <td>I Have To Make What I Think Is The Best Decisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>367883553121394690</td>\n",
       "      <td>@elizrod_ that's from hard work üòâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367883867719348224</td>\n",
       "      <td>RT @MileenaSucks: Can I just lay out in the gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text\n",
       "0  367881326273105920  @shoebydoo32 I only left to go back home for t...\n",
       "1  367881326281519105  oh my god bina id idnt read that u played GTA ...\n",
       "2  367882185916702722  I Have To Make What I Think Is The Best Decisi...\n",
       "3  367883553121394690                  @elizrod_ that's from hard work üòâ\n",
       "4  367883867719348224  RT @MileenaSucks: Can I just lay out in the gr..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_random.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random top 5M files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " is_unemployed\n",
      "dhaval time taken to load random sample: 72.79461789131165 seconds (45403146, 2)\n",
      "sam time taken to load random sample: 70.71351265907288 seconds (46139942, 2)\n",
      "concat: 1.076456069946289 seconds\n",
      "drop columns: 0.6384522914886475 seconds\n",
      "time taken to merge: 92.41594290733337 seconds (91543088, 3)\n",
      "drop dup: 132.29338812828064 seconds (84063455, 3)\n",
      "sort: 58.255332708358765 seconds (84063455, 3)\n",
      "top 10M truncate: 0.0006420612335205078 seconds (84063455, 3)\n",
      "                    tweet_id     proba  \\\n",
      "54503667  726772870114861057  0.315428   \n",
      "67056185  636011684159553536  0.315428   \n",
      "36193661  509522867193532416  0.315428   \n",
      "90195797  681217225940848640  0.315428   \n",
      "5859759   614623305014857728  0.315428   \n",
      "1537069   618943039407439873  0.315428   \n",
      "26144902  657039147975086080  0.315428   \n",
      "4209031   908119920118059008  0.315428   \n",
      "21620326  541697172123578368  0.315428   \n",
      "79419446  279764170675720192  0.315428   \n",
      "11549360  691379139320897537  0.315428   \n",
      "84431785  550734227713851393  0.315428   \n",
      "46498727  781932669718396928  0.315428   \n",
      "73264428  377565084895027201  0.315428   \n",
      "71638176  718589917157142529  0.315428   \n",
      "16685693  280692210868027394  0.315428   \n",
      "28123376  372837341054124033  0.315428   \n",
      "25071703  417823625157570561  0.315428   \n",
      "42767016  719263476498198528  0.315428   \n",
      "2017516   428669541791830016  0.315428   \n",
      "47799755  698219432808681472  0.315428   \n",
      "47294013  685326918346870785  0.315428   \n",
      "65493768  545773372752556032  0.315428   \n",
      "31294652  737863952043024385  0.315428   \n",
      "28447503  946436845885206529  0.315428   \n",
      "53059853  713469066493689857  0.315428   \n",
      "1331843   725503694901510144  0.315428   \n",
      "27347377  762395794557181952  0.315428   \n",
      "87738766  760205755702128640  0.315428   \n",
      "55860512  519701759401275393  0.315428   \n",
      "75462302  766330269733302272  0.315428   \n",
      "35507839  726282996332916736  0.315428   \n",
      "24196603  742981011441586177  0.315428   \n",
      "62580770  527824553402433536  0.315428   \n",
      "66723493  755961321191985152  0.315428   \n",
      "88414640  564171162889248769  0.315428   \n",
      "56803481  558685256732008448  0.315428   \n",
      "69065248  515288835622993920  0.315428   \n",
      "40271607  663439173270024192  0.315428   \n",
      "68588487  716388142446723072  0.315428   \n",
      "26756823  368131285543567360  0.315428   \n",
      "59228459  620643054119071744  0.315428   \n",
      "52989216  518889922410053632  0.315428   \n",
      "6359580   339902198039334912  0.315428   \n",
      "17176017  545082168121491456  0.315428   \n",
      "25505605  579700988660994048  0.315428   \n",
      "19312410  360374851346771970  0.315428   \n",
      "31735195  753092324817764353  0.315428   \n",
      "44752246  536040746038468608  0.315428   \n",
      "49874468  531254932075081728  0.315428   \n",
      "\n",
      "                                                       text  \n",
      "54503667  @TrackBrat_73 damn woman...I'm tryin!üòÇüòÇ https:...  \n",
      "67056185                                    @nadineex3 damn  \n",
      "36193661                              @DATBOYLOKZ damn !!!!  \n",
      "90195797                               üò≥üò≥üò≥üò≥ damn Carolina..  \n",
      "5859759                                    @_Dakotttaa damn  \n",
      "1537069                   @Vic__TorTois Damn turtlepoke.üòÇüòÇüê¢  \n",
      "26144902                                 @grantshippel damn  \n",
      "4209031                                  @baddieB_x3 Damn üòï  \n",
      "21620326                            @ArianaGreig damn üòçüëçüíØüôèüôå  \n",
      "79419446                      @SuckMi_3Stripes damn again!?  \n",
      "11549360                               @cailey_johnson damn  \n",
      "84431785                        Lmfao\"2015\"#Already damn üòãüòÖ  \n",
      "46498727                                     @SuhhKidd damn  \n",
      "73264428         throwbaaaack damn üëå http://t.co/9vwgxi6Fud  \n",
      "71638176      @jameslano damn bruh. https://t.co/MLefDkviS6  \n",
      "16685693                   @NurseKiKi86 damn that's hard...  \n",
      "28123376                     @Ababy_Xo damn that's crazy. üö∂  \n",
      "25071703                          @Cenas_Girl_ Damn right!!  \n",
      "42767016                                      @abeal98 damn  \n",
      "2017516                     @bxfoster damn straight!ECONüòÇüòÇüòÇ  \n",
      "47799755                                      @dvrrxll damn  \n",
      "47294013                        @riahtaughtyou_ damn dude..  \n",
      "65493768                         @yagirlkellytee damn babeüòû  \n",
      "31294652                       @bigblackkendal damn really?  \n",
      "28447503                                    Sighing... damn  \n",
      "53059853                              @LouisT91Updates DAMN  \n",
      "1331843                                @xo_naeemah damn üòÇüòÇüòÇ  \n",
      "27347377                                  @andytweetz_ damn  \n",
      "87738766                                 @Blackshear82 damn  \n",
      "55860512                               @pretttykitttty DAMN  \n",
      "75462302                                @thatKID_Tim13 DAMN  \n",
      "35507839                               @bernicecruz_10 damn  \n",
      "24196603                                 @guy_sparkman damn  \n",
      "62580770                                 @YourMomBot damn üî´  \n",
      "66723493                              @H2ODelirious damn :/  \n",
      "88414640                                  @AlexGLogics damn  \n",
      "56803481                                        TGIF!! Damn  \n",
      "69065248                          @kathy_derosa Damn right!  \n",
      "40271607                                 @LilveronicaR damn  \n",
      "68588487  @GeT_RiGhTcs Damn right, son. https://t.co/sH0...  \n",
      "26756823                            @EwWood13 Damn asshole.  \n",
      "59228459                              @peterjhanley_ damn üòî  \n",
      "52989216                            @felipegonzal355 damn üòî  \n",
      "6359580                                  @gandiaa310 damn üòë  \n",
      "17176017                                   @Sexy_BlTCH damn  \n",
      "25505605                             @theeyadoreaddi damn üòÇ  \n",
      "19312410                       @craig_3000 damn it! \"Who's\"  \n",
      "31735195                OHHHH DAMN  https://t.co/DLVGPsVq3C  \n",
      "44752246                                    @iizzyylol damn  \n",
      "49874468                               @singing_ghosts damn  \n",
      "time taken to dump: 3.7957584857940674 seconds\n",
      "\n",
      "\n",
      " lost_job_1mo\n",
      "dhaval time taken to load random sample: 76.0063784122467 seconds (45403146, 2)\n",
      "sam time taken to load random sample: 71.85550570487976 seconds (46139942, 2)\n",
      "concat: 1.1062977313995361 seconds\n",
      "drop columns: 0.6451785564422607 seconds\n",
      "time taken to merge: 93.94717121124268 seconds (91543088, 3)\n",
      "drop dup: 125.55868101119995 seconds (84063455, 3)\n",
      "sort: 63.14474105834961 seconds (84063455, 3)\n",
      "top 10M truncate: 4.194307565689087 seconds (84063455, 3)\n",
      "                    tweet_id     proba  \\\n",
      "64850143  733814762589429760  0.222577   \n",
      "60239803  290400212760023040  0.222577   \n",
      "13860198  790247571239366656  0.222577   \n",
      "51121510  497839356531732481  0.222577   \n",
      "67842310  489180450800562177  0.222577   \n",
      "71737331  691850109416554497  0.222577   \n",
      "37701024  454092266844332032  0.222577   \n",
      "4031874   322965241908588544  0.222577   \n",
      "85189591  318735395363897344  0.222577   \n",
      "17867797  861660864608256000  0.222577   \n",
      "10074121  341311672704704512  0.222577   \n",
      "59826776  711594048834764800  0.222577   \n",
      "37472162  354035249237344256  0.222577   \n",
      "51151281  549059274542837760  0.222577   \n",
      "5759722   348641755933069312  0.222577   \n",
      "5267927   485533549831811073  0.222577   \n",
      "34730502  688566200117297153  0.222577   \n",
      "84442     917031444546953217  0.222577   \n",
      "11023964  626871788346212352  0.222577   \n",
      "34246817  711616920626155520  0.222577   \n",
      "35485607  367077387168522240  0.222577   \n",
      "77660060  639937338840190976  0.222577   \n",
      "35618349  328695550432116737  0.222577   \n",
      "74930066  454861422543925249  0.222577   \n",
      "66146143  686304417616904192  0.222577   \n",
      "50972606  673559399856640000  0.222577   \n",
      "39152518  509824680962711552  0.222577   \n",
      "46439600  590895640730685442  0.222577   \n",
      "62600788  429620990289514497  0.222577   \n",
      "36861665  699689217631395840  0.222577   \n",
      "43573892  442183186504613888  0.222577   \n",
      "44569022  449545599373701120  0.222577   \n",
      "41439042  596144367506558976  0.222577   \n",
      "89030339  425153830083235840  0.222577   \n",
      "26346582  280234616181379072  0.222577   \n",
      "53228336  339195889774129152  0.222577   \n",
      "56606437  738805963642265602  0.222577   \n",
      "25947631  702997395282468864  0.222577   \n",
      "2586574   381841433814384640  0.222577   \n",
      "10316925  492484979562000384  0.222577   \n",
      "20285534  486575490325442560  0.222577   \n",
      "78473303  368105046237388801  0.222577   \n",
      "18718930  379768755397869568  0.222577   \n",
      "44721911  485276820598960129  0.222577   \n",
      "76096989  803925053733646336  0.222577   \n",
      "88983216  759268189964496896  0.222577   \n",
      "14710304  359325897947496448  0.222577   \n",
      "20673332  645653659540398081  0.222577   \n",
      "67982583  764315351526105088  0.222577   \n",
      "57879805  397864618527182848  0.222577   \n",
      "\n",
      "                                                       text  \n",
      "64850143                  @madison_mares @renzootero11 here  \n",
      "60239803                            @LadyHikari07 2:10 here  \n",
      "13860198                              @BKuzan we're here üëäüèæ  \n",
      "51121510                                 @MariMvri I'm here  \n",
      "67842310                             @norrinhester i'm here  \n",
      "71737331                             @blamenipples I'm here  \n",
      "37701024                   @realJovonnie Houston,Texas here  \n",
      "4031874      http://t.co/Z9FaiQevvQ \\nOr here @JulianJones_  \n",
      "85189591                              $AAPL reentering here  \n",
      "17867797  @brunelldonald @realDonaldTrump Here Here!!! üëå...  \n",
      "10074121                            @voicemaster01 I'm here  \n",
      "59826776                             @_GrapeJuice_ I'm here  \n",
      "37472162                                  @jano2l 8:32 here  \n",
      "51151281  @legsrjust4show wooWWWW HERE https://t.co/tqCY...  \n",
      "5759722                                       otp; i'm here  \n",
      "5267927                                @jazy_beLLa I'm here  \n",
      "34730502                                @bradbudke I'm here  \n",
      "84442                            @JardinM1 @CSGOEmpire Here  \n",
      "11023964  They're HERE.....really here #unmannedvehicle\\...  \n",
      "34246817                      @ryvrleiscute @_meggie10 HERE  \n",
      "35485607                            @GoBringMeFood I'm here  \n",
      "77660060                        @HackieJagan someone's here  \n",
      "35618349                         @MattStreeter21 she's here  \n",
      "74930066                           @The_MaggieMae out, here  \n",
      "66146143                   @wydgrey grey,,,,pls,,,,not here  \n",
      "50972606                          @thereanApp4that I'm here  \n",
      "39152518                             @blakeecarter I'm here  \n",
      "46439600                   @TenderlyMoreno_ isn't here üíîüíîüíîüòî  \n",
      "62600788                       @bpbullock22 I'm here nowüòä‚ù§Ô∏è  \n",
      "36861665                            @NolimitSeries I'm here  \n",
      "43573892                      @CalcoteJoshua I'm here bro!!  \n",
      "44569022                            @BlueeCocainee I'm here  \n",
      "41439042                      @asiamonique_ sameeee here üôåüèæ  \n",
      "89030339                  @KalieDickasonn I'm here tooooooo  \n",
      "26346582                                @_kingneal I'm here  \n",
      "53228336                               @jennnaa_BUGG üéÇ here  \n",
      "56606437                                @sikeher i'm here üòõ  \n",
      "25947631                                @DJxINK I'm here :)  \n",
      "2586574                                 @aratris 11/30 here  \n",
      "10316925                          It's pouringgggg here ‚òî‚ö°‚òÅ  \n",
      "20285534                            @elektricastar I'm here  \n",
      "78473303                   @NicoleeVeee I'm here already.:)  \n",
      "18718930                           @LandOf_Misfits I'M HERE  \n",
      "44721911                            @JennaLongmuir I'm here  \n",
      "76096989                          @CharityCr1TiKaL 3am here  \n",
      "88983216                                 @_jonesss I'm here  \n",
      "14710304                          @Lou__Dawg I'm here now!!  \n",
      "20673332    @notalphaa @Valcyon here http://t.co/tGOvUWTNYP  \n",
      "67982583                            @Sean_PA I'm here punk.  \n",
      "57879805                               @RayaJean I'm here üôå  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to dump: 3.6084368228912354 seconds\n",
      "\n",
      "\n",
      " job_search\n",
      "dhaval time taken to load random sample: 79.00391340255737 seconds (45403146, 2)\n",
      "sam time taken to load random sample: 76.98716473579407 seconds (46139942, 2)\n",
      "concat: 1.1033446788787842 seconds\n",
      "drop columns: 0.6489970684051514 seconds\n",
      "time taken to merge: 93.70298218727112 seconds (91543088, 3)\n",
      "drop dup: 124.26292729377747 seconds (84063455, 3)\n",
      "sort: 63.569708824157715 seconds (84063455, 3)\n",
      "top 10M truncate: 4.127707242965698 seconds (84063455, 3)\n",
      "                     tweet_id     proba  \\\n",
      "34197908   900651169118400512  0.206155   \n",
      "40756034   603191989656526849  0.206155   \n",
      "78032596   728501531633319937  0.206155   \n",
      "79711005   725808905717043200  0.206155   \n",
      "25895934   743196049246826497  0.206155   \n",
      "14888869   656264698816393216  0.206155   \n",
      "46285190   518963092168773632  0.206155   \n",
      "34105429   647181086330503169  0.206155   \n",
      "12277609   639277361079435264  0.206155   \n",
      "37040356   779216501249236992  0.206155   \n",
      "70057006  1004568217400950784  0.206155   \n",
      "73062165   351541223644864512  0.206155   \n",
      "41100359   361999695679205376  0.206155   \n",
      "31992898   727482831560163328  0.206155   \n",
      "51975258   732885485165682688  0.206155   \n",
      "64028639   771954919402250240  0.206155   \n",
      "71868377   597492601336369153  0.206154   \n",
      "40475302   413022367879675904  0.206154   \n",
      "73998572   566980482781310976  0.206154   \n",
      "39234342   763099476965875712  0.206154   \n",
      "3424060    526896677039652864  0.206154   \n",
      "37377923   796330196903268352  0.206154   \n",
      "3312454    557622029940424704  0.206154   \n",
      "62170852   347048163464593408  0.206154   \n",
      "41188099   613411029326757888  0.206154   \n",
      "36853043   691406951968808961  0.206154   \n",
      "91462036   750783113320501248  0.206154   \n",
      "49277149   613704404370329601  0.206154   \n",
      "36678375   286493310569304066  0.206154   \n",
      "14934409   743960872142405632  0.206154   \n",
      "40187544   747246303868923905  0.206154   \n",
      "26773682   387724271956418561  0.206154   \n",
      "38090818   319665478077386753  0.206154   \n",
      "73574706   343901609400627200  0.206154   \n",
      "79002493   485578806527160320  0.206154   \n",
      "52780708   409885170750070784  0.206154   \n",
      "33807880   531647455868502017  0.206154   \n",
      "90979282   570241755192254467  0.206154   \n",
      "91033884   391989472658591744  0.206153   \n",
      "79724338   738606679365816320  0.206153   \n",
      "65541464   892860522047123457  0.206153   \n",
      "3031659    774425150733316096  0.206153   \n",
      "63531076  1046728883079458817  0.206153   \n",
      "30847334   603639152437960704  0.206153   \n",
      "84829590   783785050429132800  0.206153   \n",
      "88203504   421330189344194560  0.206153   \n",
      "13347310   672458227246866433  0.206153   \n",
      "45478991   434022799129477120  0.206153   \n",
      "27620135   367848455340699648  0.206153   \n",
      "81201074   570422802261667840  0.206153   \n",
      "\n",
      "                                                       text  \n",
      "34197908  what's up with these weird annoying youtubers?...  \n",
      "40756034  @livingRastafari @Radio1045 @c_scaffo @katrina...  \n",
      "78032596  RT @ShopInfinityCo: Joggers üî•üî• available now. ...  \n",
      "79711005  RT @ShopInfinityCo: Joggers üî•üî• available now. ...  \n",
      "25895934  RT @ShopOmegaCo: Joggers üî•üî• available now. htt...  \n",
      "14888869  I like this intro graphic that's like \"let's r...  \n",
      "46285190                  Get out the brooms #Royals #Sweep  \n",
      "34105429  VA|BESPOKE Intel: Moschino RTW Spring 2016 htt...  \n",
      "12277609  http://t.co/6e4NZ0i18U Spiderman Foamposite Si...  \n",
      "37040356  #seoexpert #smallbusiness 5 Guidelines for Soc...  \n",
      "70057006                                 Get out the brooms  \n",
      "73062165                  Get out the brooms Baltimore!!!!!  \n",
      "41100359  Ar slayer looking for a team @ShawnAbner @MLGF...  \n",
      "31992898  RT @ShopInfinityCo: Joggers üî•üî• available now. ...  \n",
      "51975258  RT @ShopOmegaCo: Joggers üî•üî• available now. htt...  \n",
      "64028639  #jobs4u #jobs Center Recreation and Life Skill...  \n",
      "71868377  NOAH'S BUILDIN AN ARK ON THIS COURT!! #sportsball  \n",
      "40475302              RT @_ILikeNoodles_: Just rlly ill rn.  \n",
      "73998572  Hope found here #passiton http://t.co/RapoAcvv...  \n",
      "39234342  I try to put 2+2 together and get 0 bc I be ex...  \n",
      "3424060        RT @korleekee: I am just ready to let looseüòà  \n",
      "37377923  I will keep doing the good work #InPrayers htt...  \n",
      "3312454   Willing to pay someone to do my business plan ...  \n",
      "62170852  @Champaign_Room enough with these charity case...  \n",
      "41188099  CSU faculty and staff in a think-pair-share di...  \n",
      "36853043                  @dabigfella aye pls check your dm  \n",
      "91462036  Brandon Aaron Gibbs @BrandonAGibbs https://t.c...  \n",
      "49277149                      I want you but do you want me  \n",
      "36678375                           Hmm I must've been tired  \n",
      "14934409    Oh thanks I had no idea https://t.co/nQS6j4jTqO  \n",
      "40187544                 Or Abused  https://t.co/Qn2hkgk2Zj  \n",
      "26773682                  WHY ISN'T OUR SETUP MAN PITCHING?  \n",
      "38090818  Just went an un following spree... if you want...  \n",
      "73574706  Anyone selling their kenny chesney tickets? Fr...  \n",
      "79002493  Roof top puffin on a backweezy http://t.co/eLy...  \n",
      "52780708  RT @kaljacks: Ever get those days where yah ju...  \n",
      "33807880  When you want to a specific person but the nev...  \n",
      "90979282  @proverbsofdro @247Sports @amsyv try one i sen...  \n",
      "91033884  One Lowes coupon 10% OFF UPTO $1,0000 ORDER Ex...  \n",
      "79724338  Couldn't be more happy I got to see that DJ AM...  \n",
      "65541464  RT @violetblue: @ScreamingByte As someone who ...  \n",
      "3031659   @casey1771 @GoldenSince1987 HECK!!!! IVE BEEN ...  \n",
      "63531076                  \"go 'head\" \\n\"HELP IVE BEEN SHOT\"  \n",
      "30847334  @StevenMcCaig @kyle_harlan @QuesoRepublic ive ...  \n",
      "84829590  Now hiring for: Relocation Manger in Richmond,...  \n",
      "88203504  Car fixed. Elevator working. Laundry started. ...  \n",
      "13347310  RT @stwissmann: #GSD Peggy #Downey #CA #Emerge...  \n",
      "45478991         @viva_lawhitegrl come on Felicia...I'm not  \n",
      "27620135                                   awk reunion lolz  \n",
      "81201074  Most of the time, I cry thinking about social ...  \n",
      "time taken to dump: 3.5523135662078857 seconds\n",
      "\n",
      "\n",
      " is_hired_1mo\n",
      "dhaval time taken to load random sample: 79.4340136051178 seconds (45403146, 2)\n",
      "sam time taken to load random sample: 78.71965622901917 seconds (46139942, 2)\n",
      "concat: 1.1394157409667969 seconds\n",
      "drop columns: 0.6539552211761475 seconds\n",
      "time taken to merge: 92.5326361656189 seconds (91543088, 3)\n",
      "drop dup: 123.81565570831299 seconds (84063455, 3)\n",
      "sort: 63.32800269126892 seconds (84063455, 3)\n",
      "top 10M truncate: 4.472942352294922 seconds (84063455, 3)\n",
      "                     tweet_id     proba  \\\n",
      "62204028   504104472394883072  0.259382   \n",
      "4510075    788033649623040000  0.259382   \n",
      "32473464   606415408472670208  0.259382   \n",
      "62284617   570649890440617984  0.259382   \n",
      "69146332   614365661301743616  0.259382   \n",
      "61629577   512627176709959680  0.259382   \n",
      "60731379   652885956270419969  0.259381   \n",
      "21743123   654625468495196160  0.259381   \n",
      "61078260   565350823627350016  0.259381   \n",
      "70926432   656438519435542528  0.259381   \n",
      "73359952   793917914437001216  0.259381   \n",
      "59867386   283822910693576704  0.259381   \n",
      "71618478  1017743365113372672  0.259381   \n",
      "62769245   363472601055641600  0.259381   \n",
      "1341513    734621742816169985  0.259381   \n",
      "7324337    831183483066339328  0.259381   \n",
      "49435530   717449565880848384  0.259381   \n",
      "79549945   647352444821737472  0.259381   \n",
      "44348252   696039199741448195  0.259381   \n",
      "16557733   617234523625893888  0.259381   \n",
      "85878774   369938699481788416  0.259381   \n",
      "20389724   674861051846901760  0.259381   \n",
      "10823972   462362977128419328  0.259381   \n",
      "19621704   353513511437082624  0.259381   \n",
      "10418687   643142248444624896  0.259381   \n",
      "66800761   399640532928200704  0.259381   \n",
      "43620593   585955312575717377  0.259380   \n",
      "13552404   670621176759128064  0.259380   \n",
      "77644621   623170524709961728  0.259380   \n",
      "16394093   384866487129104384  0.259380   \n",
      "4034623    326884361586765824  0.259380   \n",
      "4167092    609524461449162752  0.259380   \n",
      "54993191   528719085350440960  0.259380   \n",
      "40006434   741654122257129476  0.259380   \n",
      "76445158   383000198307676160  0.259380   \n",
      "68862962   683968743605702656  0.259380   \n",
      "5725203    602198656800854016  0.259380   \n",
      "61558412   598923408605368321  0.259380   \n",
      "6345716    319636797212741635  0.259380   \n",
      "53162436   354350396480815104  0.259380   \n",
      "196672     457594607090819072  0.259380   \n",
      "18182059   749088823905120256  0.259380   \n",
      "72980091   600777676622843906  0.259380   \n",
      "81076299   772949762303819781  0.259380   \n",
      "42918256   686253993769734145  0.259379   \n",
      "80175060   583967875075076096  0.259379   \n",
      "52364686   791780324871180288  0.259379   \n",
      "31745274   762423275502784512  0.259379   \n",
      "89983424   724734107041681408  0.259379   \n",
      "33770016   359818980418007040  0.259379   \n",
      "\n",
      "                                                       text  \n",
      "62204028                  I feel the lows before the highs.  \n",
      "4510075   Our Black and White Farmhouse Buckets are feat...  \n",
      "32473464  What was the third thing...? #tooeasy https://...  \n",
      "62284617  Check out the new plasma table at @perrytechya...  \n",
      "69146332                  Really enjoying @bestposture. #FF  \n",
      "61629577                          @Nikkikins91 THANKS NIKKI  \n",
      "60731379  That was un-called for !!! http://t.co/6fNz9fnQZP  \n",
      "21743123                        @NicoleBresner thanks Nikki  \n",
      "61078260                           @misnikki72 thanks Nikki  \n",
      "70926432  RT @KGtheArTist: #Follow me on #Instagram @ KG...  \n",
      "73359952  RT @sinderbrand: Elsewhere on the trail today:...  \n",
      "59867386  The \"other\" Williams in the year-end ASN 100 f...  \n",
      "71618478                                     chirp chirp üòÇüòÇ  \n",
      "62769245                              But I feel good now üòÑ  \n",
      "1341513   RT @DopeEthiopian: By 10th/11th grade, I was b...  \n",
      "7324337                                         Chirp chirp  \n",
      "49435530                            chirp chirp üê§ #1stTweet  \n",
      "79549945                   Chirp chirp #ALDUBPreparationDay  \n",
      "44348252  chirp chirp #EsuranceSweepstakes     https://t...  \n",
      "16557733  RT @poutycheeks: 3 days till I hibernate mysel...  \n",
      "85878774  ETL Developer - Herndon, VA http://t.co/u4uwrw...  \n",
      "20389724  Wonderful for @BryantMcGill    https://t.co/BH...  \n",
      "10823972    I still haven't seen any new yawkers at consol.  \n",
      "19621704                                   So freaking hott  \n",
      "10418687  Shitty offense and penalties are killing the #...  \n",
      "66800761                            @christyshinn thx crust  \n",
      "43620593                                         Wavey gang  \n",
      "13552404  @RealJamesWoods read up on the  Carr brothers ...  \n",
      "77644621  RT @Lumin0via: reuploading bc its a lil dark. ...  \n",
      "16394093  Is it October yet? For a lager this is pretty ...  \n",
      "4034623   @Emporatti Point taken. LMFAO. I can't even be...  \n",
      "4167092   Happy Friday!! http://t.co/GBqlux05Dr#leticaba...  \n",
      "54993191  CreateSpace http://t.co/bzL90OCWDd  BookLaunch...  \n",
      "40006434  RT @Gerald_AWO: At @VamptVo's animation panel ...  \n",
      "76445158  Thank goodness I have done my Project Euler ho...  \n",
      "68862962  Starting off the first day back with 4 hours o...  \n",
      "5725203   RT @JackJackJohnson: Check out the humble boys...  \n",
      "61558412  Skype for Business Server 2015: What‚Äôs New htt...  \n",
      "6345716                        Celtics are in the playoffs!  \n",
      "53162436   @OptimisstPrime A factory job cleaning equipment  \n",
      "196672    Grand Opening at SLIVR. Love that building and...  \n",
      "18182059   RT @BLXCKAMIR: 2016 has been great. God is good.  \n",
      "72980091  #BlackFriday Dolce by Mojo Moxy Stardust Open ...  \n",
      "81076299  #NYPDDCPI @ West Indian Day Parade Grand Army ...  \n",
      "42918256  Madeline on coffee? #Madeline  #sarcasm  https...  \n",
      "80175060  @DrMonaOdom Happy Good Friday to you. http://t...  \n",
      "52364686  Trying #vegemite for the first time #australia...  \n",
      "31745274  Bad day to be the #NFL and @nflcommish! #FireG...  \n",
      "89983424                        Workaholics is a great show  \n",
      "33770016                       Pleased b-day Kendall Schmit  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to dump: 3.8029568195343018 seconds\n",
      "\n",
      "\n",
      " job_offer\n",
      "dhaval time taken to load random sample: 79.67919206619263 seconds (45403146, 2)\n",
      "sam time taken to load random sample: 82.5118670463562 seconds (46139942, 2)\n",
      "concat: 1.2263267040252686 seconds\n",
      "drop columns: 0.665715217590332 seconds\n",
      "time taken to merge: 94.20846009254456 seconds (91543088, 3)\n",
      "drop dup: 125.87841057777405 seconds (84063455, 3)\n",
      "sort: 62.68632531166077 seconds (84063455, 3)\n",
      "top 10M truncate: 3.8062336444854736 seconds (84063455, 3)\n",
      "                     tweet_id     proba  \\\n",
      "69711976   560282535587237888  0.369386   \n",
      "61720049   644322030662234112  0.369386   \n",
      "3735268    533044457164537857  0.369386   \n",
      "25730182   574340504499851264  0.369386   \n",
      "33616259   283563681474818048  0.369386   \n",
      "54097201   594118166508400640  0.369386   \n",
      "25740199   588703890285187072  0.369386   \n",
      "87331336   724981461942677504  0.369386   \n",
      "66644943   766760454307753984  0.369386   \n",
      "39713218   765915352295276544  0.369386   \n",
      "36234507   442542957246173185  0.369386   \n",
      "91131394   689243882014392321  0.369385   \n",
      "38443758   605778083971407872  0.369385   \n",
      "62350555   728602832455208961  0.369385   \n",
      "91094170   408901203871801344  0.369385   \n",
      "19899202   393190352074850304  0.369385   \n",
      "78802184   725245208359780352  0.369385   \n",
      "4564144    724889917164294144  0.369385   \n",
      "5389103    354324710479245314  0.369384   \n",
      "12808999   278737199627915264  0.369384   \n",
      "50201575   289764586855481344  0.369384   \n",
      "15607552  1016321017944379394  0.369384   \n",
      "32646545   778362209818677248  0.369384   \n",
      "23890184   932714425362006016  0.369384   \n",
      "37724044   751109098582609920  0.369384   \n",
      "2342557    350983196567011329  0.369384   \n",
      "16757084   465555866109112322  0.369384   \n",
      "77285790   527293537873055744  0.369384   \n",
      "75354612   586029799333847040  0.369384   \n",
      "32042143   693570201879650304  0.369384   \n",
      "2500636    628746700761530368  0.369384   \n",
      "70630158   628456777944797184  0.369383   \n",
      "57446359   367463518754598912  0.369383   \n",
      "19072571   523306726150643712  0.369383   \n",
      "4094395    493624013986729985  0.369383   \n",
      "69658036   539814470579912705  0.369383   \n",
      "18996254   606542118455148545  0.369383   \n",
      "31925418   635893786678296576  0.369383   \n",
      "26755553   553204522018144256  0.369383   \n",
      "19800796   711684109203087361  0.369383   \n",
      "12583768   886228241111027712  0.369383   \n",
      "41928350   333441078084644864  0.369383   \n",
      "43229431   521811490249003010  0.369383   \n",
      "70645570   645302654755807232  0.369383   \n",
      "58978153   712402157270474752  0.369383   \n",
      "74557488   575550473190703106  0.369383   \n",
      "45990301   402850861765758976  0.369383   \n",
      "66691476   344126164081729536  0.369383   \n",
      "27976723   629918392217112576  0.369382   \n",
      "51781462   348627763680382976  0.369382   \n",
      "\n",
      "                                                       text  \n",
      "69711976  @WhitneyCummings is an @eileen_davidson fan?! ...  \n",
      "61720049               @jaketapper is an asshat. #GOPDebate  \n",
      "3735268                       @NiallOfficial is an angel. üëº  \n",
      "25730182  RT @SFWebFest: Keynote inspirations for intera...  \n",
      "33616259  Want to be an Allstar? You can here! http://t....  \n",
      "54097201  Want to be an Allstar? You can here! http://t....  \n",
      "25740199  Want to be an Allstar? You can here! http://t....  \n",
      "87331336  Want to be an Allstar? You can here! https://t...  \n",
      "66644943  Kula Shaker‚Äôs Sept.-Oct. Run https://t.co/Fz59...  \n",
      "39713218         Beautiful Princess https://t.co/LmF99J8eeR  \n",
      "36234507       Beautiful princess üéÄüëë http://t.co/aDQNRzJbhc  \n",
      "91131394  RT @jimbobjoeftw: \"Tweet and retweet to win th...  \n",
      "38443758  How are you - Have a hideaway 2 houses for you...  \n",
      "62350555  Draft Environmental Assessment: Plaquemines Pa...  \n",
      "91094170  @DanMoreno_ yayyyy! üòÅ I'll text you tomorrow t...  \n",
      "19899202  What you talkin' bout: http://t.co/S7943mSXDF ...  \n",
      "78802184  RT @x_bwc: Best Lesbian Porns - https://t.co/r...  \n",
      "4564144   RT @x_bwc: Best Lesbian Porns - https://t.co/p...  \n",
      "5389103   Now Playing on Badtomato.FM Hardreams - All An...  \n",
      "12808999                    Lol snap chat me: hannahgladson  \n",
      "50201575  RT @PatrickBroder_: \"@Brittany_Teman: PB AND A...  \n",
      "15607552  Video: Designing a Wedding Arch  https://t.co/...  \n",
      "32646545  RT @climatetruth: Sources: Oil executive on #T...  \n",
      "23890184  RT @DigitalJonathan: Employees are a little bi...  \n",
      "37724044  RT @gima2327: NEW YORK, NY - JULY 06: (L-R) Mu...  \n",
      "2342557   http://t.co/6n7eAXjTZD \"Choose a job you love,...  \n",
      "16757084  @TSRNSports where is San Jac and Galveston pla...  \n",
      "77285790  RT @bergrbergr: 10-run rule! We can all go hom...  \n",
      "75354612  Stock Up and Save Event at Walmart http://t.co...  \n",
      "32042143  RT @leahjonesaw: @Amy_taboo Im doing live webc...  \n",
      "2500636   RT @HeyTammyBruce: Kitten ‚Äòsnuggler‚Äô volunteer...  \n",
      "70630158  RT @Miss_anderson6: All my clients are getting...  \n",
      "57446359                               I'd rather be honest  \n",
      "19072571  Watching the Mighty Ducks! How's your Friday n...  \n",
      "4094395   Want quick sales of your #Canada #police badge...  \n",
      "69658036          Network like a Pro http://t.co/weHVozT2lc  \n",
      "18996254  RT @FIFAWWC: .@VicMontagliani: \"This event an ...  \n",
      "31925418  Parkside Lending launches super-low down payme...  \n",
      "26755553  Thanks for #TheOneDerBeers mention @ChicagoBee...  \n",
      "19800796  RT @RadioSEGA: #RS10th: Codenamed \"Project 7\" ...  \n",
      "12583768  Microsoft Xbox 360 250GB Black Console Bundle ...  \n",
      "41928350  Elegant Gorham Full Lead Crystal Candlesticks ...  \n",
      "43229431  The Process of Installing a Trenchless Sewer i...  \n",
      "70645570  RT @Pixel__YT: Make sure to check http://t.co/...  \n",
      "58978153  A stunning renovation and architectural transf...  \n",
      "74557488  Judge OKs atheist‚Äôs ‚Äòreason station‚Äô in city h...  \n",
      "45990301  Today we are launching the #GatorNationIsEvery...  \n",
      "66691476       #DontWakeMeUpUnless it's june 11th , 8 pm !!  \n",
      "27976723  RT @UN: Apply: #UNESCOprize for individuals &a...  \n",
      "51781462  Drinking a Ranger India Pale Ale (IPA) by @new...  \n",
      "time taken to dump: 4.1581902503967285 seconds\n"
     ]
    }
   ],
   "source": [
    "# outputting 1M (pinky finger up) tweets by column\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# boundary_list = [i/20.0 for i in range(11)]\n",
    "# boundary_list.reverse()\n",
    "# print('boundary_list', boundary_list)\n",
    "\n",
    "for column in [\"is_unemployed\", \"lost_job_1mo\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "    print('\\n\\n', column)\n",
    "    \n",
    "#     if column != 'job_offer': continue\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    # model_output_path = '/scratch/da2734/twitter/jobs/running_on_200Msamples/pred_output_100M_ONNX_optimized/{}/'.format(column)\n",
    "#     print(model_output_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_random1 = pd.concat([pd.read_csv(f) for f in glob.glob(\n",
    "        '/scratch/da2734/twitter/jobs/running_on_200Msamples/iteration1/glove_inferences/glove_inferences_dhaval/{}/'.format(column)+\n",
    "        'random*.csv')], ignore_index = True)\n",
    "    print('dhaval time taken to load random sample:', str(time.time() - start_time), 'seconds', model_output_random1.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_random2 = pd.concat([pd.read_csv(f) for f in glob.glob(\n",
    "        '/scratch/da2734/twitter/jobs/running_on_200Msamples/iteration1/glove_inferences/glove_inferences_sam/{}/'.format(column)+\n",
    "        'random*.csv')], ignore_index = True)\n",
    "    print('sam time taken to load random sample:', str(time.time() - start_time), 'seconds', model_output_random2.shape)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_random = pd.concat([model_output_random1, model_output_random2])\n",
    "    print('concat:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_random = model_output_random[['tweet_id', 'proba']]\n",
    "    print('drop columns:', str(time.time() - start_time), 'seconds')    \n",
    "\n",
    "    start_time = time.time()\n",
    "    merged_random = pd.merge(model_output_random, tweets_random, how='inner', on = 'tweet_id')\n",
    "    print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "\n",
    "    # print(merged_random.head())\n",
    "\n",
    "    start_time = time.time()\n",
    "    merged_random = merged_random.drop_duplicates(['text'])\n",
    "    print('drop dup:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    merged_random = merged_random.sort_values(by=['proba'], ascending=False)\n",
    "    print('sort:', str(time.time() - start_time), 'seconds', merged_random.shape)    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    merged_random_temp = merged_random[:5000000]\n",
    "    print('top 10M truncate:', str(time.time() - start_time), 'seconds', merged_random.shape)   \n",
    "    \n",
    "    print(merged_random_temp.tail(50))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pickle.dump( merged_random_temp, open( \"./ONNXturk100M/iteration1/{}_GLOVECNN_merged_random_100m_july1.pkl\".format(column), \"wb\" ) )\n",
    "    print('time taken to dump:', str(time.time() - start_time), 'seconds')\n",
    "        \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtered top 10M files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# outputting 1M (pinky finger up) tweets by column\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# boundary_list = [i/20.0 for i in range(11)]\n",
    "# boundary_list.reverse()\n",
    "# print('boundary_list', boundary_list)\n",
    "\n",
    "for column in [\"is_unemployed\", \"lost_job_1mo\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "    print('\\n\\n', column)\n",
    "    \n",
    "#     if column == 'job_offer': continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_path = '/scratch/da2734/twitter/jobs/running_on_200Msamples/pred_output_100M_GLOVE_CNN_optimized/{}/'.format(column)\n",
    "    print(model_output_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_filtered = pd.concat([pd.read_csv(f) for f in glob.glob(model_output_path+'filtered*.csv')], ignore_index = True)\n",
    "    print('time taken to load filtered sample:', str(time.time() - start_time), 'seconds', model_output_filtered.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_filtered = model_output_filtered[['tweet_id', 'proba']]\n",
    "    print('drop columns:', str(time.time() - start_time), 'seconds')\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    merged_filtered = pd.merge(model_output_filtered, tweets_filtered, how='inner', on = 'tweet_id')\n",
    "    print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_filtered.shape)\n",
    "\n",
    "    print(merged_filtered.shape)\n",
    "\n",
    "    start_time = time.time()\n",
    "    merged_filtered = merged_filtered.drop_duplicates(['text'])\n",
    "    print('drop dup:', str(time.time() - start_time), 'seconds', merged_filtered.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    merged_filtered = merged_filtered.sort_values(by=['proba'], ascending=False)\n",
    "    print('sort:', str(time.time() - start_time), 'seconds', merged_filtered.shape)    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    merged_filtered_temp = merged_filtered[:5000000]\n",
    "    print('top 5M truncate:', str(time.time() - start_time), 'seconds', merged_filtered.shape)   \n",
    "    \n",
    "    print(merged_filtered_temp.tail(50)['text'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pickle.dump( merged_filtered_temp, open( \"./ONNXturk100M/{}_GLOVE_CNN_merged_filtered_100m_jun22.pkl\".format(column), \"wb\" ) )\n",
    "    print('time taken to dump:', str(time.time() - start_time), 'seconds')\n",
    "        \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "merged_filtered_temp = merged_filtered[5000000:12000000]\n",
    "print('top 5M truncate:', str(time.time() - start_time), 'seconds', merged_filtered.shape)   \n",
    "\n",
    "# print(merged_filtered_temp.tail(50)['text'])\n",
    "\n",
    "start_time = time.time()\n",
    "pickle.dump( merged_filtered_temp, open( \"./ONNXturk100M/{}_GLOVE_CNN_merged_filtered_100m_jun22_5_to_12M.pkl\".format(column), \"wb\" ) )\n",
    "print('time taken to dump:', str(time.time() - start_time), 'seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random top 10M files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# outputting 1M (pinky finger up) tweets by column\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# boundary_list = [i/20.0 for i in range(11)]\n",
    "# boundary_list.reverse()\n",
    "# print('boundary_list', boundary_list)\n",
    "\n",
    "for column in [\"is_unemployed\", \"lost_job_1mo\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "    print('\\n\\n', column)\n",
    "    \n",
    "    if column != 'job_offer': continue\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_path = '/scratch/da2734/twitter/jobs/running_on_200Msamples/pred_output_100M_GLOVE_CNN_optimized/{}/'.format(column)\n",
    "    print(model_output_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_random = pd.concat([pd.read_csv(f) for f in glob.glob(model_output_path+'random*.csv')], ignore_index = True)\n",
    "    print('time taken to load random sample:', str(time.time() - start_time), 'seconds', model_output_random.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_random = model_output_random[['tweet_id', 'proba']]\n",
    "    print('drop columns:', str(time.time() - start_time), 'seconds')\n",
    "    \n",
    "\n",
    "    start_time = time.time()\n",
    "    merged_random = pd.merge(model_output_random, tweets_random, how='inner', on = 'tweet_id')\n",
    "    print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "\n",
    "#     print(merged_random.head())\n",
    "\n",
    "    start_time = time.time()\n",
    "    merged_random = merged_random.drop_duplicates(['text'])\n",
    "    print('drop dup:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    merged_random = merged_random.sort_values(by=['proba'], ascending=False)\n",
    "    print('sort:', str(time.time() - start_time), 'seconds', merged_random.shape)    \n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     merged_random_temp = merged_random[:5000000]\n",
    "#     print('top 5M truncate:', str(time.time() - start_time), 'seconds', merged_random.shape)   \n",
    "    \n",
    "#     print(merged_random_temp.tail(50)['text'])\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     pickle.dump( merged_random_temp, open( \"./ONNXturk100M/{}_GLOVE_CNN_merged_random_100m_jun22.pkl\".format(column), \"wb\" ) )\n",
    "#     print('time taken to dump:', str(time.time() - start_time), 'seconds')\n",
    "        \n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputting 1M (pinky finger up) tweets by column\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for column in [\"is_unemployed\", \"lost_job_1mo\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "    print('\\n\\n', column)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_path = '/scratch/da2734/twitter/jobs/running_on_200Msamples/pred_output_100M_GLOVE_CNN_optimized/{}/'.format(column)\n",
    "    print(model_output_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_filtered = pd.concat([pd.read_csv(f) for f in glob.glob(model_output_path+'filtered*.csv')], ignore_index = True)\n",
    "    print('time taken to load filtered sample:', str(time.time() - start_time), 'seconds', model_output_filtered.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_filtered = model_output_filtered[['tweet_id', 'proba']]\n",
    "    model_output_filtered.columns = ['tweet_id', column]\n",
    "    print('drop columns:', str(time.time() - start_time), 'seconds')\n",
    "    \n",
    "\n",
    "    if column == 'is_unemployed':\n",
    "        start_time = time.time()\n",
    "        merged_filtered = pd.merge(model_output_filtered, tweets_filtered, how='inner', on = 'tweet_id')\n",
    "        print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_filtered.shape)\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        merged_filtered = pd.merge(model_output_filtered, merged_filtered, how='inner', on = 'tweet_id')\n",
    "        print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_filtered.shape)\n",
    "            \n",
    "    print(merged_filtered.tail(10))\n",
    "            \n",
    "#     break\n",
    "    \n",
    "    \n",
    "start_time = time.time()\n",
    "merged_filtered = merged_filtered.drop_duplicates(['text'])\n",
    "print('drop dup:', str(time.time() - start_time), 'seconds', merged_filtered.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "pickle.dump( merged_filtered, open( \"./ONNXturk100M/ALL_ONNX_BERT_ST_merged_filtered_100m_jun24.pkl\", \"wb\" ) )\n",
    "print('time taken to dump:', str(time.time() - start_time), 'seconds')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging random tweets into one big file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# outputting 1M (pinky finger up) tweets by column\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for column in [\"is_unemployed\", \"lost_job_1mo\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "    print('\\n\\n', column)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_path = '/scratch/da2734/twitter/jobs/running_on_200Msamples/pred_output_100M_GLOVE_CNN_optimized/{}/'.format(column)\n",
    "    print(model_output_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    model_output_random = pd.concat([pd.read_csv(f) for f in glob.glob(model_output_path+'random*.csv')], ignore_index = True)\n",
    "    print('time taken to load random sample:', str(time.time() - start_time), 'seconds', model_output_random.shape)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_output_random = model_output_random[['tweet_id', 'proba']]\n",
    "    model_output_random.columns = ['tweet_id', column]\n",
    "    print('drop columns:', str(time.time() - start_time), 'seconds')\n",
    "    \n",
    "\n",
    "    if column == 'is_unemployed':\n",
    "        start_time = time.time()\n",
    "        merged_random = pd.merge(model_output_random, tweets_random, how='inner', on = 'tweet_id')\n",
    "        print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        merged_random = pd.merge(model_output_random, merged_random, how='inner', on = 'tweet_id')\n",
    "        print('time taken to merge:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "            \n",
    "    print(merged_random.tail(10))\n",
    "            \n",
    "#     break\n",
    "    \n",
    "    \n",
    "start_time = time.time()\n",
    "merged_random = merged_random.drop_duplicates(['text'])\n",
    "print('drop dup:', str(time.time() - start_time), 'seconds', merged_random.shape)\n",
    "\n",
    "start_time = time.time()\n",
    "pickle.dump( merged_random, open( \"./ONNXturk100M/ALL_GLOVE_CNN_merged_random_100m_jun24.pkl\", \"wb\" ) )\n",
    "print('time taken to dump:', str(time.time() - start_time), 'seconds')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_random.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
