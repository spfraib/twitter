{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from glob import glob\n",
    "import json\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import psutil\n",
    "import socket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save each 1000 requests\n"
     ]
    }
   ],
   "source": [
    "n_requests=1000\n",
    "print('Save each',n_requests,'requests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/decahose/parsed/users\n",
      "../../data/keys\n",
      "../../data/users\n"
     ]
    }
   ],
   "source": [
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data = '../../data'\n",
    "else:\n",
    "    path_to_data = '/scratch/spf248/twitter/data'\n",
    "\n",
    "path_to_users = os.path.join(path_to_data,'users')\n",
    "path_to_keys = os.path.join(path_to_data,'keys','twitter')\n",
    "print(path_to_users)\n",
    "print(path_to_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLURM_JOB_ID : 0 (Default)\n",
      "SLURM_ARRAY_TASK_ID : 0 (Default)\n",
      "SLURM_ARRAY_TASK_COUNT : 1 (Default)\n",
      "SLURM_JOB_CPUS_PER_NODE : 4 (Default)\n"
     ]
    }
   ],
   "source": [
    "def get_env_var(varname,default):\n",
    "    \n",
    "    if os.environ.get(varname) != None:\n",
    "        var = int(os.environ.get(varname))\n",
    "        print(varname,':', var)\n",
    "    else:\n",
    "        var = default\n",
    "        print(varname,':', var,'(Default)')\n",
    "    return var\n",
    "\n",
    "# Choose Number of Nodes To Distribute Credentials: e.g. jobarray=0-4, cpu_per_task=20, credentials = 90 (<100)\n",
    "SLURM_JOB_ID            = get_env_var('SLURM_JOB_ID',0)\n",
    "SLURM_ARRAY_TASK_ID     = get_env_var('SLURM_ARRAY_TASK_ID',0)\n",
    "SLURM_ARRAY_TASK_COUNT  = get_env_var('SLURM_ARRAY_TASK_COUNT',1)\n",
    "SLURM_JOB_CPUS_PER_NODE = get_env_var('SLURM_JOB_CPUS_PER_NODE',mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Environment Variables: # credentials ( 49 ) > # CPU ( 4 )\n",
      "Only Keeping 4 Credentials\n",
      "../../data/keys/WorldBankGroup6-dunstan.json\n",
      "../../data/keys/spfraib_sentiments-sarah.json\n",
      "../../data/keys/WorldBankGroup6-antoine.json\n",
      "../../data/keys/spfraib_sentiments-sam6.json\n"
     ]
    }
   ],
   "source": [
    "def get_key_files(SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT,SLURM_JOB_CPUS_PER_NODE):\n",
    "\n",
    "    # Randomize set of key files using constant seed\n",
    "    np.random.seed(0)\n",
    "    all_key_files = np.random.permutation(glob(os.path.join(path_to_keys,'*.json')))\n",
    "    \n",
    "    # Split file list by node\n",
    "    key_files = np.array_split(all_key_files,SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]\n",
    "    \n",
    "    # Check that node has more CPU than key file \n",
    "    if len(key_files) <= SLURM_JOB_CPUS_PER_NODE:\n",
    "        print('# Credentials Allocated To Node:', len(key_files)) \n",
    "    else:\n",
    "        print('Check Environment Variables: # credentials (',len(key_files),') > # CPU (', SLURM_JOB_CPUS_PER_NODE,')')\n",
    "        print('Only Keeping', SLURM_JOB_CPUS_PER_NODE, 'Credentials')\n",
    "        key_files = key_files[:SLURM_JOB_CPUS_PER_NODE]\n",
    "        \n",
    "    return key_files\n",
    "\n",
    "key_files = get_key_files(SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT,SLURM_JOB_CPUS_PER_NODE)\n",
    "print('\\n'.join(key_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials Checked!\n"
     ]
    }
   ],
   "source": [
    "def get_auth(key_file):\n",
    "    \n",
    "    # Import Key\n",
    "    with open(key_file) as f:\n",
    "        key = json.load(f)\n",
    "\n",
    "    # OAuth process, using the keys and tokens\n",
    "    auth = tweepy.OAuthHandler(key['consumer_key'], key['consumer_secret'])\n",
    "    auth.set_access_token(key['access_token'], key['access_token_secret'])\n",
    "\n",
    "    # Creation of the actual interface, using authentication\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "#         print(key_file,\": Authentication OK\")\n",
    "    except:\n",
    "        print(key_file,\": error during authentication\")\n",
    "        sys.exit('Exit')\n",
    "    \n",
    "    return api\n",
    "\n",
    "for key_file in np.random.permutation(glob(os.path.join(path_to_keys,'*.json'))):\n",
    "    get_auth(key_file)\n",
    "print('Credentials Checked!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Users...\n",
      "# Users: 1937\n",
      "First User Id: 322020836\n",
      "Node\"s # Users: 1937\n",
      "Node\"s First User Id: 322020836\n",
      "Computing Time: 249 sec\n"
     ]
    }
   ],
   "source": [
    "def get_users(SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT):\n",
    "    \n",
    "    # Import Users\n",
    "    users_by_account_location = pd.read_json(\n",
    "    glob(os.path.join(path_to_users,'user-ids-by-account-location','*json'))[0],lines=True)\n",
    "    \n",
    "    all_users = list(itertools.chain.from_iterable(users_by_account_location['user_id']))\n",
    "\n",
    "    # Randomize All Users\n",
    "    np.random.seed(0)\n",
    "    all_users=np.random.permutation(all_users)\n",
    "    \n",
    "    print('# Users:', len(all_users))\n",
    "    print('First User Id:', all_users[0])\n",
    "    \n",
    "    # Split users by node\n",
    "    users=np.array_split(all_users,SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID].copy()\n",
    "    print('Node\"s # Users:', len(users))\n",
    "    print('Node\"s First User Id:', users[0])\n",
    "    \n",
    "    return users\n",
    "    \n",
    "start = timer()\n",
    "print('Import Users...')\n",
    "\n",
    "users = get_users(SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT)\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Existing Users Profile\n"
     ]
    }
   ],
   "source": [
    "print('Import Existing Users Profile')\n",
    "l = []\n",
    "for filename in sorted(glob(os.path.join(path_to_users,'users-profile/*.json'))):\n",
    "    try:\n",
    "        df = pd.read_json(filename,lines=True,dtype=False)\n",
    "        l.append(df)\n",
    "    except:\n",
    "        print('error importing', filename)\n",
    "existing_users = pd.concat(l, axis=0, ignore_index=True)['id_str'].drop_duplicates().tolist()\n",
    "print('# Existing Users:', len(existing_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Remaining Users: 1936\n"
     ]
    }
   ],
   "source": [
    "users=list(set(users).difference(existing_users))\n",
    "print('# Remaining Users:', len(users))\n",
    "\n",
    "# Randomize Changing Order Each Run\n",
    "np.random.seed()\n",
    "users=np.random.permutation(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup users by chunks of size 100\n",
    "def lookup_users(user_ids, api):\n",
    "    if len(user_ids)>100:\n",
    "        print('Reduce # Users')\n",
    "        return []\n",
    "    try:\n",
    "        lookups=api.lookup_users(user_ids=list(user_ids),include_entities='true',tweet_mode='extended')\n",
    "        return [lookup._json for lookup in lookups]\n",
    "    except tweepy.error.TweepError as e:\n",
    "        print('Lookup error', e)\n",
    "        return []\n",
    "    \n",
    "# lookups=lookup_users(users[:100], get_auth(key_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_users_by_block(index_key):\n",
    "    \n",
    "    # Create Access For Block of Users\n",
    "    api=get_auth(key_files[index_key])\n",
    "    \n",
    "    # Select Block of Users\n",
    "    users_block=np.array_split(users,len(key_files))[index_key]\n",
    "    \n",
    "    # Split further by chunks of size 100 to accomodate Twitter lookup limit\n",
    "    users_chunks=list(chunks(users_block,100))\n",
    "    \n",
    "    lookups=[]\n",
    "    \n",
    "    # Initialize Output File ID\n",
    "    output_id = str(uuid.uuid4())\n",
    "    \n",
    "    for i,users_chunk in enumerate(users_chunks):\n",
    "        \n",
    "        # Loop users by chunk of size 100\n",
    "        lookups.extend(lookup_users(users_chunk,api))\n",
    "        \n",
    "        # Save Lookups Each 100 Chunks\n",
    "        if (i and not i%n_requests) or i==len(users_chunks)-1:\n",
    "            \n",
    "            print('Process', index_key, 'saving lookups with output id', output_id)\n",
    "        \n",
    "            # Save to Json\n",
    "            filename = \\\n",
    "            'users-'+\\\n",
    "            str(SLURM_JOB_ID)+'-'+\\\n",
    "            str(SLURM_ARRAY_TASK_ID)+'-'+\\\n",
    "            str(index_key)+'-'+\\\n",
    "            output_id+'.json'\n",
    "            with open(os.path.join(path_to_users,filename),'w') as f:\n",
    "                json.dump(lookups,f)\n",
    "\n",
    "            # Reset\n",
    "            output_id = str(uuid.uuid4())\n",
    "            lookups=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookup Users...\n",
      "\n",
      "Process 3 saving lookups with output id ae576c5e-9437-4b67-8cd4-b58854191396\n",
      "Process 0 saving lookups with output id fc44a8da-9b13-4d34-b9be-17849ba8f4db\n",
      "Process 2 saving lookups with output id e18b820f-8043-4b34-aa9d-fdb5f6b46d25\n",
      "Process 1 saving lookups with output id 5ab92913-952d-47e6-afb4-c5892a140ab2\n",
      "Process 3 saving lookups with output id 9a30f644-ce27-4cf1-a590-1be722a96a61\n",
      "Process 0 saving lookups with output id 36f36e4a-8953-48cb-817d-2409923c148c\n",
      "Process 1 saving lookups with output id 155f7878-ad17-447e-892b-e14084a94144\n",
      "Process 3 saving lookups with output id 8fc2bbf8-0488-4768-aa81-16db5b7faddd\n",
      "Process 2 saving lookups with output id e2970c27-5847-43d2-94ce-6c9b06abad9e\n",
      "Process 0 saving lookups with output id 5edac3db-073c-4009-b78c-2f4a12ef7961\n",
      "Process 1 saving lookups with output id 119c3e48-fec4-454b-a6f0-f349111340d8\n",
      "Process 2 saving lookups with output id 237c888a-5c69-4343-ba51-f3ee5acb6bd0\n",
      "Computing Time: 16 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Lookup Users...\\n')\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    \n",
    "    pool.map(lookup_users_by_block, range(len(key_files)))\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
