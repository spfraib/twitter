{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession.builder.appName(\"\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data = '../../data'\n",
    "else:\n",
    "    path_to_data = '/user/spf248/twitter/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to data: ../../data\n",
      "Country: US\n"
     ]
    }
   ],
   "source": [
    "print('Path to data:',path_to_data) \n",
    "country_code = \"US\"\n",
    "print('Country:', country_code)\n",
    "iterations=range(2)\n",
    "models=['GLOVE','BERT']\n",
    "labels=['is_hired_1mo', 'is_unemployed', 'job_offer', 'job_search', 'lost_job_1mo']\n",
    "keywords=['fired', 'hired', 'job', 'laid_off', 'position', 'quit', 'unemployed', 'work']\n",
    "targets=[\n",
    "'target_anyone_hiring',\n",
    "'target_here_is_a_job_opportunity_you_might_be_interested_in',\n",
    "'target_i_am_currently_not_working',\n",
    "'target_i_am_searching_for_a_new_position',\n",
    "'target_i_got_hired_today',\n",
    "'target_i_lost_my_job_today',\n",
    "'target_i_recently_started_working_at_my_new_job',\n",
    "'target_i_was_fired_earlier_this_week',\n",
    "'target_looking_for_a_new_position',\n",
    "'target_now_i_am_unemployed']\n",
    "\n",
    "base_rates=[\n",
    "1.7342911457049017e-05,\n",
    "0.0003534645020523677,\n",
    "0.005604641971672389,\n",
    "0.00015839552996469054,\n",
    "1.455338466552472e-05]\n",
    "N_random=92114009\n",
    "base_ranks=[int(x*N_random) for x in base_rates]\n",
    "label2rank=dict(zip(labels,base_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tweets = spark.read.parquet(os.path.join(path_to_data,'classification',country_code,'random-scored'))\n",
    "df = random_tweets.select('tweet_id','text')\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in iterations:\n",
    "    print()\n",
    "    print('********* Iteration:',iteration,'*********')\n",
    "    for model in models:\n",
    "        print()\n",
    "        print('****** Model:',model,'******')\n",
    "        for label in labels:\n",
    "            print('*** Label:',label,'***')\n",
    "            predictions=spark.read.option(\"header\", \"true\").csv(os.path.join(path_to_data,'classification',country_code,'predictions','iteration_'+str(iteration),model,label,'random*'))\n",
    "            tmp=predictions.withColumnRenamed('proba','score').withColumnRenamed('second','score').select('tweet_id','score')\n",
    "            tmp=tmp.withColumn('score',F.col('score').cast('float'))\n",
    "            tmp=tmp.join(df,on='tweet_id')\n",
    "            tmp=tmp.where(~tmp.text.contains('RT @'))\n",
    "            tmp=tmp.sort(F.col(\"score\").desc()).limit(label2rank[label])\n",
    "            sample_top_tweets=tmp.sample(False, 110/label2rank[label], seed=0)\n",
    "            sample_top_tweets.coalesce(1).write.mode(\"ovserwrite\").parquet(os.path.join(path_to_data,'classification',country_code,'sample_top_tweets','iteration_'+str(iteration),model,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Iteration: 0 *********\n",
      "\n",
      "****** Model: GLOVE ******\n",
      "*** Label: is_hired_1mo ***\n",
      "*** Label: is_unemployed ***\n",
      "*** Label: job_offer ***\n",
      "*** Label: job_search ***\n",
      "*** Label: lost_job_1mo ***\n",
      "\n",
      "****** Model: BERT ******\n",
      "*** Label: is_hired_1mo ***\n",
      "*** Label: is_unemployed ***\n",
      "*** Label: job_offer ***\n",
      "*** Label: job_search ***\n",
      "*** Label: lost_job_1mo ***\n",
      "\n",
      "********* Iteration: 1 *********\n",
      "\n",
      "****** Model: GLOVE ******\n",
      "*** Label: is_hired_1mo ***\n",
      "*** Label: is_unemployed ***\n",
      "*** Label: job_offer ***\n",
      "*** Label: job_search ***\n",
      "*** Label: lost_job_1mo ***\n",
      "\n",
      "****** Model: BERT ******\n",
      "*** Label: is_hired_1mo ***\n",
      "*** Label: is_unemployed ***\n",
      "*** Label: job_offer ***\n",
      "*** Label: job_search ***\n",
      "*** Label: lost_job_1mo ***\n"
     ]
    }
   ],
   "source": [
    "for iteration in iterations:\n",
    "    print()\n",
    "    print('********* Iteration:',iteration,'*********')\n",
    "    for model in models:\n",
    "        print()\n",
    "        print('****** Model:',model,'******')\n",
    "        for label in labels:\n",
    "            print('*** Label:',label,'***')\n",
    "            df=spark.read.parquet(os.path.join(path_to_data,'classification',country_code,'sample_top_tweets','iteration_'+str(iteration),model,label)).toPandas()\n",
    "            filename='high_scored_tweets_iteration'+str(iteration)+'_'+model+'_'+label+'.pkl'\n",
    "            df.to_pickle(os.path.join(path_to_data,'classification',country_code,'labeling',str(iteration),'sampled','evalproc',filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
