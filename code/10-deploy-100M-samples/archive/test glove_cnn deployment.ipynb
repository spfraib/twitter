{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/share/apps/anaconda3/2019.10/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/share/apps/anaconda3/2019.10/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/anaconda3/2019.10/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/anaconda3/2019.10/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29bf166010ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/share/apps/anaconda3/2019.10/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/share/apps/anaconda3/2019.10/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /lib64/libm.so.6: version `GLIBC_2.23' not found (required by /scratch/da2734/pyenv_dval_wb_twitter/py3.7/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data_utils as utils\n",
    "\n",
    "from tensorflow.contrib import learn\n",
    "# from text_cnn import TextCNN\n",
    "# from data_utils import IMDBDataset\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     34,
     41,
     99
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# run using: sbatch --array=0-9 7.9-get-predictions-from-BERT.sh\n",
    "\n",
    "print('started 10.3-ONNX-BERT-deploying-100M_random_ONLY.py')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertConfig, BertTokenizer, BertTokenizerFast, BertForSequenceClassification\n",
    "import onnxruntime as ort\n",
    "from onnxruntime_tools import optimizer\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from convert_graph_to_onnx import convert\n",
    "import os\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import onnx\n",
    "from quantize import quantize, QuantizationMode\n",
    "print('libs loaded')\n",
    "\n",
    "# column = sys.argv[1]\n",
    "# column = 'is_unemployed'\n",
    "\n",
    "\n",
    "root_path='/scratch/da2734/twitter/jobs/running_on_200Msamples/'\n",
    "\n",
    "####################################################################################################################################\n",
    "# HELPER FUNCTIONS\n",
    "####################################################################################################################################\n",
    "\n",
    "# inference\n",
    "def get_tokens(tokens_dict, i):\n",
    "    i_tokens_dict = dict()\n",
    "    for key in ['input_ids','token_type_ids','attention_mask']:\n",
    "        i_tokens_dict[key] = tokens_dict[key][i]\n",
    "    tokens = {name: np.atleast_2d(value) for name, value in i_tokens_dict.items()}\n",
    "    return tokens\n",
    "\n",
    "def inference(onnx_model, model_dir, examples, fast_tokenizer, num_threads):\n",
    "    quantized_str = ''\n",
    "    if 'quantized' in onnx_model:\n",
    "        quantized_str = 'quantized'\n",
    "    onnx_inference = []\n",
    "#     pytorch_inference = []\n",
    "    # onnx session\n",
    "    options = ort.SessionOptions()\n",
    "    options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "    options.intra_op_num_threads = 1\n",
    "    print(onnx_model)\n",
    "    ort_session = ort.InferenceSession(onnx_model, options)\n",
    "\n",
    "    # pytorch pretrained model and tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(model_dir)\n",
    "    tokenizer_str = \"BertTokenizerFast\"\n",
    "\n",
    "    print(\"**************** {} ONNX inference with batch tokenization and with {} tokenizer****************\".format(quantized_str, tokenizer_str))\n",
    "    start_onnx_inference_batch = time.time()\n",
    "    start_batch_tokenization = time.time()\n",
    "    tokens_dict = tokenizer.batch_encode_plus(examples, max_length=128)\n",
    "    total_batch_tokenization_time = time.time() - start_batch_tokenization\n",
    "    total_inference_time = 0\n",
    "    total_build_label_time = 0\n",
    "    for i in range(len(examples)):\n",
    "        \"\"\"\n",
    "        Onnx inference with batch tokenization\n",
    "        \"\"\"\n",
    "        \n",
    "        if i%100 == 0: \n",
    "            print('[inference... ]', i, 'out of ', len(examples))\n",
    "        \n",
    "        tokens = get_tokens(tokens_dict, i)\n",
    "        #inference\n",
    "        start_inference = time.time()\n",
    "        ort_outs = ort_session.run(None, tokens)\n",
    "        total_inference_time = total_inference_time + (time.time() - start_inference)\n",
    "        #build label\n",
    "        start_build_label = time.time()\n",
    "        torch_onnx_output = torch.tensor(ort_outs[0], dtype=torch.float32)\n",
    "        onnx_logits = F.softmax(torch_onnx_output, dim=1)\n",
    "        logits_label = torch.argmax(onnx_logits, dim=1)\n",
    "        label = logits_label.detach().cpu().numpy()\n",
    "#         onnx_inference.append(label[0])\n",
    "        onnx_inference.append( onnx_logits.detach().cpu().numpy()[0].tolist() )\n",
    "        total_build_label_time = total_build_label_time + (time.time() - start_build_label)\n",
    "#         print(i, label[0], onnx_logits.detach().cpu().numpy()[0].tolist(), type(onnx_logits.detach().cpu().numpy()[0]) )\n",
    "\n",
    "    end_onnx_inference_batch = time.time()\n",
    "    print(\"Total batch tokenization time (in seconds): \", total_batch_tokenization_time)\n",
    "    print(\"Total inference time (in seconds): \", total_inference_time)\n",
    "    print(\"Total build label time (in seconds): \", total_build_label_time)\n",
    "    print(\"Duration ONNX inference (in seconds) with {} and batch tokenization: \".format(tokenizer_str), end_onnx_inference_batch - start_onnx_inference_batch, (end_onnx_inference_batch - start_onnx_inference_batch)/len(examples))\n",
    "\n",
    "    return onnx_inference\n",
    "\n",
    "\n",
    "def get_env_var(varname, default):\n",
    "    if os.environ.get(varname) != None:\n",
    "        var = int(os.environ.get(varname))\n",
    "        print(varname, ':', var)\n",
    "    else:\n",
    "        var = default\n",
    "        print(varname, ':', var, '(Default)')\n",
    "    return var\n",
    "\n",
    "\n",
    "# Choose Number of Nodes To Distribute Credentials: e.g. jobarray=0-4, cpu_per_task=20, credentials = 90 (<100)\n",
    "# SLURM_JOB_ID = get_env_var('SLURM_JOB_ID', 0)\n",
    "# SLURM_ARRAY_TASK_ID = get_env_var('SLURM_ARRAY_TASK_ID', 0)\n",
    "# SLURM_ARRAY_TASK_COUNT = get_env_var('SLURM_ARRAY_TASK_COUNT', 1)\n",
    "\n",
    "SLURM_JOB_ID = 123123123\n",
    "SLURM_ARRAY_TASK_ID = 10\n",
    "SLURM_ARRAY_TASK_COUNT = 500\n",
    "\n",
    "\n",
    "print('SLURM_JOB_ID', SLURM_JOB_ID)\n",
    "print('SLURM_ARRAY_TASK_ID', SLURM_ARRAY_TASK_ID)\n",
    "print('SLURM_ARRAY_TASK_COUNT', SLURM_ARRAY_TASK_COUNT)\n",
    "\n",
    "\n",
    "# ####################################################################################################################################\n",
    "# # loading data\n",
    "# ####################################################################################################################################\n",
    "\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path_to_data='/scratch/spf248/twitter/data/classification/US/'\n",
    "\n",
    "\n",
    "print('Load random Tweets:')\n",
    "# random contains 7.3G of data!!\n",
    "start_time = time.time()\n",
    "\n",
    "paths_to_random=list(np.array_split(\n",
    "                        glob(os.path.join(path_to_data,'random','*.parquet')),\n",
    "#                         glob(os.path.join(path_to_data,'random_10perct_sample','*.parquet')),\n",
    "#                         glob(os.path.join(path_to_data,'random_1perct_sample','*.parquet')),\n",
    "                        SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID])\n",
    "print('#files:', len(paths_to_random))\n",
    "\n",
    "tweets_random=pd.DataFrame()\n",
    "for file in paths_to_random:\n",
    "    print(file)\n",
    "    tweets_random=pd.concat([tweets_random,pd.read_parquet(file)[['tweet_id','text']]])       \n",
    "    print(tweets_random.shape)\n",
    "    \n",
    "    break #DEBUG\n",
    "\n",
    "print('load random sample:', str(time.time() - start_time), 'seconds')\n",
    "print(tweets_random.shape)\n",
    "\n",
    "\n",
    "print('dropping duplicates:')\n",
    "# random contains 7.3G of data!!\n",
    "start_time = time.time()\n",
    "tweets_random = tweets_random.drop_duplicates('text')\n",
    "print('drop duplicates:', str(time.time() - start_time), 'seconds')\n",
    "print(tweets_random.shape)\n",
    "\n",
    "\n",
    "tweets_random = tweets_random[:250] #DEBUG\n",
    "\n",
    "start_time = time.time()\n",
    "print('converting to list')\n",
    "examples = tweets_random.text.values.tolist()\n",
    "\n",
    "\n",
    "print('convert to list:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "for column in [\"is_unemployed\", \"lost_job_1mo\", \"job_search\", \"is_hired_1mo\", \"job_offer\"]:\n",
    "\n",
    "    print('\\n\\n!!!!!', column)\n",
    "    loop_start = time.time()\n",
    "\n",
    "    model_path = '/scratch/da2734/twitter/jobs/onnx/results_simpletransformers_jun3_10Klabels_0_all_labels/{}/'.format(column)\n",
    "    onnx_path = '/scratch/da2734/twitter/jobs/onnx/results_simpletransformers_jun3_10Klabels_0_all_labels/{}/onnx/'.format(column)\n",
    "\n",
    "    ####################################################################################################################################\n",
    "    # TOKENIZATION and INFERENCE \n",
    "    ####################################################################################################################################\n",
    "    print('Predictions of random Tweets:')\n",
    "    start_time = time.time()\n",
    "    onnx_labels = inference(onnx_path+'bert_optimized.onnx', \n",
    "                                            model_path, \n",
    "                                            examples, \n",
    "                                            fast_tokenizer=True, \n",
    "                                            num_threads=5)\n",
    "    \n",
    "    print('time taken:', str(time.time() - start_time), 'seconds')\n",
    "    print('per tweet:', (time.time() - start_time)/tweets_random.shape[0], 'seconds')\n",
    "\n",
    "    if not os.path.exists(os.path.join(root_path,'pred_output_100M_ONNX_optimized', column)):\n",
    "        print('>>>> directory doesnt exists, creating it')\n",
    "        os.makedirs(os.path.join(root_path,'pred_output_100M_ONNX_optimized', column))   \n",
    "\n",
    "    \n",
    "    ####################################################################################################################################\n",
    "    # SAVING\n",
    "    ####################################################################################################################################        \n",
    "    print('Save Predictions of random Tweets:')\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    predictions_random_df = pd.DataFrame(data=onnx_labels, columns = ['first', 'second'])\n",
    "    predictions_random_df = predictions_random_df.set_index(tweets_random.tweet_id)\n",
    "\n",
    "    print(predictions_random_df.head())\n",
    "    predictions_random_df.to_csv(\n",
    "        os.path.join(root_path,'pred_output_100M_ONNX_optimized', column, 'random'+'-'+str(SLURM_JOB_ID)+'-'+str(SLURM_ARRAY_TASK_ID)+'.csv')\n",
    "        )\n",
    "    print('saved to:\\n', os.path.join(root_path,'pred_output_100M_ONNX_optimized', column, 'random'+'-'+str(SLURM_JOB_ID)+'-'+str(SLURM_ARRAY_TASK_ID)+'.csv'), 'saved')\n",
    "\n",
    "    print('save time taken:', str(time.time() - start_time), 'seconds')\n",
    "\n",
    "    print('full loop:', str(time.time() - loop_start), 'seconds', (time.time() - loop_start)/len(examples))\n",
    "\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
