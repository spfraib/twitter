{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import socket\n",
    "from glob import glob\n",
    "import os\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: US\n",
      "Folder: ITER_1_BERT\n",
      "Path to data: ../../data/classification/US\n"
     ]
    }
   ],
   "source": [
    "country_code = \"US\"\n",
    "print('Country:', country_code)\n",
    "model='BERT'\n",
    "iteration='1'\n",
    "iter_and_model='ITER_'+iteration\n",
    "if model:\n",
    "    iter_and_model+='_'+model\n",
    "print('Folder:', iter_and_model)\n",
    "# Local\n",
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data = os.path.join('../../data/classification',country_code)\n",
    "# Cluster\n",
    "else:\n",
    "    path_to_data = os.path.join('/scratch/spf248/twitter/data/classification',country_code)\n",
    "print('Path to data:',path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all existing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surveys: 18\n"
     ]
    }
   ],
   "source": [
    "print(\"Surveys:\",len(sorted([x.split('/')[-2] for x in glob(os.path.join(path_to_data,'labeling','*','qualtrics','*','labels.csv'))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# labels: 204480\n"
     ]
    }
   ],
   "source": [
    "# Only keep one label per worker and tweet\n",
    "labels=pd.concat(\n",
    "[pd.read_csv(file) for file in glob(os.path.join(path_to_data,'labeling','*','qualtrics','*','labels.csv'))]).sort_values(\n",
    "by=['tweet_id','class_id','QIDWorker']).drop_duplicates(\n",
    "['tweet_id','class_id','QIDWorker']).set_index(\n",
    "['tweet_id','class_id','QIDWorker'])\n",
    "\n",
    "print('# labels:', labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>QIDWorker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">278519817328279552</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>A170EDGL8ZWMSL</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1CFPKUOCGJIM6</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1NHTBY5YB9JH7</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3B7TNVOISSZ2O</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVCXJ9M71WDCB</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1079723333548093440</th>\n",
       "      <th>4</th>\n",
       "      <th>AGYZ0GAAUIJZX</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th>A1ETJBNTO9ZWZ8</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2MFMT03E21ZIT</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3135Y3RMFC3PK</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGYZ0GAAUIJZX</th>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204480 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              score\n",
       "tweet_id            class_id QIDWorker             \n",
       "278519817328279552  1        A170EDGL8ZWMSL     yes\n",
       "                             A1CFPKUOCGJIM6     yes\n",
       "                             A1NHTBY5YB9JH7     yes\n",
       "                             A3B7TNVOISSZ2O     yes\n",
       "                             AVCXJ9M71WDCB      yes\n",
       "...                                             ...\n",
       "1079723333548093440 4        AGYZ0GAAUIJZX       no\n",
       "                    5        A1ETJBNTO9ZWZ8     yes\n",
       "                             A2MFMT03E21ZIT     yes\n",
       "                             A3135Y3RMFC3PK     yes\n",
       "                             AGYZ0GAAUIJZX   unsure\n",
       "\n",
       "[204480 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# labeled tweets: 10522\n"
     ]
    }
   ],
   "source": [
    "def is_labeled(x):\n",
    "    # If First sequence was allocated more than once\n",
    "    if x[0]>1:\n",
    "        # If no other sequence\n",
    "        if len(x)==1:\n",
    "            return True\n",
    "        else:\n",
    "            # If second sequence less popular\n",
    "            if x[1]<x[0]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Counts labels for each observation\n",
    "counts=labels.groupby(['tweet_id','class_id'])['score'].value_counts().rename('count')\n",
    "\n",
    "# Keep tweets that were labeled more than once with most popular labels strictly dominating\n",
    "ids_labeled=counts.groupby(['tweet_id','class_id']).apply(list).apply(is_labeled).groupby('tweet_id').sum().where(lambda x:x==5).dropna().index\n",
    "print('# labeled tweets:', len(ids_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep most popular label sequence\n",
    "labels=counts.reindex(ids_labeled,level='tweet_id').reset_index(\n",
    "level='score').groupby(['tweet_id','class_id'])['score'].first().unstack()\n",
    "labels.index=labels.index.astype(str)\n",
    "\n",
    "class2name=dict(zip(range(1,6),[\n",
    "'is_unemployed',\n",
    "'job_loss',\n",
    "'job_search',\n",
    "'is_hired',\n",
    "'job_offer',\n",
    "]))\n",
    "\n",
    "['Does this tweet indicate that the user is currently unemployed?',\n",
    "'Does this tweet indicate that the user became unemployed within the last month?',\n",
    "'Does this tweet indicate that the user is currently searching for a job?',\n",
    "'Does this tweet indicate that the user was hired within the last month?',\n",
    "'Does this tweet contain a job offer?',]\n",
    "\n",
    "labels.rename(columns=lambda x:class2name[x],inplace=True)\n",
    "labels.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Input tweets: 990\n",
      "# Labeled tweets: 755\n"
     ]
    }
   ],
   "source": [
    "tweets=pd.DataFrame()\n",
    "sample_files=glob(os.path.join(path_to_data,'labeling',iter_and_model,'sample','*'))\n",
    "for sample_file in sample_files:\n",
    "    if '.pkl' in sample_file:\n",
    "        tweets=pd.concat([tweets,pd.read_pickle(sample_file)])\n",
    "    elif '.parquet' in sample_file:\n",
    "        tweets=pd.concat([tweets,pd.read_parquet(sample_file)])\n",
    "    else:\n",
    "        print('Extension error:', sample_file)\n",
    "tweets=tweets.drop_duplicates('tweet_id')[['tweet_id','text']]\n",
    "tweets.tweet_id=tweets.tweet_id.astype(str)\n",
    "print('# Input tweets:',tweets.shape[0])\n",
    "\n",
    "tweets=tweets.merge(labels)\n",
    "print('# Labeled tweets:',tweets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_unemployed    0.250331\n",
       "job_loss         0.123179\n",
       "job_search       0.137748\n",
       "is_hired         0.123179\n",
       "job_offer        0.182781\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[class2name.values()].applymap(lambda x:x=='yes').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_pickle(os.path.join(path_to_data,'labeling',iter_and_model,'labels.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
