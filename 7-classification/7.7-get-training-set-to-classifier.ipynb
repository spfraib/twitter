{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import socket\n",
    "from glob import glob\n",
    "import os\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: US\n",
      "Folder: ITER_0\n",
      "Path to data: ../../data/classification/US\n"
     ]
    }
   ],
   "source": [
    "country_code = \"US\"\n",
    "print('Country:', country_code)\n",
    "model='BERT'\n",
    "iteration='1'\n",
    "iter_and_model='ITER_'+iteration\n",
    "if model:\n",
    "    iter_and_model+='_'+model\n",
    "print('Folder:', iter_and_model)\n",
    "# Local\n",
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data = os.path.join('../../data/classification',country_code)\n",
    "# Cluster\n",
    "else:\n",
    "    path_to_data = os.path.join('/scratch/spf248/twitter/data/classification',country_code)\n",
    "print('Path to data:',path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surveys: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Surveys:\",len(sorted([x.split('/')[-2] for x in glob(os.path.join(path_to_data,'labeling',iter_and_model,'qualtrics','*','labels.csv'))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# labels: 14750\n"
     ]
    }
   ],
   "source": [
    "# Only keep one label per worker and tweet\n",
    "labels=pd.concat(\n",
    "[pd.read_csv(file) for file in glob(os.path.join(path_to_data,'labeling',iter_and_model,'qualtrics','*','labels.csv'))]).sort_values(\n",
    "by=['tweet_id','class_id','QIDWorker']).drop_duplicates(\n",
    "['tweet_id','class_id','QIDWorker']).set_index(\n",
    "['tweet_id','class_id','QIDWorker'])\n",
    "\n",
    "print('# labels:', labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>QIDWorker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">278264509674692609</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>A1PR74OHURJNTO</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUCHGHY1IKZZK</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>A1PR74OHURJNTO</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUCHGHY1IKZZK</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>A1PR74OHURJNTO</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1066457161025363969</th>\n",
       "      <th>4</th>\n",
       "      <th>AY832D29HUURG</th>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th>AITLTT4ZKSZIM</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU7A3QNJF3O00</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUCHGHY1IKZZK</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY832D29HUURG</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14750 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              score\n",
       "tweet_id            class_id QIDWorker             \n",
       "278264509674692609  1        A1PR74OHURJNTO      no\n",
       "                             AUCHGHY1IKZZK       no\n",
       "                    2        A1PR74OHURJNTO      no\n",
       "                             AUCHGHY1IKZZK       no\n",
       "                    3        A1PR74OHURJNTO      no\n",
       "...                                             ...\n",
       "1066457161025363969 4        AY832D29HUURG   unsure\n",
       "                    5        AITLTT4ZKSZIM       no\n",
       "                             AU7A3QNJF3O00       no\n",
       "                             AUCHGHY1IKZZK       no\n",
       "                             AY832D29HUURG      yes\n",
       "\n",
       "[14750 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# labeled tweets: 941\n"
     ]
    }
   ],
   "source": [
    "def is_labeled(x):\n",
    "    # If First sequence was allocated more than once\n",
    "    if x[0]>1:\n",
    "        # If no other sequence\n",
    "        if len(x)==1:\n",
    "            return True\n",
    "        else:\n",
    "            # If second sequence less popular\n",
    "            if x[1]<x[0]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Counts labels for each observation\n",
    "counts=labels.groupby(['tweet_id','class_id'])['score'].value_counts().rename('count')\n",
    "\n",
    "# Keep tweets that were labeled more than once with most popular labels strictly dominating\n",
    "ids_labeled=counts.groupby(['tweet_id','class_id']).apply(list).apply(is_labeled).groupby('tweet_id').sum().where(lambda x:x==5).dropna().index\n",
    "print('# labeled tweets:', len(ids_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep most popular label sequence\n",
    "labels=counts.reindex(ids_labeled,level='tweet_id').reset_index(\n",
    "level='score').groupby(['tweet_id','class_id'])['score'].first().unstack()\n",
    "labels.index=labels.index.astype(str)\n",
    "\n",
    "class2name=dict(zip(range(1,6),[\n",
    "'is_unemployed',\n",
    "'job_loss',\n",
    "'job_search',\n",
    "'is_hired',\n",
    "'job_offer',\n",
    "]))\n",
    "\n",
    "['Does this tweet indicate that the user is currently unemployed?',\n",
    "'Does this tweet indicate that the user became unemployed within the last month?',\n",
    "'Does this tweet indicate that the user is currently searching for a job?',\n",
    "'Does this tweet indicate that the user was hired within the last month?',\n",
    "'Does this tweet contain a job offer?',]\n",
    "\n",
    "labels.rename(columns=lambda x:class2name[x],inplace=True)\n",
    "labels.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension error: ../../data/classification/US/labeling/ITER_0/sample/_SUCCESS\n",
      "# Tweets: 9800\n"
     ]
    }
   ],
   "source": [
    "tweets=pd.DataFrame()\n",
    "sample_files=glob(os.path.join(path_to_data,'labeling',iter_and_model,'sample','*'))\n",
    "for sample_file in sample_files:\n",
    "    if '.pkl' in sample_file:\n",
    "        tweets=pd.concat([tweets,pd.read_pickle(sample_file)])\n",
    "    elif '.parquet' in sample_file:\n",
    "        tweets=pd.concat([tweets,pd.read_parquet(sample_file)])\n",
    "    else:\n",
    "        print('Extension error:', sample_file)\n",
    "tweets=tweets.drop_duplicates('tweet_id')[['tweet_id','text']]\n",
    "tweets.tweet_id=tweets.tweet_id.astype(str)\n",
    "print('# Tweets:',tweets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.merge(labels).to_pickle(os.path.join(path_to_data,'labeling',iter_and_model,'labels.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_unemployed    0.200595\n",
       "job_loss         0.095321\n",
       "job_search       0.120357\n",
       "is_hired         0.078494\n",
       "job_offer        0.181203\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.merge(labels)[class2name.values()].applymap(lambda x:x=='yes').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
