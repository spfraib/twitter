{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import re\n",
    "import socket\n",
    "from glob import glob\n",
    "import os\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: US\n",
      "Hostname: Samuels-MBP.home\n"
     ]
    }
   ],
   "source": [
    "iterations=range(2)\n",
    "models=['GLOVE','BERT']\n",
    "labels=['is_hired_1mo','is_unemployed','job_offer','job_search','lost_job_1mo']\n",
    "\n",
    "country_code = \"US\"\n",
    "print('Country:', country_code)\n",
    "\n",
    "print('Hostname:', socket.gethostname())\n",
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data='../../data'\n",
    "else:\n",
    "    path_to_data='/scratch/spf248/twitter/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract labeled tweets:\n",
      "\n",
      "# labels: 13183\n"
     ]
    }
   ],
   "source": [
    "print('Extract labeled tweets:\\n')\n",
    "labeled_tweets=pd.read_pickle(os.path.join(path_to_data,'classification',country_code,'labeling','labels.pkl'))\n",
    "print('# labels:', labeled_tweets.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>is_unemployed</th>\n",
       "      <th>lost_job_1mo</th>\n",
       "      <th>job_search</th>\n",
       "      <th>is_hired_1mo</th>\n",
       "      <th>job_offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278307497121554433</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278519817328279552</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278534362910322688</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>278660548453888001</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278690533809991681</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id is_unemployed lost_job_1mo job_search is_hired_1mo  \\\n",
       "0  278307497121554433            no           no         no           no   \n",
       "1  278519817328279552           yes           no        yes           no   \n",
       "2  278534362910322688            no           no        yes           no   \n",
       "3  278660548453888001           yes           no         no           no   \n",
       "4  278690533809991681            no           no         no           no   \n",
       "\n",
       "  job_offer  \n",
       "0        no  \n",
       "1        no  \n",
       "2        no  \n",
       "3        no  \n",
       "4        no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********* Iteration: 0 *********\n",
      "\n",
      "*** Model: GLOVE ***\n",
      "Extension error: ../../data/classification/US/labeling/0/sampled/training/_SUCCESS\n",
      "# tweets: iteration_0_GLOVE 9746\n",
      "*** Label: is_hired_1mo ***\n",
      "# tweets: 9715\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.08\n",
      "*** Label: is_unemployed ***\n",
      "# tweets: 9679\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.2\n",
      "*** Label: job_offer ***\n",
      "# tweets: 9716\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.18\n",
      "*** Label: job_search ***\n",
      "# tweets: 9731\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.12\n",
      "*** Label: lost_job_1mo ***\n",
      "# tweets: 9661\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.1\n",
      "\n",
      "*** Model: BERT ***\n",
      "Extension error: ../../data/classification/US/labeling/0/sampled/training/_SUCCESS\n",
      "# tweets: iteration_0_BERT 9746\n",
      "*** Label: is_hired_1mo ***\n",
      "# tweets: 9715\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.08\n",
      "*** Label: is_unemployed ***\n",
      "# tweets: 9679\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.2\n",
      "*** Label: job_offer ***\n",
      "# tweets: 9716\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.18\n",
      "*** Label: job_search ***\n",
      "# tweets: 9731\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.12\n",
      "*** Label: lost_job_1mo ***\n",
      "# tweets: 9661\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.1\n",
      "\n",
      "********* Iteration: 1 *********\n",
      "\n",
      "*** Model: GLOVE ***\n",
      "# tweets: iteration_1_GLOVE 983\n",
      "*** Label: is_hired_1mo ***\n",
      "# tweets: 975\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.31\n",
      "*** Label: is_unemployed ***\n",
      "# tweets: 966\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.38\n",
      "*** Label: job_offer ***\n",
      "# tweets: 974\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.36\n",
      "*** Label: job_search ***\n",
      "# tweets: 975\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.32\n",
      "*** Label: lost_job_1mo ***\n",
      "# tweets: 969\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.25\n",
      "\n",
      "*** Model: BERT ***\n",
      "# tweets: iteration_1_BERT 989\n",
      "*** Label: is_hired_1mo ***\n",
      "# tweets: 985\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.15\n",
      "*** Label: is_unemployed ***\n",
      "# tweets: 970\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.27\n",
      "*** Label: job_offer ***\n",
      "# tweets: 975\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.17\n",
      "*** Label: job_search ***\n",
      "# tweets: 980\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.15\n",
      "*** Label: lost_job_1mo ***\n",
      "# tweets: 975\n",
      "% Positives (taking all the labeled tweets across boundaries for that model): 0.13\n"
     ]
    }
   ],
   "source": [
    "for iteration in iterations:\n",
    "    print()\n",
    "    print('********* Iteration:',iteration,'*********')\n",
    "    for model in models:\n",
    "        print()\n",
    "        print('*** Model:',model,'***')\n",
    "        name='iteration_'+str(iteration)+'_'+model\n",
    "        sample_files=glob(os.path.join(path_to_data,'classification',country_code,'labeling',str(iteration),'sampled','training','*'))\n",
    "        if iteration!=0:\n",
    "            sample_files=[x for x in sample_files if model.lower() in x.lower()]\n",
    "        sampled_tweets=pd.DataFrame()\n",
    "        for sample_file in sample_files:\n",
    "            if '.pkl' in sample_file:\n",
    "                tmp=pd.read_pickle(sample_file)[['tweet_id','text']]\n",
    "            elif '.parquet' in sample_file:\n",
    "                tmp=pd.read_parquet(sample_file)[['tweet_id','text']]\n",
    "            else:\n",
    "                print('Extension error:', sample_file)\n",
    "            tmp.tweet_id=tmp.tweet_id.astype(str)\n",
    "            sampled_tweets=pd.concat([sampled_tweets,tmp])\n",
    "        sampled_tweets=sampled_tweets.drop_duplicates('tweet_id')\n",
    "        sampled_tweets=sampled_tweets.merge(labeled_tweets)\n",
    "        print('# tweets:', name, sampled_tweets.shape[0])\n",
    "        \n",
    "        for label in labels:\n",
    "            print('*** Label:',label,'***')\n",
    "            training_tweets=sampled_tweets[['text',label]].copy()\n",
    "            training_tweets[label]=training_tweets[label].apply(lambda x:{'yes':1,'no':0,'unsure':np.nan}[x])\n",
    "            training_tweets.dropna(inplace=True)\n",
    "            training_tweets.rename(columns={label:'class'},inplace=True)\n",
    "            print('# tweets:', training_tweets.shape[0])\n",
    "            print('% Positives (taking all the labeled tweets across boundaries for that model):', round(training_tweets['class'].mean(),2))\n",
    "            training_tweets.to_csv(os.path.join(path_to_data,'classification',country_code,'labeling',str(iteration),'labeled','training','labels_iteration_'+str(iteration)+'_'+model+'_'+label+'.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
