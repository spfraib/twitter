{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import json\n",
    "import io, os\n",
    "import sys\n",
    "import re\n",
    "import socket\n",
    "import pandas as pd\n",
    "import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: Samuels-MacBook-Pro.local\n"
     ]
    }
   ],
   "source": [
    "country_code=\"US\"\n",
    "\n",
    "print('Hostname:', socket.gethostname())\n",
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data='../../data'\n",
    "else:\n",
    "    path_to_data='/scratch/spf248/twitter/data'\n",
    "\n",
    "# Setting user Parameters\n",
    "with open(os.path.join(path_to_data,'keys/qualtrics/apiToken'),'r') as f:\n",
    "    apiToken = eval(f.readline())\n",
    "dataCenter = \"nyu.ca1\"\n",
    "surveyId = \"SV_8uMuwiJVgsGDPjn\"\n",
    "fileFormat = \"csv\" # [\"csv\", \"tsv\", \"spss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportSurvey(apiToken,surveyId,dataCenter,fileFormat):\n",
    "    \n",
    "    surveyId = surveyId\n",
    "    fileFormat = fileFormat\n",
    "    dataCenter = dataCenter \n",
    "\n",
    "    # Setting static parameters\n",
    "    requestCheckProgress = 0.0\n",
    "    progressStatus = \"inProgress\"\n",
    "    baseUrl = \"https://{0}.qualtrics.com/API/v3/responseexports/\".format(dataCenter)\n",
    "    headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"x-api-token\": apiToken,\n",
    "    }\n",
    "\n",
    "    # Step 1: Creating Data Export\n",
    "    downloadRequestUrl = baseUrl\n",
    "    downloadRequestPayload = '{\"format\":\"' + fileFormat + '\",\"surveyId\":\"' + surveyId + '\"}'\n",
    "    downloadRequestResponse = requests.request(\"POST\", downloadRequestUrl, data=downloadRequestPayload, headers=headers)\n",
    "    progressId = downloadRequestResponse.json()[\"result\"]['id']\n",
    "    print(downloadRequestResponse.text)\n",
    "\n",
    "    # Step 2: Checking on Data Export Progress and waiting until export is ready\n",
    "    while progressStatus != \"complete\" and progressStatus != \"failed\":\n",
    "        print (\"progressStatus=\", progressStatus)\n",
    "        requestCheckUrl = baseUrl + progressId\n",
    "        requestCheckResponse = requests.request(\"GET\", requestCheckUrl, headers=headers)\n",
    "        requestCheckProgress = requestCheckResponse.json()[\"result\"][\"percentComplete\"]\n",
    "        print(\"Download is \" + str(requestCheckProgress) + \" complete\")\n",
    "        progressStatus = requestCheckResponse.json()[\"result\"][\"status\"]\n",
    "\n",
    "    #step 2.1: Check for error\n",
    "    if progressStatus is \"failed\":\n",
    "        raise Exception(\"export failed\")\n",
    "\n",
    "    # # Step 3: Downloading file\n",
    "    requestDownloadUrl = baseUrl + progressId + '/file'\n",
    "    requestDownload = requests.request(\"GET\", requestDownloadUrl, headers=headers, stream=True)\n",
    "\n",
    "    # Step 4: Unzipping the file\n",
    "    zipfile.ZipFile(io.BytesIO(requestDownload.content)).extractall(\n",
    "    os.path.join(path_to_data,\"classification\",country_code,\"labeled\",surveyId))\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(path_to_data,\"classification\",country_code,\"labeled\",surveyId)):\n",
    "    if not re.compile('^SV_.*').match(surveyId):\n",
    "        print(\"survey Id must match ^SV_.*\")\n",
    "    else:\n",
    "        exportSurvey(apiToken, surveyId, dataCenter, fileFormat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(path_to_data,\"classification\",country_code,\"labeled\",surveyId,\"labor-market-tweets.csv\"),low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "# of workers who refused the consent form: 0\n",
      "# of workers who did not complete the survey: 0\n"
     ]
    }
   ],
   "source": [
    "# First two rows contain metadata\n",
    "df.drop([0,1],inplace=True)\n",
    "\n",
    "if df.QIDWorker.unique().shape[0]!=df.QIDWorker.shape[0]:\n",
    "    print('Some workers took the survey twice, hence indexing by worker might be invalid.')\n",
    "    \n",
    "else:\n",
    "    df.set_index('QIDWorker',inplace=True)\n",
    "    \n",
    "places=rg.search([tuple(x) for x in df[['LocationLatitude','LocationLongitude']].astype(float).dropna().values.tolist()])\n",
    "\n",
    "print('# of workers who refused the consent form:', (df.QIDConsent.astype(int)==0).sum())\n",
    "print('# of workers who did not complete the survey:', (df.Finished.astype(int)==0).sum())\n",
    "\n",
    "to_drop=[\n",
    "'ResponseID',\n",
    "'ResponseSet', \n",
    "'IPAddress', \n",
    "'StartDate', \n",
    "'EndDate',\n",
    "'RecipientLastName', \n",
    "'RecipientFirstName', \n",
    "'RecipientEmail',\n",
    "'ExternalDataReference',\n",
    "'Finished',\n",
    "'Status', \n",
    "'Random ID',\n",
    "'QIDConsent', \n",
    "'QIDDescription',\n",
    "'QIDCompletion',\n",
    "'LocationLatitude',\n",
    "'LocationLongitude',\n",
    "'LocationAccuracy']\n",
    "\n",
    "df.drop(to_drop,1,inplace=True,errors='ignore')\n",
    "df.drop([x for x in df.columns if 'BR-FL_' in x],1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>check_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIDWorker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1SWV4X4PD25S1</th>\n",
       "      <td>1_1_2_2_2</td>\n",
       "      <td>2_3_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1USDMJVT10CE4</th>\n",
       "      <td>1_1_2_2_2</td>\n",
       "      <td>2_2_2_2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2APPZDU0VS9LN</th>\n",
       "      <td>1_1_2_2_2</td>\n",
       "      <td>2_2_2_2_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2F0X4LN9N4O4C</th>\n",
       "      <td>1_2_2_2_2</td>\n",
       "      <td>2_2_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2FUMA4UR6S920</th>\n",
       "      <td>1_2_2_2_2</td>\n",
       "      <td>2_2_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2GR3333S2F53G</th>\n",
       "      <td>1_1_3_2_2</td>\n",
       "      <td>2_2_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2SYRFPPV9WDEG</th>\n",
       "      <td>1_1_2_2_2</td>\n",
       "      <td>2_1_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A35D31QHYQUF9V</th>\n",
       "      <td>1_1_3_2_2</td>\n",
       "      <td>2_2_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A38USYKE9P7Z9O</th>\n",
       "      <td>1_1_2_2_2</td>\n",
       "      <td>2_1_1_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3LRZX8477TYYZ</th>\n",
       "      <td>1_1_3_2_2</td>\n",
       "      <td>2_2_2_1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDC9A6Z60W2Z</th>\n",
       "      <td>1_1_3_2_2</td>\n",
       "      <td>2_3_2_1_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "check_id                0          1\n",
       "QIDWorker                           \n",
       "A1SWV4X4PD25S1  1_1_2_2_2  2_3_2_1_2\n",
       "A1USDMJVT10CE4  1_1_2_2_2  2_2_2_2_2\n",
       "A2APPZDU0VS9LN  1_1_2_2_2  2_2_2_2_2\n",
       "A2F0X4LN9N4O4C  1_2_2_2_2  2_2_2_1_2\n",
       "A2FUMA4UR6S920  1_2_2_2_2  2_2_2_1_2\n",
       "A2GR3333S2F53G  1_1_3_2_2  2_2_2_1_2\n",
       "A2SYRFPPV9WDEG  1_1_2_2_2  2_1_2_1_2\n",
       "A35D31QHYQUF9V  1_1_3_2_2  2_2_2_1_2\n",
       "A38USYKE9P7Z9O  1_1_2_2_2  2_1_1_1_2\n",
       "A3LRZX8477TYYZ  1_1_3_2_2  2_2_2_1_2\n",
       "AFDC9A6Z60W2Z   1_1_3_2_2  2_3_2_1_2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks\n",
    "checks=df[[col for col in df.columns if 'check' in col]].copy()\n",
    "checks.columns.name='QID'\n",
    "\n",
    "# Rearrange Results\n",
    "checks=checks.stack().rename('score').to_frame()\n",
    "\n",
    "# Extract Check ID\n",
    "checks['check_id']=checks.index.get_level_values('QID').map(\n",
    "lambda x:re.findall('check-(\\d)',x)[0])\n",
    "\n",
    "# Extract Class ID\n",
    "checks['class_id']=checks.index.get_level_values('QID').map(\n",
    "lambda x:re.findall('_(\\d)',x)[0])\n",
    "\n",
    "# Sort Values\n",
    "checks=checks.reset_index(level='QIDWorker').sort_values(\n",
    "by=['QIDWorker','check_id','class_id']).set_index(\n",
    "['QIDWorker','check_id','class_id'])\n",
    "\n",
    "# List check sequence filling missing values\n",
    "checks=checks.unstack(level='class_id').apply(lambda x:'_'.join(x),1)\n",
    "checks=checks.unstack(level='check_id').fillna('')\n",
    "\n",
    "# Select workers who failed the check sequence\n",
    "checks=checks.where(lambda x:(x['0']!='1_1_2_2_2')|(x['1']!='2_2_2_1_2')).dropna()\n",
    "\n",
    "# print('Workers who failed the check questions (= bots?):')\n",
    "checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Observations with at least two identical labels:\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# Remove checks\n",
    "df.drop([col for col in df.columns if 'check' in col],1,inplace=True)\n",
    "df.columns.name='QID'\n",
    "\n",
    "# Rearrange Results\n",
    "df=df.stack().rename('score').to_frame()\n",
    "\n",
    "# Extract Tweets ID (Removing Extra Indexing)\n",
    "df['tweet_id']=df.index.get_level_values('QID').map(\n",
    "lambda x:re.sub('-v\\d','',x.replace('ID_','').replace('.1','')).split('_')[0])\n",
    "\n",
    "# Extract Classes (Removing Extra Indexing)\n",
    "df['class_id']=df.index.get_level_values('QID').map(\n",
    "lambda x:re.sub('-v\\d','',x.replace('ID_','').replace('.1','')).split('_')[1])\n",
    "\n",
    "# Sort Values\n",
    "df=df.reset_index(level='QIDWorker').sort_values(\n",
    "by=['tweet_id','class_id','QIDWorker']).set_index(\n",
    "['tweet_id','class_id','QIDWorker'])\n",
    "\n",
    "# Drop Bots\n",
    "df.drop(checks.index,level='QIDWorker',inplace=True)\n",
    "\n",
    "# Convert Scores\n",
    "df.score=df.score.apply(lambda x:{'1':'yes','2':'no','3':'unsure'}[x])\n",
    "\n",
    "# Count number of labels and number of unique labels\n",
    "counts=df.groupby(['tweet_id','class_id'])['score'].agg(['count','nunique'])\n",
    "\n",
    "print('% Observations with at least two identical labels:')\n",
    "print(counts[(counts['count']>1)&(counts['nunique']==1)].shape[0]/counts[(counts['count']>1)].shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path_to_data,\"classification\",country_code,'labeled',surveyId,'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>QIDWorker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1005925892621783041</th>\n",
       "      <th>1</th>\n",
       "      <th>AMA18W8F60Y2J</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>AMA18W8F60Y2J</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>AMA18W8F60Y2J</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>AMA18W8F60Y2J</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>AMA18W8F60Y2J</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">998726197856100352</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>A1CFMY4CEYOM8Y</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AETIZKQNUSBLB</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>A100Y89FZO4J0B</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1CFMY4CEYOM8Y</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AETIZKQNUSBLB</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20880 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            score\n",
       "tweet_id            class_id QIDWorker           \n",
       "1005925892621783041 1        AMA18W8F60Y2J    yes\n",
       "                    2        AMA18W8F60Y2J    yes\n",
       "                    3        AMA18W8F60Y2J     no\n",
       "                    4        AMA18W8F60Y2J     no\n",
       "                    5        AMA18W8F60Y2J     no\n",
       "...                                           ...\n",
       "998726197856100352  4        A1CFMY4CEYOM8Y   yes\n",
       "                             AETIZKQNUSBLB    yes\n",
       "                    5        A100Y89FZO4J0B    no\n",
       "                             A1CFMY4CEYOM8Y    no\n",
       "                             AETIZKQNUSBLB     no\n",
       "\n",
       "[20880 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- coin's kappa:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html\n",
    "\n",
    "- send back to labeling if there is disagreement or less than 2 labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
