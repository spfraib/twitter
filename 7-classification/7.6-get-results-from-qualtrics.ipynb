{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import json\n",
    "import io, os\n",
    "import sys\n",
    "import re\n",
    "import socket\n",
    "import pandas as pd\n",
    "import reverse_geocoder as rg\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: ITER_1_BERT\n",
      "Hostname: Samuels-MBP.home\n"
     ]
    }
   ],
   "source": [
    "country_code=\"US\"\n",
    "\n",
    "model='BERT'\n",
    "iteration='1'\n",
    "iter_and_model='ITER_'+iteration\n",
    "if model:\n",
    "    iter_and_model+='_'+model\n",
    "print('Folder:', iter_and_model)\n",
    "\n",
    "print('Hostname:', socket.gethostname())\n",
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data='../../data'\n",
    "else:\n",
    "    path_to_data='/scratch/spf248/twitter/data'\n",
    "\n",
    "# Setting user Parameters\n",
    "with open(os.path.join(path_to_data,'keys/qualtrics/apiToken'),'r') as f:\n",
    "    apiToken = eval(f.readline())\n",
    "dataCenter = \"nyu.ca1\"\n",
    "surveyId = \"SV_24RoQ3TAAnEpaN7\"\n",
    "fileFormat = \"csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportSurvey(apiToken,surveyId,dataCenter,fileFormat):\n",
    "    \n",
    "    surveyId = surveyId\n",
    "    fileFormat = fileFormat\n",
    "    dataCenter = dataCenter \n",
    "\n",
    "    # Setting static parameters\n",
    "    requestCheckProgress = 0.0\n",
    "    progressStatus = \"inProgress\"\n",
    "    baseUrl = \"https://{0}.qualtrics.com/API/v3/responseexports/\".format(dataCenter)\n",
    "    headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"x-api-token\": apiToken,\n",
    "    }\n",
    "\n",
    "    # Step 1: Creating Data Export\n",
    "    downloadRequestUrl = baseUrl\n",
    "    downloadRequestPayload = '{\"format\":\"' + fileFormat + '\",\"surveyId\":\"' + surveyId + '\"}'\n",
    "    downloadRequestResponse = requests.request(\"POST\", downloadRequestUrl, data=downloadRequestPayload, headers=headers)\n",
    "    progressId = downloadRequestResponse.json()[\"result\"]['id']\n",
    "    print(downloadRequestResponse.text)\n",
    "\n",
    "    # Step 2: Checking on Data Export Progress and waiting until export is ready\n",
    "    while progressStatus != \"complete\" and progressStatus != \"failed\":\n",
    "        print (\"progressStatus=\", progressStatus)\n",
    "        requestCheckUrl = baseUrl + progressId\n",
    "        requestCheckResponse = requests.request(\"GET\", requestCheckUrl, headers=headers)\n",
    "        requestCheckProgress = requestCheckResponse.json()[\"result\"][\"percentComplete\"]\n",
    "        print(\"Download is \" + str(requestCheckProgress) + \" complete\")\n",
    "        progressStatus = requestCheckResponse.json()[\"result\"][\"status\"]\n",
    "\n",
    "    #step 2.1: Check for error\n",
    "    if progressStatus is \"failed\":\n",
    "        raise Exception(\"export failed\")\n",
    "\n",
    "    # # Step 3: Downloading file\n",
    "    requestDownloadUrl = baseUrl + progressId + '/file'\n",
    "    requestDownload = requests.request(\"GET\", requestDownloadUrl, headers=headers, stream=True)\n",
    "\n",
    "    # Step 4: Unzipping the file\n",
    "    zipfile.ZipFile(io.BytesIO(requestDownload.content)).extractall(\n",
    "    os.path.join(path_to_data,\"classification\",country_code,\"labeling\",iter_and_model,'qualtrics',surveyId))\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\":{\"id\":\"ES_9th9qum4q358invkcdtbdqvr5c\"},\"meta\":{\"httpStatus\":\"200 - OK\",\"requestId\":\"06de4d69-3ff5-4605-9db5-703a1ed07136\"}}\n",
      "progressStatus= inProgress\n",
      "Download is 0.0 complete\n",
      "progressStatus= in progress\n",
      "Download is 0.0 complete\n",
      "progressStatus= in progress\n",
      "Download is 0.0 complete\n",
      "progressStatus= in progress\n",
      "Download is 0.0 complete\n",
      "progressStatus= in progress\n",
      "Download is 0.0 complete\n",
      "progressStatus= in progress\n",
      "Download is 100.0 complete\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(path_to_data,\"classification\",country_code,\"labeling\",iter_and_model,'qualtrics',surveyId)):\n",
    "    if not re.compile('^SV_.*').match(surveyId):\n",
    "        print(\"survey Id must match ^SV_.*\")\n",
    "    else:\n",
    "        exportSurvey(apiToken, surveyId, dataCenter, fileFormat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(path_to_data,\"classification\",country_code,\"labeling\",iter_and_model,'qualtrics',surveyId,\"labor-market-tweets.csv\"),low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "# of workers who refused the consent form: 0\n",
      "# of workers who did not complete the survey: 0\n"
     ]
    }
   ],
   "source": [
    "# First two rows contain metadata\n",
    "df.drop([0,1],inplace=True)\n",
    "\n",
    "df=df.loc[(df['QIDWorker'].dropna().drop_duplicates().index)].set_index('QIDWorker').copy()\n",
    "\n",
    "places=rg.search([tuple(x) for x in df[['LocationLatitude','LocationLongitude']].astype(float).dropna().values.tolist()])\n",
    "\n",
    "print('# of workers who refused the consent form:', (df.QIDConsent.astype(int)==0).sum())\n",
    "print('# of workers who did not complete the survey:', (df.Finished.astype(int)==0).sum())\n",
    "\n",
    "to_drop=[\n",
    "'ResponseID',\n",
    "'ResponseSet', \n",
    "'IPAddress', \n",
    "'StartDate', \n",
    "'EndDate',\n",
    "'RecipientLastName', \n",
    "'RecipientFirstName', \n",
    "'RecipientEmail',\n",
    "'ExternalDataReference',\n",
    "'Finished',\n",
    "'Status', \n",
    "'Random ID',\n",
    "'QIDConsent', \n",
    "'QIDDescription',\n",
    "'QIDCompletion',\n",
    "'LocationLatitude',\n",
    "'LocationLongitude',\n",
    "'LocationAccuracy']\n",
    "\n",
    "df.drop(to_drop,1,inplace=True,errors='ignore')\n",
    "df.drop([x for x in df.columns if 'BR-FL_' in x],1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Workers who failed the check questions (= bots?): 3\n"
     ]
    }
   ],
   "source": [
    "# Checks\n",
    "checks=df[[col for col in df.columns if 'check' in col]].copy()\n",
    "checks.columns.name='QID'\n",
    "\n",
    "# Rearrange Results\n",
    "checks=checks.stack().rename('score').to_frame()\n",
    "\n",
    "# Extract Check ID\n",
    "checks['check_id']=checks.index.get_level_values('QID').map(\n",
    "lambda x:re.findall('check-(\\d)',x)[0])\n",
    "\n",
    "# Extract Class ID\n",
    "checks['class_id']=checks.index.get_level_values('QID').map(\n",
    "lambda x:re.findall('_(\\d)',x)[0])\n",
    "\n",
    "# Sort Values\n",
    "checks=checks.reset_index(level='QIDWorker').sort_values(\n",
    "by=['QIDWorker','check_id','class_id']).set_index(\n",
    "['QIDWorker','check_id','class_id'])\n",
    "\n",
    "# Bot=Fail to give a Yes to the 3 check questions\n",
    "def is_bot(x):\n",
    "    l=x.split('_')\n",
    "    if len(l)==10:\n",
    "        if l[0]=='1' and l[1]=='1' and l[8]=='1':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "bots=checks.unstack(\n",
    "level='check_id').unstack(\n",
    "level='class_id').fillna('').apply(\n",
    "lambda x:'_'.join(x),1).apply(is_bot).where(\n",
    "lambda x:x==True).dropna().index\n",
    "\n",
    "print('# Workers who failed the check questions (= bots?):', bots.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Observations with at least two identical labels:\n",
      "43.913043478260875\n"
     ]
    }
   ],
   "source": [
    "# Remove checks\n",
    "df.drop([col for col in df.columns if 'check' in col],1,inplace=True)\n",
    "df.columns.name='QID'\n",
    "\n",
    "# Rearrange Results\n",
    "df=df.stack().rename('score').to_frame()\n",
    "\n",
    "# Extract Tweets ID (Removing Extra Indexing)\n",
    "df['tweet_id']=df.index.get_level_values('QID').map(\n",
    "lambda x:re.sub('-v\\d','',x.replace('ID_','').replace('.1','')).split('_')[0])\n",
    "\n",
    "# Extract Classes (Removing Extra Indexing)\n",
    "df['class_id']=df.index.get_level_values('QID').map(\n",
    "lambda x:re.sub('-v\\d','',x.replace('ID_','').replace('.1','')).split('_')[1])\n",
    "\n",
    "# Sort Values\n",
    "df=df.reset_index(level='QIDWorker').sort_values(\n",
    "by=['tweet_id','class_id','QIDWorker']).set_index(\n",
    "['tweet_id','class_id','QIDWorker'])\n",
    "\n",
    "# Drop Bots\n",
    "df.drop(bots,level='QIDWorker',inplace=True,errors='ignore')\n",
    "\n",
    "# Convert Scores\n",
    "df.score=df.score.apply(lambda x:{'1':'yes','2':'no','3':'unsure'}[x])\n",
    "\n",
    "# Count number of labels and number of unique labels\n",
    "counts=df.groupby(['tweet_id','class_id'])['score'].agg(['count','nunique'])\n",
    "\n",
    "print('% Observations with at least two identical labels:')\n",
    "print(counts[(counts['count']>1)&(counts['nunique']==1)].shape[0]/counts[(counts['count']>1)].shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(path_to_data,\"classification\",country_code,\"labeling\",iter_and_model,'qualtrics',surveyId,'labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th>class_id</th>\n",
       "      <th>QIDWorker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1070419306096164864</th>\n",
       "      <th>1</th>\n",
       "      <th>A11YS0T8MV3Q7C</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>A11YS0T8MV3Q7C</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>A11YS0T8MV3Q7C</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>A11YS0T8MV3Q7C</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>A11YS0T8MV3Q7C</th>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">976046480447418368</th>\n",
       "      <th>3</th>\n",
       "      <th>A2UYZFH5VT5R3H</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>A2HRAAY4QRTM7S</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2UYZFH5VT5R3H</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>A2HRAAY4QRTM7S</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2UYZFH5VT5R3H</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1370 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              score\n",
       "tweet_id            class_id QIDWorker             \n",
       "1070419306096164864 1        A11YS0T8MV3Q7C      no\n",
       "                    2        A11YS0T8MV3Q7C      no\n",
       "                    3        A11YS0T8MV3Q7C      no\n",
       "                    4        A11YS0T8MV3Q7C     yes\n",
       "                    5        A11YS0T8MV3Q7C  unsure\n",
       "...                                             ...\n",
       "976046480447418368  3        A2UYZFH5VT5R3H      no\n",
       "                    4        A2HRAAY4QRTM7S      no\n",
       "                             A2UYZFH5VT5R3H      no\n",
       "                    5        A2HRAAY4QRTM7S     yes\n",
       "                             A2UYZFH5VT5R3H      no\n",
       "\n",
       "[1370 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- coin's kappa:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html\n",
    "\n",
    "- send back to labeling if there is disagreement or less than 2 labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
