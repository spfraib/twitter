{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = \"US\"\n",
    "if os.getenv('CLUSTER')=='PRINCE':\n",
    "    path_to_data='/scratch/spf248/twitter/data'\n",
    "else:\n",
    "    path_to_data='../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "if country_code=='US':\n",
    "    user_location_2_geo_id=pd.read_csv(os.path.join(path_to_data,'official','city',country_code,'user_location_2_geo_id_admin_2.csv'),index_col=0)\n",
    "    # Create Geo Id of Metro Areas\n",
    "    metro_area_name_2_geo_id=user_location_2_geo_id.drop_duplicates(\n",
    "    'metro_area_name').reset_index(drop=True).reset_index(\n",
    "    ).set_index('metro_area_name')['index'].rename('geo_id')\n",
    "    user_location_2_geo_id['geo_id']=user_location_2_geo_id['metro_area_name'].apply(\n",
    "    lambda x:metro_area_name_2_geo_id[x])\n",
    "    user_location_2_geo_id.to_csv(os.path.join(path_to_data,'official','city',country_code,'user_location_2_geo_id.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "if country_code!='US':\n",
    "    labor_market_stats=pd.read_csv(os.path.join(path_to_data,'official','city',country_code,'labor_market_stats.csv'),sep={'AR':';','BR':',','CO':';','MX':','}[country_code])\n",
    "    labor_market_stats.rename(columns={'value':'unemployment_rate','NAME':'metro_area_name'},inplace=True)\n",
    "    labor_market_stats['date']=pd.to_datetime(labor_market_stats.apply(lambda x:str(x['year'])+'-Q'+str(x['quarter']),1)) + pd.offsets.QuarterEnd(0)\n",
    "    labor_market_stats['month'] = labor_market_stats['date'].apply(lambda x:x.month)\n",
    "    labor_market_stats = labor_market_stats[['year','month','geo_id','unemployment_rate']].sort_values(\n",
    "    by=['year','month','geo_id']).reset_index(drop=True)\n",
    "    if country_code =='CO':\n",
    "        labor_market_stats.unemployment_rate=labor_market_stats.unemployment_rate.apply(lambda x:np.float(x.replace(',','.'))/100)\n",
    "    labor_market_stats.to_csv(os.path.join(path_to_data,'official','city',country_code,'time_series_unemployment_rate.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US - compute average rate across counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelfraiberger/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "if country_code=='US':\n",
    "    labor_market_stats=pd.read_csv(os.path.join(path_to_data,'official','city',country_code,'labor_market_stats.csv'),index_col=0)\n",
    "    pop_metro_area=pd.read_csv(os.path.join(path_to_data,'official','city',country_code,'pop_metro_area.csv'),index_col=0)\n",
    "    pop_metro_area=pop_metro_area.groupby(['metro_area_name','geo_id'],as_index=False)['pop'].mean()\n",
    "    df=labor_market_stats.merge(pop_metro_area,on='geo_id')\n",
    "    df['unemployment_rate']=df['unemployment_rate'].multiply(df['pop'])\n",
    "    df=df.groupby(['year','month','metro_area_name']).sum()\n",
    "    df=df['unemployment_rate'].divide(df['pop']).rename('unemployment_rate')\n",
    "    df/=100\n",
    "    df=df.to_frame().reset_index()\n",
    "    df['geo_id']=df['metro_area_name'].apply(lambda x:metro_area_name_2_geo_id.get(x,np.nan))\n",
    "    df=df.sort_values(by=['year','month','geo_id']).reset_index(drop=True).drop(['metro_area_name'],1).dropna()\n",
    "    df['geo_id']=df['geo_id'].astype(int)\n",
    "    df=df[['year', 'month', 'geo_id', 'unemployment_rate']].copy()\n",
    "    df.to_csv(os.path.join(path_to_data,'official','city',country_code,'time_series_unemployment_rate.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
