{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from glob import glob\n",
    "import json\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import psutil\n",
    "import socket\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Data After Downloading 100 Timelines\n"
     ]
    }
   ],
   "source": [
    "cutoff = 500\n",
    "print('Save Data After Downloading',cutoff,'Timelines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLURM_JOB_ID : 7987695\n",
      "SLURM_ARRAY_TASK_ID : 0 (Default)\n",
      "SLURM_ARRAY_TASK_COUNT : 1 (Default)\n",
      "SLURM_JOB_CPUS_PER_NODE : 20\n"
     ]
    }
   ],
   "source": [
    "def get_env_var(varname,default):\n",
    "    \n",
    "    if os.environ.get(varname) != None:\n",
    "        var = int(os.environ.get(varname))\n",
    "        print(varname,':', var)\n",
    "    else:\n",
    "        var = default\n",
    "        print(varname,':', var,'(Default)')\n",
    "    return var\n",
    "\n",
    "# Choose Number of Nodes To Distribute Credentials: e.g. jobarray=0-4, cpu_per_task=20, credentials = 90 (<100)\n",
    "SLURM_JOB_ID            = get_env_var('SLURM_JOB_ID',0)\n",
    "SLURM_ARRAY_TASK_ID     = get_env_var('SLURM_ARRAY_TASK_ID',0)\n",
    "SLURM_ARRAY_TASK_COUNT  = get_env_var('SLURM_ARRAY_TASK_COUNT',1)\n",
    "SLURM_JOB_CPUS_PER_NODE = get_env_var('SLURM_JOB_CPUS_PER_NODE',mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes=[\n",
    "# 'US',\n",
    "# 'ID',\n",
    "# 'BR',\n",
    "# 'TR',\n",
    "# 'MX',\n",
    "# 'AR',\n",
    "# 'PH',\n",
    "# 'CO',\n",
    "# 'MY',\n",
    "# 'VE',\n",
    "# 'TH',\n",
    "# 'PK',\n",
    "]\n",
    "\n",
    "country_codes=[\n",
    "'VE',\n",
    "'BR',\n",
    "'US',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/twitter/data/users\n",
      "/scratch/spf248/twitter/data/locations/profiles\n",
      "/scratch/spf248/twitter/data/keys/twitter\n",
      "/scratch/spf248/twitter/data/timelines/API\n"
     ]
    }
   ],
   "source": [
    "if 'samuel' in socket.gethostname().lower():\n",
    "    path_to_data='../../data'\n",
    "else:\n",
    "    path_to_data='/scratch/spf248/twitter/data'\n",
    "\n",
    "path_to_users = os.path.join(path_to_data,'users')\n",
    "path_to_locations = os.path.join(path_to_data,'locations','profiles')\n",
    "path_to_keys = os.path.join(path_to_data,'keys','twitter')\n",
    "path_to_timelines = os.path.join(path_to_data,'timelines','historical','API')\n",
    "os.makedirs(path_to_timelines, exist_ok=True)\n",
    "print(path_to_users)\n",
    "print(path_to_locations)\n",
    "print(path_to_keys)\n",
    "print(path_to_timelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check environment variables:\n",
      "# Credentials ( 49 ) > # CPU ( 20 )\n",
      "Only keeping 20 credentials\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-zohar.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-trevor.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-henry.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-ananth.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sam3.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sarah.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sam6.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-trevor.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dunstan.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-fab.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-martin.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sarah.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-carolina2.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dharana.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-dev.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-ananth.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-mukund.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-david.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sana.json\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-antoine.json\n"
     ]
    }
   ],
   "source": [
    "def get_key_files(SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT,SLURM_JOB_CPUS_PER_NODE):\n",
    "\n",
    "    # Randomize set of key files using constant seed\n",
    "    np.random.seed(0)\n",
    "    all_key_files = np.random.permutation(glob(os.path.join(path_to_keys,'*.json')))\n",
    "    \n",
    "    # Split file list by node\n",
    "    key_files = np.array_split(all_key_files,SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]\n",
    "    \n",
    "    # Check that node has more CPU than key file \n",
    "    if len(key_files) <= SLURM_JOB_CPUS_PER_NODE:\n",
    "        print('# Credentials Allocated To Node:', len(key_files)) \n",
    "    else:\n",
    "        print('Check environment variables:')\n",
    "        print('# Credentials (',len(key_files),') > # CPU (', SLURM_JOB_CPUS_PER_NODE,')')\n",
    "        print('Only keeping', SLURM_JOB_CPUS_PER_NODE, 'credentials')\n",
    "        key_files = key_files[:SLURM_JOB_CPUS_PER_NODE]\n",
    "        \n",
    "    return key_files\n",
    "\n",
    "key_files = get_key_files(SLURM_ARRAY_TASK_ID,SLURM_ARRAY_TASK_COUNT,SLURM_JOB_CPUS_PER_NODE)\n",
    "print('\\n'.join(key_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth(key_file):\n",
    "    \n",
    "    # Import Key\n",
    "    with open(key_file) as f:\n",
    "        key = json.load(f)\n",
    "\n",
    "    # OAuth process, using the keys and tokens\n",
    "    auth = tweepy.OAuthHandler(key['consumer_key'], key['consumer_secret'])\n",
    "    auth.set_access_token(key['access_token'], key['access_token_secret'])\n",
    "\n",
    "    # Creation of the actual interface, using authentication\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    try:\n",
    "        api.verify_credentials()\n",
    "        print(key_file,\": Authentication checked\")\n",
    "    except:\n",
    "        print(key_file,\": error during authentication\")\n",
    "        sys.exit('Exit')\n",
    "    \n",
    "    return api\n",
    "\n",
    "# for key_file in np.random.permutation(glob(os.path.join(path_to_keys,'*.json'))):\n",
    "#     get_auth(key_file)\n",
    "# print('Credentials Checked!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Users By Account Locations\n",
      "# Locations: 39779\n",
      "# Users Total: 92088032\n",
      "Computing Time: 170 sec\n"
     ]
    }
   ],
   "source": [
    "print('Import Users By Account Locations')\n",
    "start = timer()\n",
    "\n",
    "l = []\n",
    "for filename in sorted(glob(os.path.join(path_to_users,'user-ids-by-account-location-verified/*.json'))):\n",
    "    try:\n",
    "        df = pd.read_json(filename,lines=True)\n",
    "        l.append(df)\n",
    "    except:\n",
    "        print('error importing', filename)\n",
    "        \n",
    "users_by_account_location=pd.concat(l, axis=0, ignore_index=True)\n",
    "users_by_account_location=users_by_account_location.set_index('user_location')['user_id']\n",
    "users_by_account_location=users_by_account_location.apply(eval).apply(lambda x:[str(y) for y in x])\n",
    "print('# Locations:', len(users_by_account_location))\n",
    "print('# Users Total:', users_by_account_location.apply(len).sum())\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Locations\n",
      "# Locations: 39779\n"
     ]
    }
   ],
   "source": [
    "print('Import Locations')\n",
    "account_locations=pd.read_pickle(os.path.join(path_to_locations,'account-locations.pkl')) \n",
    "print('# Locations:', len(account_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Users...\n",
      "# Users : 27591849\n",
      "               user_id\n",
      "country_code          \n",
      "BR             4863404\n",
      "US            21205171\n",
      "VE             1523274\n",
      "Computing Time: 130 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Select Users...')\n",
    "\n",
    "# Sorted list of users in selected countries\n",
    "users=pd.merge(\n",
    "users_by_account_location.reindex(\n",
    "account_locations.loc[\n",
    "account_locations['country_short'].isin(country_codes),'user_location']).dropna().reset_index(),\n",
    "account_locations[['user_location','country_short']]).drop('user_location',1).rename(\n",
    "columns={'country_short':'country_code'}).explode('user_id').set_index('user_id')['country_code'].sort_index()\n",
    "\n",
    "# Randomize users\n",
    "users=users.sample(frac=1,random_state=0)\n",
    "\n",
    "del users_by_account_location\n",
    "del account_locations\n",
    "\n",
    "print('# Users :', len(users)) \n",
    "print(users.reset_index().groupby('country_code').count())\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Users Across Nodes...\n",
      "# Users : 27591849\n",
      "Computing Time: 2 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Split Users Across Nodes...')\n",
    "\n",
    "print('First user:', users.index[0])\n",
    "users=np.array_split(users,SLURM_ARRAY_TASK_COUNT)[SLURM_ARRAY_TASK_ID]\n",
    "print('# Users for this node:', len(users)) \n",
    "print('First user for this node:', users.index[0])\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nb of verified users in the US = 21,205,171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove users whose timeline were successfully downloaded...\n",
      "BR : 3577650\n",
      "US : 6257600\n",
      "VE : 719150\n",
      "# downloaded timelines: 10554400\n",
      "# remaining users for this node: 17421031\n",
      "Computing Time: 53 sec\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "print('Remove users whose timeline were successfully downloaded...')\n",
    "\n",
    "def get_success(country_code):\n",
    "    \n",
    "    if not os.path.exists(os.path.join(path_to_timelines, country_code, 'success')):\n",
    "        return set()\n",
    "    else:\n",
    "        success = set()\n",
    "        with open(os.path.join(path_to_timelines, country_code, 'success'), 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                success.add(line.strip('\\n').split('\\t')[0])\n",
    "        return set(success)\n",
    "\n",
    "success=set()\n",
    "for country_code in country_codes:\n",
    "    tmp=get_success(country_code)\n",
    "    print(country_code, ':', len(tmp))\n",
    "    success=success.union(tmp)\n",
    "print('# downloaded timelines:', len(success))\n",
    "\n",
    "users.drop(success,errors='ignore',inplace=True)\n",
    "print('# remaining users for this node:', len(users))\n",
    "\n",
    "# Group users by country\n",
    "users_by_country=users.reset_index().groupby('country_code')['user_id'].apply(list).reindex(country_codes)\n",
    "\n",
    "end = timer()\n",
    "print('Computing Time:', round(end - start), 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(user_id,api):\n",
    "    \n",
    "    timeline = []\n",
    "    error = None\n",
    "    \n",
    "    # Collect All Statuses in Timeline\n",
    "    try:\n",
    "        cursor = tweepy.Cursor(\n",
    "        api.user_timeline, \n",
    "        user_id=user_id, \n",
    "        count=3200,\n",
    "        tweet_mode=\"extended\", \n",
    "        include_rts=True).items()\n",
    "        \n",
    "        for status in cursor:\n",
    "            timeline.append(status._json)\n",
    "     \n",
    "    except tweepy.error.TweepError as e:\n",
    "        error = str(e)\n",
    "        \n",
    "    return pd.DataFrame(timeline), error\n",
    "\n",
    "# timeline = get_user_timeline('12',get_auth(key_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_timelines(index_key,country_code):\n",
    "\n",
    "    # Create Access For Block of Users\n",
    "    api = get_auth(key_files[index_key])\n",
    "    \n",
    "    # Select Block of Users\n",
    "    users_block = np.array_split(users_by_country[country_code],len(key_files))[index_key]\n",
    "    \n",
    "    # Initialize Output File ID\n",
    "    output_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Initialize DataFrame\n",
    "    timelines = pd.DataFrame()\n",
    "    \n",
    "    # Initialize Downloaded User List\n",
    "    downloaded_ids = []\n",
    "    \n",
    "    for user_id in users_block:\n",
    "        \n",
    "        # Try Downloading Timeline\n",
    "        timeline, error = get_timeline(user_id,api)\n",
    "        \n",
    "        if error!=None:\n",
    "#             print(user_id,index_key,error)\n",
    "            continue\n",
    "            \n",
    "        # Append\n",
    "        timelines = pd.concat([timelines, timeline],sort=False)\n",
    "        downloaded_ids.append(user_id)\n",
    "            \n",
    "        # Save after <cutoff> timelines or when reaching last user\n",
    "        if len(downloaded_ids) == cutoff or user_id == users_block[-1]:\n",
    "            \n",
    "            filename = \\\n",
    "            'timelines-'+\\\n",
    "            str(SLURM_JOB_ID)+'-'+\\\n",
    "            str(SLURM_ARRAY_TASK_ID)+'-'+\\\n",
    "            str(index_key)+'-'+\\\n",
    "            str(len(downloaded_ids))+'-'+\\\n",
    "            output_id+'.json.bz2'\n",
    "            \n",
    "            print('Process', index_key, 'saving', len(downloaded_ids), 'timelines with output file:', \n",
    "            os.path.join(path_to_timelines,country_code,filename))\n",
    "            \n",
    "            # Save as list of dict discarding index\n",
    "            timelines.to_json(\n",
    "            os.path.join(path_to_timelines,country_code,filename),\n",
    "            orient='records',\n",
    "            force_ascii=False,\n",
    "            date_format=None,\n",
    "            double_precision=15)\n",
    "            \n",
    "            # Save User Id and File In Which Its Timeline Was Saved\n",
    "            with open(os.path.join(path_to_timelines,country_code,'success'), 'a', encoding='utf-8') as file:\n",
    "                for downloaded_id in downloaded_ids:\n",
    "                    file.write(downloaded_id+'\\t'+filename+'\\n')\n",
    "            \n",
    "            # Reset Output File ID, Data, and Downloaded Users\n",
    "            del timelines, downloaded_ids\n",
    "            output_id = str(uuid.uuid4())\n",
    "            timelines = pd.DataFrame()\n",
    "            downloaded_ids = []\n",
    "            \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Timelines...\n",
      "\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sarah.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sana.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sarah.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-trevor.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-dev.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-mukund.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-henry.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-david.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-trevor.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dunstan.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sam6.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-zohar.json : Authentication checked\n",
      "VE\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-antoine.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sam3.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-carolina2.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-ananth.json : Authentication checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dharana.json : Authentication checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 18\n",
      "Rate limit reached. Sleeping for: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-fab.json : Authentication checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 16\n",
      "Rate limit reached. Sleeping for: 36\n",
      "Rate limit reached. Sleeping for: 16\n",
      "Rate limit reached. Sleeping for: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-ananth.json : Authentication checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 13\n",
      "Rate limit reached. Sleeping for: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-martin.json : Authentication checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 5 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-5-9-46a4c29b-27db-4938-94d9-6bbab69c0941.json.bz2\n",
      "Process 3 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-3-9-09f19a79-7d5a-4903-a65f-fd13ba3f349d.json.bz2\n",
      "Process 4 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-4-8-8a987af5-c525-47c2-8690-8b2e0af31990.json.bz2\n",
      "Process 1 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-1-8-19a4f368-2602-45f6-ac72-794236ce44b5.json.bz2\n",
      "Process 13 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-13-10-6c6abdd3-6918-4020-8c2f-26cb40d0bddd.json.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 15 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-15-9-6eb49597-1c63-4f4e-816d-b8057980a738.json.bz2\n",
      "Process 16 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-16-9-886f19d6-15ef-4ec8-ad4a-6bd7e276f8b9.json.bz2\n",
      "Process 0 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-0-9-2f323a95-a85a-4f43-b5d1-c9e74feb0b9f.json.bz2\n",
      "Process 19 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-19-9-4405e9ec-0b5f-42e2-b3fa-94ec993743ea.json.bz2\n",
      "Process 2 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-2-8-0921b3f1-870c-4a18-bbfc-37a77e7cbd40.json.bz2\n",
      "Process 7 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-7-10-44a929c2-75d6-4c76-8beb-46face305a68.json.bz2\n",
      "Process 11 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-11-8-4d8d9ff7-901c-4ad6-a63a-92dfe911631e.json.bz2\n",
      "Process 8 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-8-10-18baf445-f6e4-42cf-9ad5-78076d8e64a5.json.bz2\n",
      "Process 14 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-14-8-4815f776-f250-449c-a8e5-10622b151a7b.json.bz2\n",
      "Process 18 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-18-9-236a95e9-e873-40f2-8cdc-d722aedf3400.json.bz2\n",
      "Process 12 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-12-9-04456184-aef1-40b7-976f-b3940205e7df.json.bz2\n",
      "Process 9 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-9-9-7296bcbc-b065-4d81-af51-3f19fca2c6ca.json.bz2\n",
      "Process 10 saving 7 timelines with output file: /scratch/spf248/twitter/data/timelines/API/VE/timelines-7987695-0-10-7-97f778f3-0442-40c8-be03-69ac56f87579.json.bz2\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-mukund.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sarah.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-ananth.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-antoine.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sana.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sarah.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sam3.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-zohar.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-martin.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-fab.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-henry.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-david.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-trevor.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sam6.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dharana.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-dev.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-trevor.json : Authentication checked\n",
      "BR\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dunstan.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-ananth.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-carolina2.json : Authentication checked\n",
      "Process 8 saving 7 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-8-7-94bbe485-33d5-40d1-9e9e-24ccb04bd703.json.bz2\n",
      "Process 2 saving 6 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-2-6-60c55a50-164a-41fe-a742-7077c766b8f1.json.bz2\n",
      "Process 7 saving 6 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-7-6-d0608a33-1f7f-4793-a42b-1923af7f3fa8.json.bz2\n",
      "Process 4 saving 7 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-4-7-1e96930f-5108-478d-af23-e62772d59e41.json.bz2\n",
      "Process 13 saving 6 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-13-6-8fc42330-ee0d-4a03-84a7-ff2eccf63ad7.json.bz2\n",
      "Process 10 saving 6 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-10-6-c80a6f0a-7463-438e-a1bd-ac84fc53f12a.json.bz2\n",
      "Process 18 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-18-9-b68662ad-c532-4b40-9983-5f29292dc4c1.json.bz2\n",
      "Process 1 saving 7 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-1-7-794c34b2-f5ba-4f58-aa1c-44bc875f56e7.json.bz2\n",
      "Process 12 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-12-8-f0f2b445-f63e-4c90-b7d5-2bbf598bfcfb.json.bz2\n",
      "Process 5 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-5-9-ed1d027e-d3fa-481d-b4e2-8f7321473073.json.bz2\n",
      "Process 9 saving 6 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-9-6-b5a8219c-da2e-4864-a2e9-a107efe5ba5a.json.bz2\n",
      "Process 19 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-19-9-b4669b3f-a67d-4a00-bc59-31c930353ee4.json.bz2\n",
      "Process 16 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-16-8-46fe9918-c18c-4dc1-a663-28578c391c5c.json.bz2\n",
      "Process 6 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-6-8-20b60be5-79c9-417c-acc2-398ac0f34edc.json.bz2\n",
      "Process 15 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/BR/timelines-7987695-0-15-8-2f5fac94-06ba-4ae5-b2ee-838307f8a270.json.bz2\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sam3.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-zohar.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-ananth.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dharana.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-sarah.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sam6.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-henry.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sana.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-ananth.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-mukund.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-david.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-dev.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-trevor.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-martin.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-antoine.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-sarah.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-dunstan.json : Authentication checked\n",
      "US\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-fab.json : Authentication checked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/spf248/twitter/data/keys/twitter/spfraib_sentiments-trevor.json : Authentication checked\n",
      "/scratch/spf248/twitter/data/keys/twitter/WorldBankGroup6-carolina2.json : Authentication checked\n",
      "Process 14 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-14-9-db89f877-5576-4584-b933-ed31a12937a9.json.bz2\n",
      "Process 12 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-12-8-59c7324a-105d-44c0-81dc-87f104f2cdc9.json.bz2\n",
      "Process 8 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-8-8-e08fef95-e79d-4aa9-8d1c-63fbc7882fc7.json.bz2\n",
      "Process 9 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-9-10-f0e345ef-6804-4412-875d-82e5399b785a.json.bz2\n",
      "Process 10 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-10-9-59e41204-9c22-44db-b087-02ea7013a0db.json.bz2\n",
      "Process 0 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-0-10-c2b34cce-bc25-473e-ab95-b8fe3e19ef83.json.bz2\n",
      "Process 3 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-3-9-437688dd-5b6c-4ffc-a185-d6933028325d.json.bz2\n",
      "Process 5 saving 8 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-5-8-811c436f-0103-4923-ab16-7fdc585c1e4d.json.bz2\n",
      "Process 11 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-11-10-f334c144-865e-40f3-9e6c-12f568d130d8.json.bz2\n",
      "Process 19 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-19-9-7151526b-f027-49b6-9a03-147a2c0c57ff.json.bz2\n",
      "Process 15 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-15-10-78a81208-4d37-473a-9f9a-ce85727d7c3e.json.bz2\n",
      "Process 13 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-13-9-edb27192-cb22-4d99-90ce-80de1a6b303c.json.bz2\n",
      "Process 6 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-6-9-3281ad08-e813-4b79-98f0-4eaedd384cc3.json.bz2\n",
      "Process 2 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-2-10-25f90a99-8bd4-4e58-8c5a-879c174947a3.json.bz2\n",
      "Process 7 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-7-10-6ca1e829-80e0-4a16-8eaa-ee90d9908cf5.json.bz2\n",
      "Process 16 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-16-10-8b67d58b-b485-40ca-8a9f-fdc1cf746d64.json.bz2\n",
      "Process 4 saving 10 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-4-10-2e038108-1272-4415-8d77-099beb5c7a2f.json.bz2\n",
      "Process 1 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-1-9-7d15d8a4-c25d-453b-b509-5ab889320ad3.json.bz2\n",
      "Process 17 saving 9 timelines with output file: /scratch/spf248/twitter/data/timelines/API/US/timelines-7987695-0-17-9-e393fa65-004f-4ad8-875d-a02d269ad7a4.json.bz2\n"
     ]
    }
   ],
   "source": [
    "print('Extract Timelines...\\n')\n",
    "with mp.Pool() as pool:\n",
    "    for country_code in country_codes:\n",
    "        print(country_code)\n",
    "        pool.map(partial(download_timelines, country_code=country_code), range(len(key_files)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
