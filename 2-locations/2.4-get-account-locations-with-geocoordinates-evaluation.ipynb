{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import more_itertools as mit\n",
    "from fuzzywuzzy import fuzz\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../../data/locations/profiles/geocoding/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Acount Location Data...\n",
      "# Selected Account locations (After String Cleaning): 41115\n",
      "Done in 0 sec\n"
     ]
    }
   ],
   "source": [
    "print('Import Acount Location Data...')\n",
    "start = timer()\n",
    "\n",
    "# Account Location, Average User Geolocation, Number of Users\n",
    "account_locations = pd.read_pickle(path_to_data+'account-locations-to-geocode.pkl')\n",
    "print('# Selected Account locations (After String Cleaning):', account_locations.shape[0])\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>POINT</th>\n",
       "      <th>N</th>\n",
       "      <th>CC</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>(-5.53034, 106.54255)</td>\n",
       "      <td>98240</td>\n",
       "      <td>ID</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>(49.01730709, 1.43906842)</td>\n",
       "      <td>88896</td>\n",
       "      <td>FR</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>(-17.99120486, -45.60141543)</td>\n",
       "      <td>70885</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jakarta</td>\n",
       "      <td>(-5.19392835, 103.92920358)</td>\n",
       "      <td>55842</td>\n",
       "      <td>ID</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippines</td>\n",
       "      <td>(14.604133, 120.017236)</td>\n",
       "      <td>51989</td>\n",
       "      <td>PH</td>\n",
       "      <td>Philippines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LOCATION                         POINT      N  CC      COUNTRY\n",
       "0    Indonesia         (-5.53034, 106.54255)  98240  ID    Indonesia\n",
       "1       London     (49.01730709, 1.43906842)  88896  FR       France\n",
       "2       Brasil  (-17.99120486, -45.60141543)  70885  BR       Brazil\n",
       "3      Jakarta   (-5.19392835, 103.92920358)  55842  ID    Indonesia\n",
       "4  Philippines       (14.604133, 120.017236)  51989  PH  Philippines"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Merge, and Format Geocodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_of_interest = frozenset([\n",
    "'country',\n",
    "'locality',\n",
    "'sublocality',\n",
    "'neighborhood',\n",
    "'administrative_area_level_1',\n",
    "'administrative_area_level_2',\n",
    "'administrative_area_level_3',\n",
    "'administrative_area_level_4',\n",
    "])\n",
    "\n",
    "def nth_result(response,n):\n",
    "\n",
    "    formatted_result = {}\n",
    "    \n",
    "    #Only Consider First result\n",
    "    nth_result = mit.nth(response['results'], n, None)\n",
    "    \n",
    "    if not nth_result:\n",
    "        return pd.Series()\n",
    "        \n",
    "    for component in nth_result['address_components']:\n",
    "\n",
    "        for type_of_interest in types_of_interest:\n",
    "\n",
    "            if type_of_interest in component['types']:\n",
    "\n",
    "                formatted_result[type_of_interest+'_long'] = component['long_name']\n",
    "                formatted_result[type_of_interest+'_short'] = component['short_name']\n",
    "            \n",
    "    return pd.Series(formatted_result)\n",
    "\n",
    "def match(x):\n",
    "    try:\n",
    "        return fuzz.token_set_ratio(\n",
    "        x['LOCATION'].lower(),\n",
    "        x['formatted_address'].lower())\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def is_ascii(x):\n",
    "    try:\n",
    "        return int(x==x.encode('utf-8').decode('ascii'))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def of_interest(x):\n",
    "    try: \n",
    "        return int(len(list(set(x.split(',')).intersection(list(types_of_interest))))>0)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Geocoded Data...\n",
      "# Geocoded locations: 428399\n",
      "Done in 15 sec\n"
     ]
    }
   ],
   "source": [
    "print('Import Geocoded Data...')\n",
    "start = timer()\n",
    "\n",
    "# Account Locations Geocoded Using the Google API\n",
    "geocoded_locations = pd.read_pickle(path_to_data+'account-locations-geocoded.pkl')\n",
    "print('# Geocoded locations:', geocoded_locations.shape[0])\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>formatted_address</th>\n",
       "      <th>google_place_id</th>\n",
       "      <th>input_string</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_results</th>\n",
       "      <th>postcode</th>\n",
       "      <th>response</th>\n",
       "      <th>status</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPROXIMATE</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>ChIJtwRkSdcHTCwRhfStG-dNe-M</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>-0.789275</td>\n",
       "      <td>113.921327</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>{'results': [{'address_components': [{'long_na...</td>\n",
       "      <td>OK</td>\n",
       "      <td>country,political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APPROXIMATE</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>ChIJdd4hrwug2EcRmSrV3Vo6llI</td>\n",
       "      <td>London</td>\n",
       "      <td>51.507351</td>\n",
       "      <td>-0.127758</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>{'results': [{'address_components': [{'long_na...</td>\n",
       "      <td>OK</td>\n",
       "      <td>locality,political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APPROXIMATE</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>ChIJzyjM68dZnAARYz4p8gYVWik</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>-14.235004</td>\n",
       "      <td>-51.925280</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>{'results': [{'address_components': [{'long_na...</td>\n",
       "      <td>OK</td>\n",
       "      <td>country,political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APPROXIMATE</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>ChIJnUvjRenzaS4RoobX2g-_cVM</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>-6.208763</td>\n",
       "      <td>106.845599</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>{'results': [{'address_components': [{'long_na...</td>\n",
       "      <td>OK</td>\n",
       "      <td>colloquial_area,locality,political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APPROXIMATE</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>ChIJY96HXyFTQDIRV9opeu-QR3g</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>12.879721</td>\n",
       "      <td>121.774017</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>{'results': [{'address_components': [{'long_na...</td>\n",
       "      <td>OK</td>\n",
       "      <td>country,political</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy   formatted_address              google_place_id input_string  \\\n",
       "0  APPROXIMATE           Indonesia  ChIJtwRkSdcHTCwRhfStG-dNe-M    Indonesia   \n",
       "1  APPROXIMATE          London, UK  ChIJdd4hrwug2EcRmSrV3Vo6llI       London   \n",
       "2  APPROXIMATE              Brazil  ChIJzyjM68dZnAARYz4p8gYVWik       Brasil   \n",
       "3  APPROXIMATE  Jakarta, Indonesia  ChIJnUvjRenzaS4RoobX2g-_cVM      Jakarta   \n",
       "4  APPROXIMATE         Philippines  ChIJY96HXyFTQDIRV9opeu-QR3g  Philippines   \n",
       "\n",
       "    latitude   longitude  number_of_results postcode  \\\n",
       "0  -0.789275  113.921327                  1            \n",
       "1  51.507351   -0.127758                  1            \n",
       "2 -14.235004  -51.925280                  1            \n",
       "3  -6.208763  106.845599                  1            \n",
       "4  12.879721  121.774017                  1            \n",
       "\n",
       "                                            response status  \\\n",
       "0  {'results': [{'address_components': [{'long_na...     OK   \n",
       "1  {'results': [{'address_components': [{'long_na...     OK   \n",
       "2  {'results': [{'address_components': [{'long_na...     OK   \n",
       "3  {'results': [{'address_components': [{'long_na...     OK   \n",
       "4  {'results': [{'address_components': [{'long_na...     OK   \n",
       "\n",
       "                                 type  \n",
       "0                   country,political  \n",
       "1                  locality,political  \n",
       "2                   country,political  \n",
       "3  colloquial_area,locality,political  \n",
       "4                   country,political  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geocoded_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop extra geocodes:\n",
      "# Geocoded locations: 40994\n"
     ]
    }
   ],
   "source": [
    "print('Drop extra geocodes:')\n",
    "geocoded_locations = geocoded_locations[\n",
    "geocoded_locations['input_string'].isin(account_locations['LOCATION'])].copy()\n",
    "print('# Geocoded locations:', geocoded_locations.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format First Geocoded Result:\n",
      "Done in 19 sec\n"
     ]
    }
   ],
   "source": [
    "# Discarded 173 locations with 2238 users matched with secondary results\n",
    "print('Format First Geocoded Result:')\n",
    "start = timer()\n",
    "\n",
    "geocoded_locations = pd.concat([geocoded_locations,\n",
    "geocoded_locations['response'].apply(lambda x: nth_result(x, 0))],1)\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Location Data...\n",
      "# Locations: 41115\n",
      "#Users At Selected Locations: 9050984\n",
      "Done in 3 sec\n"
     ]
    }
   ],
   "source": [
    "print('Merge Location Data...')\n",
    "start = timer()\n",
    "\n",
    "# Could measure distance with geocoordinates to identify homonyms and missclassified reversed geocodes\n",
    "locations = pd.merge(\n",
    "account_locations,\n",
    "geocoded_locations.drop([\n",
    "'accuracy',\n",
    "'google_place_id',\n",
    "'postcode',\n",
    "'number_of_results', \n",
    "'response',\n",
    "],1,errors='ignore'),\n",
    "left_on='LOCATION',\n",
    "right_on='input_string',\n",
    "how='left').drop(\n",
    "'input_string',1).sort_values(\n",
    "by='N',ascending=False)\n",
    "\n",
    "del geocoded_locations\n",
    "\n",
    "locations['MATCH']    = locations.apply(match,1)\n",
    "locations['ASCII']    = locations['LOCATION'].apply(is_ascii)\n",
    "locations['INTEREST'] = locations['type'].apply(of_interest)\n",
    "\n",
    "print('# Locations:',locations.shape[0])\n",
    "print('#Users At Selected Locations:',locations['N'].sum())\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprocess With Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Locations To Be Reprocessed With Bias Iteratively, Discarding The Ones Already Inlcuded (Gives Priority To Manually Included Bias)\n",
    "def update_reprocess(locations_and_bias,reprocess_with_bias):\n",
    "    reprocess_with_bias.update({k:v for k,v in locations_and_bias.items() if k not in reprocess_with_bias})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprocess_with_bias = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Locations With Manually Included Bias: 39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('(d)mv', 'Delaware'),\n",
       " ('+65', 'Singapore'),\n",
       " ('ad', 'UAE'),\n",
       " ('almagro', 'Argentina'),\n",
       " ('amman_jordan', 'Jordan'),\n",
       " ('aus', 'Australia'),\n",
       " ('bayonne', 'France'),\n",
       " ('brighton', 'GB'),\n",
       " ('cali', 'Mexico'),\n",
       " ('canterbury', 'GB')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Account Locations With Manually Included Bias (Some Belong To Homonyms)\n",
    "location2region = []\n",
    "with open(path_to_data+'account-locations-to-region.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        location2region.append(line.strip('\\n').split('\\t'))\n",
    "location2region = dict(location2region)\n",
    "print('# Locations With Manually Included Bias:',len(location2region))\n",
    "list(location2region.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations To Reprocess With Manually Added Regional Bias: 117\n",
      "Total Reprocessed With Bias: 117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Ireland', 'Ireland'),\n",
       " ('Valencia', 'Spain'),\n",
       " ('Cali', 'Mexico'),\n",
       " ('Córdoba', 'Argentina'),\n",
       " ('Brighton', 'GB'),\n",
       " ('Korea', 'South Korea'),\n",
       " ('Cordoba', 'Argentina'),\n",
       " ('korea', 'South Korea'),\n",
       " ('valencia', 'Spain'),\n",
       " ('DMV', 'Delaware, Maryland, Virginia')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Locations\n",
    "locations_with_fixed_region = \\\n",
    "list(locations.loc[locations['LOCATION'].apply(lambda x:x.strip().lower() in location2region),'LOCATION'])\n",
    "\n",
    "# Include Bias\n",
    "locations_with_fixed_region = \\\n",
    "dict([[x,location2region[x.lower().strip()]] for x in locations_with_fixed_region])\n",
    "\n",
    "# Update list\n",
    "update_reprocess(locations_with_fixed_region, reprocess_with_bias)\n",
    "\n",
    "print('Locations To Reprocess With Manually Added Regional Bias:', len(locations_with_fixed_region))\n",
    "print('Total Reprocessed With Bias:', len(reprocess_with_bias))\n",
    "list(locations_with_fixed_region.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations To Reprocess With Geolocated Bias: 121\n",
      "Total Reprocessed With Bias: 233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Trinidad & Tobago', 'Trinidad and Tobago'),\n",
       " ('Texas!', 'United States of America'),\n",
       " ('Jakarta | Indonesia', 'Indonesia'),\n",
       " ('Jakarta_Indonesia', 'Indonesia'),\n",
       " ('Singapore!', 'Malaysia'),\n",
       " ('Republic of the Philippines :)', 'Philippines'),\n",
       " ('Philippines :)', 'Philippines'),\n",
       " ('Colombia!', 'Colombia'),\n",
       " ('Venezuela!', 'Venezuela, Bolivarian Republic of'),\n",
       " ('California!', 'United States of America')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_forgotten = dict(locations.loc[locations['status'].isnull(),['LOCATION','COUNTRY']].values.tolist())\n",
    "\n",
    "# Update list\n",
    "update_reprocess(locations_forgotten, reprocess_with_bias)\n",
    "\n",
    "print('Locations To Reprocess With Geolocated Bias:', len(locations_forgotten))\n",
    "print('Total Reprocessed With Bias:', len(reprocess_with_bias))\n",
    "list(locations_forgotten.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed Locations To Reprocess With Geolocated Bias: 48\n",
      "Total Reprocessed With Bias: 278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('関西', 'Japan'),\n",
       " ('関東', 'Japan'),\n",
       " ('North East England',\n",
       "  'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('North West, England',\n",
       "  'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('SG', 'Malaysia'),\n",
       " ('North East, England',\n",
       "  'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Venezuela♥', 'Venezuela, Bolivarian Republic of'),\n",
       " ('North West England',\n",
       "  'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Argentina♥', 'Argentina'),\n",
       " ('sg', 'Malaysia')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_missed = dict(locations.loc[locations['status']=='ZERO_RESULTS',['LOCATION','COUNTRY']].values.tolist())\n",
    "\n",
    "# Update list\n",
    "update_reprocess(locations_missed, reprocess_with_bias)\n",
    "\n",
    "print('Missed Locations To Reprocess With Geolocated Bias:', len(locations_missed))\n",
    "print('Total Reprocessed With Bias:', len(reprocess_with_bias))\n",
    "list(locations_missed.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Homonyms: 252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abingdon',\n",
       " 'acre',\n",
       " 'airdrie',\n",
       " 'alberton',\n",
       " 'alex',\n",
       " 'alexandria',\n",
       " 'almagro',\n",
       " 'almonte',\n",
       " 'alton',\n",
       " 'amesbury']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Account Locations With Homonyms (Geocoded Using Geolocated Country Bias)\n",
    "homonyms = []\n",
    "with open(path_to_data+'account-locations-homonyms.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        homonyms.append(line.strip('\\n'))\n",
    "print('# Homonyms:',len(homonyms))\n",
    "homonyms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations With Homonyms To Reprocess With Geolocated Bias: 570\n",
      "Total Reprocessed With Bias: 795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Liverpool', 'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Birmingham', 'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Nederland', 'Belgium'),\n",
       " ('Cali', 'Mexico'),\n",
       " ('Córdoba', 'Brazil'),\n",
       " ('liverpool', 'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Kent', 'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Norwich', 'United Kingdom of Great Britain and Northern Ireland'),\n",
       " ('Cordoba', 'Brazil'),\n",
       " ('Jersey', 'United States of America')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_with_homonyms = dict(locations.loc[\n",
    "locations['LOCATION'].apply(lambda x:x.strip().lower() in homonyms),\n",
    "['LOCATION','COUNTRY']].values.tolist())\n",
    "\n",
    "# Update list\n",
    "update_reprocess(locations_with_homonyms, reprocess_with_bias)\n",
    "\n",
    "print('Locations With Homonyms To Reprocess With Geolocated Bias:', len(locations_with_homonyms))\n",
    "print('Total Reprocessed With Bias:', len(reprocess_with_bias))\n",
    "list(locations_with_homonyms.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninteresting Location To Reprocess With Geolocated Bias: 3312\n",
      "Total Reprocessed With Bias: 4021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Barcelona', 'Spain'),\n",
       " ('Ireland', 'Ireland'),\n",
       " ('Valencia', 'Portugal'),\n",
       " ('Roma', 'Italy'),\n",
       " ('Milano', 'Italy'),\n",
       " ('Italia', 'Italy'),\n",
       " ('MNL', 'Philippines'),\n",
       " ('Bali', 'Indonesia'),\n",
       " ('Adana', 'Turkey'),\n",
       " ('New York, New York', 'United States of America')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_uninteresting = dict(locations.loc[locations['INTEREST']==0,['LOCATION','COUNTRY']].values.tolist())\n",
    "\n",
    "# Update list\n",
    "update_reprocess(locations_uninteresting, reprocess_with_bias)\n",
    "\n",
    "print('Uninteresting Location To Reprocess With Geolocated Bias:', len(locations_uninteresting))\n",
    "print('Total Reprocessed With Bias:', len(reprocess_with_bias))\n",
    "list(locations_uninteresting.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Locations To Be Reprocessed With Bias:\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Save Locations To Be Reprocessed With Bias:')\n",
    "reprocess_with_bias = pd.DataFrame(pd.Series(reprocess_with_bias,name='BIAS'))\n",
    "reprocess_with_bias.index.name='LOCATION'\n",
    "reprocess_with_bias.reset_index(inplace=True)\n",
    "reprocess_with_bias.to_pickle(path_to_data+'account-locations-to-geocode-with-bias.pkl')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>BIAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valencia</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cali</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Córdoba</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOCATION       BIAS\n",
       "0   Ireland    Ireland\n",
       "1  Valencia      Spain\n",
       "2      Cali     Mexico\n",
       "3   Córdoba  Argentina\n",
       "4  Brighton         GB"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reprocess_with_bias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verified Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Locations To be Reprocessed\n",
    "locations = locations[-locations['LOCATION'].isin(reprocess_with_bias['LOCATION'])].copy()\n",
    "\n",
    "verified = []\n",
    "dropped  = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When N reaches ~50 and users average geolocation differ from their account location, it sometimes indicates that users manually entered a location that might be identified by geocoding but does correspond to their actual location. Their account location might the city they are from or that they identify with. We decided to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# dropped locations: 775 of 37094\n",
      "# verified locations: 1280 of 36319\n",
      "# verified locations: 36319 of 36319\n"
     ]
    }
   ],
   "source": [
    "dropped += list(locations.loc[(locations['N']<50)&(locations['CC']!=locations['country_short']),'LOCATION'])\n",
    "print('# dropped locations:',len(dropped),'of',locations.shape[0])\n",
    "\n",
    "# Checked \n",
    "verified += list(locations.loc[(locations['N']>=50)&(locations['CC']!=locations['country_short']),'LOCATION'])\n",
    "print('# verified locations:',len(verified),'of',locations.shape[0]-len(dropped))\n",
    "\n",
    "# Checked bottom 500 N and Match\n",
    "verified += list(locations.loc[(locations['CC']==locations['country_short']),'LOCATION'])\n",
    "print('# verified locations:',len(verified),'of',locations.shape[0]-len(dropped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Merge, and Format Geocodes Reprocessed With Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_with_bias = []\n",
    "dropped_with_bias  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Geocoded locations: 5004\n"
     ]
    }
   ],
   "source": [
    "# Account Locations Geocoded Using the Google API\n",
    "geocoded_locations_with_bias = pd.read_pickle(path_to_data+'account-locations-geocoded-with-bias.pkl')\n",
    "print('# Geocoded locations:', geocoded_locations_with_bias.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge and Format:\n",
      "# Locations Geocoded With Bias: 4021\n",
      "# Locations Geocoded With Bias With Result: 3469\n",
      "Done in 2 sec\n"
     ]
    }
   ],
   "source": [
    "print('Merge and Format:')\n",
    "start = timer()\n",
    "\n",
    "# Merge Geocoded Locations With Reprocessed Locations (The Latter Keeps Being Updated So Use Left Merge)\n",
    "locations_with_bias = pd.merge(\n",
    "reprocess_with_bias[['LOCATION']],\n",
    "geocoded_locations_with_bias,\n",
    "left_on='LOCATION',\n",
    "right_on='raw_string',\n",
    "how='left').drop('raw_string',1)\n",
    "\n",
    "locations_with_bias = pd.merge(\n",
    "locations_with_bias,\n",
    "account_locations[['LOCATION','N','CC']],\n",
    "how='left')\n",
    "\n",
    "del geocoded_locations_with_bias\n",
    "\n",
    "print('# Locations Geocoded With Bias:', locations_with_bias.shape[0])\n",
    "\n",
    "locations_with_bias.sort_values(by='N',ascending=False,inplace=True)\n",
    "\n",
    "dropped_with_bias+=list(locations_with_bias.loc[locations_with_bias['status']!='OK','LOCATION'])\n",
    "\n",
    "locations_with_bias = locations_with_bias[locations_with_bias['status']=='OK'].copy()\n",
    "\n",
    "print('# Locations Geocoded With Bias With Result:', locations_with_bias.shape[0])\n",
    "\n",
    "locations_with_bias = locations_with_bias[[\n",
    "'LOCATION', \n",
    "'input_string',\n",
    "'N',\n",
    "'CC',\n",
    "'formatted_address', \n",
    "'latitude', \n",
    "'longitude', \n",
    "'response',\n",
    "'type',\n",
    "]].reset_index(drop=True).copy()\n",
    "\n",
    "locations_with_bias = pd.concat([locations_with_bias,\n",
    "locations_with_bias['response'].apply(lambda x: nth_result(x, 0))],1)\n",
    "del locations_with_bias['response']\n",
    "\n",
    "locations_with_bias['MATCH'] = locations_with_bias.apply(match,1)\n",
    "locations_with_bias['ASCII'] = locations_with_bias['LOCATION'].apply(is_ascii)\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cali', 'Baja California, Mexico'),\n",
       " ('dmv', 'USA'),\n",
       " ('toledo', 'Toledo, Spain'),\n",
       " ('mia', 'Miami, USA'),\n",
       " ('qc', 'Qatar City'),\n",
       " ('(d)mv', 'Delaware, USA'),\n",
       " ('d(m)v', 'Maryland, USA'),\n",
       " ('dm(v)', 'Virginia, USA'),\n",
       " ('brighton & hove', 'Brighton, UK'),\n",
       " ('brighton & hove, uk', 'Brighton, UK')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locations That Were Not Identified With Country Bias --> Reprocessed With Manually Included Bias\n",
    "location2manual = {}\n",
    "with open(path_to_data+'account-locations-to-manual.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        key,value = line.strip('\\n').split('\\t',1)\n",
    "        location2manual.update({key:value})\n",
    "list(location2manual.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Locations To Be Reprocessed Manually:\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Save Locations To Be Reprocessed Manually:')\n",
    "\n",
    "# Find Locations\n",
    "reprocess_manually = \\\n",
    "list(locations_with_bias.loc[locations_with_bias['LOCATION'].apply(\n",
    "lambda x:x.strip().lower() in location2manual),'LOCATION'])\n",
    "\n",
    "# Map Into fixed locations\n",
    "reprocess_manually = \\\n",
    "dict([[x,location2manual[x.lower().strip()]] for x in reprocess_manually])\n",
    "\n",
    "reprocess_manually = pd.DataFrame(pd.Series(reprocess_manually,name='FIXED'))\n",
    "reprocess_manually.index.name='LOCATION'\n",
    "reprocess_manually.reset_index(inplace=True)\n",
    "reprocess_manually.to_pickle(path_to_data+'account-locations-to-geocode-manually.pkl')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>FIXED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Liverpool, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nederland</td>\n",
       "      <td>Netherland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cali</td>\n",
       "      <td>Baja California, Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PH</td>\n",
       "      <td>Philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liverpool</td>\n",
       "      <td>Liverpool, UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LOCATION                    FIXED\n",
       "0  Liverpool            Liverpool, UK\n",
       "1  Nederland               Netherland\n",
       "2       Cali  Baja California, Mexico\n",
       "3         PH              Philippines\n",
       "4  liverpool            Liverpool, UK"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reprocess_manually.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# verified locations: 92 of 2810\n",
      "# verified locations: 197 of 2810\n",
      "# verified locations: 204 of 2810\n",
      "# verified locations: 667 of 2810\n",
      "# verified locations: 2810 of 2810\n"
     ]
    }
   ],
   "source": [
    "locations_with_bias = \\\n",
    "locations_with_bias[-locations_with_bias['LOCATION'].isin(reprocess_manually['LOCATION'])].copy()\n",
    "\n",
    "verified_with_bias += list(locations_with_bias.loc[\n",
    "locations_with_bias['LOCATION'].isin(locations_with_fixed_region),'LOCATION'])\n",
    "verified_with_bias = list(set(verified_with_bias))\n",
    "print('# verified locations:',len(verified_with_bias),'of',locations_with_bias.shape[0])\n",
    "\n",
    "verified_with_bias += list(locations_with_bias.loc[\n",
    "locations_with_bias['LOCATION'].isin(locations_forgotten),'LOCATION'])\n",
    "verified_with_bias = list(set(verified_with_bias))\n",
    "print('# verified locations:',len(verified_with_bias),'of',locations_with_bias.shape[0])\n",
    "\n",
    "verified_with_bias += list(locations_with_bias.loc[\n",
    "locations_with_bias['LOCATION'].isin(locations_missed),'LOCATION'])\n",
    "verified_with_bias = list(set(verified_with_bias))\n",
    "print('# verified locations:',len(verified_with_bias),'of',locations_with_bias.shape[0])\n",
    "\n",
    "verified_with_bias += list(locations_with_bias.loc[\n",
    "locations_with_bias['LOCATION'].isin(locations_with_homonyms)]['LOCATION'])\n",
    "verified_with_bias = list(set(verified_with_bias))\n",
    "print('# verified locations:',len(verified_with_bias),'of',locations_with_bias.shape[0])\n",
    "\n",
    "verified_with_bias += list(locations_with_bias.loc[\n",
    "locations_with_bias['LOCATION'].isin(locations_uninteresting)]['LOCATION'])\n",
    "verified_with_bias = list(set(verified_with_bias))\n",
    "print('# verified locations:',len(verified_with_bias),'of',locations_with_bias.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Merge, and format manually processed geocodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Geocoded locations: 659\n"
     ]
    }
   ],
   "source": [
    "# Account Locations Geocoded Using the Google API\n",
    "geocoded_locations_manually = pd.read_pickle(path_to_data+'account-locations-geocoded-manually.pkl')\n",
    "print('# Geocoded locations:', geocoded_locations_manually.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge and Format:\n",
      "# Locations Geocoded With Bias: 659\n",
      "# Locations Geocoded With Bias With Result: 650\n",
      "Done in 1 sec\n"
     ]
    }
   ],
   "source": [
    "print('Merge and Format:')\n",
    "start = timer()\n",
    "\n",
    "# Merge Geocoded Locations With Reprocessed Locations (The Latter Keeps Being Updated So Use Left Merge)\n",
    "locations_manually = pd.merge(\n",
    "reprocess_manually[['LOCATION']],\n",
    "geocoded_locations_manually,\n",
    "left_on='LOCATION',\n",
    "right_on='raw_string',\n",
    "how='left').drop('raw_string',1)\n",
    "\n",
    "locations_manually = pd.merge(\n",
    "locations_manually,\n",
    "account_locations[['LOCATION','N','CC']],\n",
    "how='left')\n",
    "\n",
    "del geocoded_locations_manually\n",
    "\n",
    "print('# Locations Geocoded With Bias:', locations_manually.shape[0])\n",
    "\n",
    "locations_manually.sort_values(by='N',ascending=False,inplace=True)\n",
    "\n",
    "dropped_manually=list(locations_manually.loc[locations_manually['status']!='OK','LOCATION'])\n",
    "\n",
    "locations_manually = locations_manually[locations_manually['status']=='OK'].copy()\n",
    "\n",
    "print('# Locations Geocoded With Bias With Result:', locations_manually.shape[0])\n",
    "\n",
    "locations_manually = locations_manually[[\n",
    "'LOCATION', \n",
    "'input_string',\n",
    "'N',\n",
    "'CC',\n",
    "'formatted_address', \n",
    "'latitude', \n",
    "'longitude', \n",
    "'response',\n",
    "'type',\n",
    "]].reset_index(drop=True).copy()\n",
    "\n",
    "locations_manually = pd.concat([locations_manually,\n",
    "locations_manually['response'].apply(lambda x: nth_result(x, 0))],1)\n",
    "del locations_manually['response']\n",
    "\n",
    "verified_manually = list(locations_manually['LOCATION'])\n",
    "\n",
    "print(\"Done in\", round(timer()-start), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final List of Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "'LOCATION',\n",
    "'N',\n",
    "'latitude', \n",
    "'longitude',\n",
    "'country_long',\n",
    "'country_short',\n",
    "'locality_long',\n",
    "'locality_short',\n",
    "'administrative_area_level_1_long',\n",
    "'administrative_area_level_1_short',\n",
    "'administrative_area_level_2_long',\n",
    "'administrative_area_level_2_short',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_final = pd.concat([\n",
    "locations.loc[locations['LOCATION'].isin(verified),cols],\n",
    "locations_with_bias.loc[locations_with_bias['LOCATION'].isin(verified_with_bias),cols],\n",
    "locations_manually.loc[locations_manually['LOCATION'].isin(verified_manually),cols],\n",
    "]).sort_values(by='N',ascending=False).reset_index(drop=True)\n",
    "\n",
    "locations_final.rename(columns={'LOCATION':'user_location','N':'n_users'},inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_final.to_pickle(path_to_data+'../account-locations.pkl')\n",
    "locations_final.to_csv(path_to_data+'../account-locations.csv',float_format='%.10f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_final=pd.read_pickle(path_to_data+'../account-locations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39779"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.user_location.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_final.country_short.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_final.administrative_area_level_1_short.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3651"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_final.administrative_area_level_2_short.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7700"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_final.locality_short.unique().shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
